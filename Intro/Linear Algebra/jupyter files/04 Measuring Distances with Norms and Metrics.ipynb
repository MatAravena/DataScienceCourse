{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "# Measuring Distances with Norms and Metrics (solution)\nModule 0 | Chapter 2 | Notebook 4\n\n***\nIn the last lesson we got to know the scalar product and length of vectors. From this we calculated the cosine similarity of the wines. Now we will look at an alternative way of calculating the similarity. In this exercise you will learn:\n* How to calculate distances between two data points\n* The big differences between metrics and norms\n* How to caluclate the similarity of data points with the L2 norm \n***\n",
    "selectable": false
   },
   "source": [
    "# Measuring Distances with Norms and Metrics\n",
    "Module 0 | Chapter 2 | Notebook 4\n",
    "\n",
    "***\n",
    "In the last lesson we got to know the scalar product and length of vectors. From this we calculated the cosine similarity of the wines. Now we will look at an alternative way of calculating the similarity. In this exercise you will learn:\n",
    "* How to calculate distances between two data points\n",
    "* The big differences between metrics and norms\n",
    "* How to caluclate the similarity of data points with the L2 norm \n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## A brief look at metrics and norms\n",
    "selectable": false
   },
   "source": [
    "## A brief look at metrics and norms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "szenario",
    "original-content": "**Scenario:** 1001Wines is an online retailer that sells wines through its website. 1001Wines would like to recommend its customers high-quality wines that might be to their taste.\nThey therefore want to create a recommendation tool to compare the similarity of purchased wines with other wines from the assortment. If a wine from the range is similar to what customers have already ordered, it should be recommended to them.\n",
    "selectable": false
   },
   "source": [
    "**Scenario:** 1001Wines is an online retailer that sells wines through its website. 1001Wines would like to recommend its customers high-quality wines that might be to their taste.\n",
    "They therefore want to create a recommendation tool to compare the similarity of purchased wines with other wines from the assortment. If a wine from the range is similar to what customers have already ordered, it should be recommended to them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "In the last lesson you already developed a measure of similarity. This assesses the similarity of two wines based on the ratio between the proportions of sugar and sulphates in the wine. In principle, this was not a bad assumption if you don't have domain knowledge yourself. But now the sommeliers at 1001Wines have had their say and said that the ratio of the proportions is not what determines the different flavour, but rather the total number of ingredients. Sometimes the exact requirements only come to light in the course of the project. But this isn't a problem. You will develop an degree of similarity based on this in this lesson.\n",
    "selectable": false
   },
   "source": [
    "In the last lesson you already developed a measure of similarity. This assesses the similarity of two wines based on the ratio between the proportions of sugar and sulphates in the wine. In principle, this was not a bad assumption if you don't have domain knowledge yourself. But now the sommeliers at 1001Wines have had their say and said that the ratio of the proportions is not what determines the different flavour, but rather the total number of ingredients. Sometimes the exact requirements only come to light in the course of the project. But this isn't a problem. You will develop an degree of similarity based on this in this lesson.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "The concept of similarity in our imagination is closely related to the concept of distance. The smaller the distance, the more similar the data points are. However, it makes sense to distinguish these two concepts from each other. When we speak colloquially of similarity, we usually mean a similarity in one or more specific characteristics. it's possible that two objects are very similar in certain aspects, but in others they are very different. For example, we previously dealt with the cosine similarity. Two vectors are similar in this case if they point roughly in the same direction. In addition to a direction, vectors also have a length. Would we call two vectors which point in the same direction, but have very different lengths similar in day-to-day life? This can depend on the context. Instead of the similarity we can also speak about the distance between two objects. In linear algebra we refer to metrics when we talk about distances. Metrics are, so to speak, a generalization of the concept of distance that we use in everyday life. Metrics have certain characteristics that our concept of distance from everyday life also has. \nA metric $d(x,y)$ meets the following properties:\n\n* $d(x,y)\\: \\ge 0; \\: d(x,y) = 0$, g.d.w. $x=y$: (positive definite)\n* $d(x,y) = d(y,x)$ (symmetry)\n* $d(x,y)\\le d(x,c)+d(c,y)$ (triangle inequality)\n\n\nWe can now bring these mathematical definitions to life. In everyday life we indicate distances in meters, for example. So we can take a meter rule and measure the length. Following this intuition, we can assume that distances cannot assume negative values. Furthermore, we expect that a distance of $0$ is only present if the two objects are in exactly the same position. This is exactly the first property of metrics. The second property describes the following observation: if you measure the distance between two objects, e.g. with a ruler, the distance does not depend on whether you place one end of the ruler at object $x$\nand read the distance to $y$, or if you do it the other way around. The last property describes that the distance should describe the shortest path between the objects. The distance from $x$ to $y$ should always be less than or equal to the sum of the distances from $x$ to another point $c$ and the distance from $c$ to $y$. Specifically: If we leave our home to drive to the cinema, the kilometer counter when we get to the cinema should at most display the length of the route travelled that it would have displayed if we had picked up a friend on the way. In the best case the person lives directly on the route, then both traveled routes are identical. Otherwise we have to make a detour and the route we travel becomes longer. \nAs far as we are concerned, the length and distance are the same. In linear algebra this is not quite the case. A distinction is made there between distances (metrics) and lengths (norms). If we have a measure of length (a norm), we can always use it to measure a distance (a metric). We define a vector that connects the two points and determine its norm. The reverse is not necessarily true. The following metric is an example of a metric that cannot be used as a norm:\n\n$d(x,y)=\\begin{cases}0&\\text{if} x=y \\\\ ||x||+||y|| & \\text{otherwise} \\end{cases}$\n\nThis distance function is not based on the norm of the vector connecting the two points and that means you cannot derive a norm from this metric in a clear way. \n\n\nLet's make this a little clearer. In the last lesson, we calculated the cosine similarity of the wines. For this, we need the angle between two vectors.\n\n![angle between 2 vectors](00-02-02-pic4.png)\n",
    "selectable": false
   },
   "source": [
    "The concept of similarity in our imagination is closely related to the concept of distance. The smaller the distance, the more similar the data points are. However, it makes sense to distinguish these two concepts from each other. When we speak colloquially of similarity, we usually mean a similarity in one or more specific characteristics. it's possible that two objects are very similar in certain aspects, but in others they are very different. For example, we previously dealt with the cosine similarity. Two vectors are similar in this case if they point roughly in the same direction. In addition to a direction, vectors also have a length. Would we call two vectors which point in the same direction, but have very different lengths similar in day-to-day life? This can depend on the context. Instead of the similarity we can also speak about the distance between two objects. In linear algebra we refer to metrics when we talk about distances. Metrics are, so to speak, a generalization of the concept of distance that we use in everyday life. Metrics have certain characteristics that our concept of distance from everyday life also has. \n",
    "A metric $d(x,y)$ meets the following properties:\n",
    "\n",
    "* $d(x,y)\\: \\ge 0; \\: d(x,y) = 0$, g.d.w. $x=y$: (positive definite)\n",
    "* $d(x,y) = d(y,x)$ (symmetry)\n",
    "* $d(x,y)\\le d(x,c)+d(c,y)$ (triangle inequality)\n",
    "\n",
    "\n",
    "We can now bring these mathematical definitions to life. In everyday life we indicate distances in meters, for example. So we can take a meter rule and measure the length. Following this intuition, we can assume that distances cannot assume negative values. Furthermore, we expect that a distance of $0$ is only present if the two objects are in exactly the same position. This is exactly the first property of metrics. The second property describes the following observation: if you measure the distance between two objects, e.g. with a ruler, the distance does not depend on whether you place one end of the ruler at object $x$\n",
    "and read the distance to $y$, or if you do it the other way around. The last property describes that the distance should describe the shortest path between the objects. The distance from $x$ to $y$ should always be less than or equal to the sum of the distances from $x$ to another point $c$ and the distance from $c$ to $y$. Specifically: If we leave our home to drive to the cinema, the kilometer counter when we get to the cinema should at most display the length of the route travelled that it would have displayed if we had picked up a friend on the way. In the best case the person lives directly on the route, then both traveled routes are identical. Otherwise we have to make a detour and the route we travel becomes longer. \n",
    "As far as we are concerned, the length and distance are the same. In linear algebra this is not quite the case. A distinction is made there between distances (metrics) and lengths (norms). If we have a measure of length (a norm), we can always use it to measure a distance (a metric). We define a vector that connects the two points and determine its norm. The reverse is not necessarily true. The following metric is an example of a metric that cannot be used as a norm:\n",
    "\n",
    "$d(x,y)=\\begin{cases}0&\\text{if} x=y \\\\ ||x||+||y|| & \\text{otherwise} \\end{cases}$\n",
    "\n",
    "This distance function is not based on the norm of the vector connecting the two points and that means you cannot derive a norm from this metric in a clear way. \n",
    "\n",
    "\n",
    "Let's make this a little clearer. In the last lesson, we calculated the cosine similarity of the wines. For this, we need the angle between two vectors.\n",
    "\n",
    "![angle between 2 vectors](00-02-02-pic4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "This measures to a certain extent the similarity of the direction of two vectors. It is easy to be convinced that cosine similarity is neither a metric nor a norm. \nSo how about the lengths of the vectors? You can calculate this for each vector individually. You don't need a second one to be able to do this. So the length is a norm. So we used the `norm()` function to calculate the length of vectors. If we have a norm, we can always use it to create a metric. Let's try that out now.\n\nIn everyday life, for example, we might say things like: \"The distance from the starting blocks to the finish line is 100 meters.\" To get to 100 meters, we measure the distance from the start point and finish point. These are also data points with two properties: their coordinates. We can plot the distance between the points on a plane with a vector and then measure its length.\n\n![distance between start and end point](00-02-03-pic1.png)\n",
    "selectable": true
   },
   "source": [
    "This measures to a certain extent the similarity of the direction of two vectors. It is easy to be convinced that cosine similarity is neither a metric nor a norm. \n",
    "So how about the lengths of the vectors? You can calculate this for each vector individually. You don't need a second one to be able to do this. So the length is a norm. So we used the `norm()` function to calculate the length of vectors. If we have a norm, we can always use it to create a metric. Let's try that out now.\n",
    "\n",
    "In everyday life, for example, we might say things like: \"The distance from the starting blocks to the finish line is 100 meters.\" To get to 100 meters, we measure the distance from the start point and finish point. These are also data points with two properties: their coordinates. We can plot the distance between the points on a plane with a vector and then measure its length.\n",
    "\n",
    "![distance between start and end point](00-02-03-pic1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "In this visualization we have chose an arbitrary zero point. For example, this could be your seat as a spectator. The start position is given by coordinates `[13, 52]` and the end point by `[113, 52]`. The distance between the points corresponds to the length of the vector. So far we have always started the vectors from the point `[0, 0]`. If we start from a different point, we simply subtract the vector of the starting point from the vector of the end point. Try it out! Create a new vector by subtracting `[13, 52]` from `[113, 52]`. How long is the new vector?\n",
    "selectable": true
   },
   "source": [
    "In this visualization we have chose an arbitrary zero point. For example, this could be your seat as a spectator. The start position is given by coordinates `[13, 52]` and the end point by `[113, 52]`. The distance between the points corresponds to the length of the vector. So far we have always started the vectors from the point `[0, 0]`. If we start from a different point, we simply subtract the vector of the starting point from the vector of the end point. Try it out! Create a new vector by subtracting `[13, 52]` from `[113, 52]`. How long is the new vector?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Remember to import `numpy` (alias `np`) to be able to perform calculations on the arrays. Also import the `norm` function from the submodule `numpy.linalg`. Subtract the arrays from one another and calculate the length from the result.",
    "hint_counter": 3,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "\n",
    "vec = np.array([13,52])\n",
    "vec2 = np.array([113,52])\n",
    "vec_length = norm(vec2 - vec)\n",
    "print(vec_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "The length is 100. Since we have given the coordinates in meters from our position, it's 100 meters.\nThe `norm()` function calculates the length of a vector, which we can use to measure a distance! If you don't specify additional arguments it calculates the Euclidean norm. This is the norm we use in everyday life to measure distances. It is also called the **L2 norm**. Remember this term, because it comes up a lot in the context of machine learning.\n\nOur distinction between metric and norm is somewhat crude. There are also precise mathematical definitions for both of them. But don't worry, you don't need to learn them now. The most important thing is that you connect the terms **norm** and **metric** with **measuring lengths and distances** of vectors.\n",
    "selectable": true
   },
   "source": [
    "The length is 100. Since we have given the coordinates in meters from our position, it's 100 meters.\n",
    "The `norm()` function calculates the length of a vector, which we can use to measure a distance! If you don't specify additional arguments it calculates the Euclidean norm. This is the norm we use in everyday life to measure distances. It is also called the **L2 norm**. Remember this term, because it comes up a lot in the context of machine learning.\n",
    "\n",
    "Our distinction between metric and norm is somewhat crude. There are also precise mathematical definitions for both of them. But don't worry, you don't need to learn them now. The most important thing is that you connect the terms **norm** and **metric** with **measuring lengths and distances** of vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "glueckwunsch",
    "original-content": "**Congratulations:** You now know the terms metric and norm. You will encounter them very often in the field of machine learning. Now we will use the L2 norm to determine a similarity between the wines.\n",
    "selectable": false
   },
   "source": [
    "**Congratulations:** You now know the terms metric and norm. You will encounter them very often in the field of machine learning. Now we will use the L2 norm to determine a similarity between the wines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## Product recommendation with the L2 norm\n",
    "selectable": false
   },
   "source": [
    "## Product recommendation with the L2 norm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Run the next cell to import the data quickly and to print the first 5 rows.\n",
    "selectable": false
   },
   "source": [
    "Run the next cell to import the data quickly and to print the first 5 rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "cell_content_type": "code_demo",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "If you would like, you can discuss this in the forum under *Measuring Distances with Norms and Metrics*.",
    "original-content": "import pandas as pd\ndf = pd.read_csv('wine-quality.csv')\ndf.head()",
    "selectable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed.acidity</th>\n",
       "      <th>volatile.acidity</th>\n",
       "      <th>citric.acid</th>\n",
       "      <th>residual.sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <th>total.sulfur.dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed.acidity  volatile.acidity  citric.acid  residual.sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free.sulfur.dioxide  total.sulfur.dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  color  \n",
       "0      8.8  white  \n",
       "1      9.5  white  \n",
       "2     10.1  white  \n",
       "3      9.9  white  \n",
       "4      9.9  white  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('wine-quality.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Last time we limited ourselves two properties, because we could visualize the results more easily. Mathematically speaking, however, it makes no difference how many entries our vectors have. We can calculate angles and lengths in all cases. So this time we will use all the columns except `'color'`, because this is not numeric. Each row of data (and therefore each wine) is a separate vector, which we will use to calculate the distances between the data points. \n\nFirst we would like to get a feeling for the distances to be able to say when two wines are similar. Calculate the L2 norm between each wine and the wine with index 0. Remember that you must subtract the corresponding vectors from each other before calculating the length (L2 norm). So the numerical values of the rows describe our start and end point, just like in the 100 meter sprint.\nSave these distances as a list in the variable `distance_idx0` and print the first two values.\n",
    "selectable": true
   },
   "source": [
    "Last time we limited ourselves two properties, because we could visualize the results more easily. Mathematically speaking, however, it makes no difference how many entries our vectors have. We can calculate angles and lengths in all cases. So this time we will use all the columns except `'color'`, because this is not numeric. Each row of data (and therefore each wine) is a separate vector, which we will use to calculate the distances between the data points. \n",
    "\n",
    "First we would like to get a feeling for the distances to be able to say when two wines are similar. Calculate the L2 norm between each wine and the wine with index 0. Remember that you must subtract the corresponding vectors from each other before calculating the length (L2 norm). So the numerical values of the rows describe our start and end point, just like in the 100 meter sprint.\n",
    "Save these distances as a list in the variable `distance_idx0` and print the first two values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Use the following code to calculate the L2 norm of two wines: `norm(df.iloc[i,:-1] - df.iloc[0,: -1])`. `i` is the iterator variable for your loop. The last column is `color`, so we can exclude it in the code.\nFor the loop code you can use e.g. `df.index`.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 52.63917709273199]\n",
      "6497\n"
     ]
    }
   ],
   "source": [
    "distance_idx0 = []\n",
    "for i in df.index:\n",
    "    distance_idx0.append( norm(df.iloc[i,:-1] - df.iloc[0,: -1]))\n",
    "\n",
    "print(distance_idx0[:2])\n",
    "print(len(distance_idx0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "The distance from the wine with index 0 to itself is 0. This is to be expected since it is just one wine. The distance to the wine with index 1 is roughly 52.6. Maybe you're wondering what that distance means. We are only familiar with measuring distances in units like meters in two or three dimensions. However, the concept can be applied to as many dimensions as you wish, the calculation remains the same. The distance is always only a number. We use them to determine how similar two data points are. Because the vector between two data points is shorter when they have very similar values. \n\nIt's best for us to get an overview of the distribution of the distances so that we can better evaluate them.\nNow print the distribution of your distances with a histogram with 50 bins.\n",
    "selectable": false
   },
   "source": [
    "The distance from the wine with index 0 to itself is 0. This is to be expected since it is just one wine. The distance to the wine with index 1 is roughly 52.6. Maybe you're wondering what that distance means. We are only familiar with measuring distances in units like meters in two or three dimensions. However, the concept can be applied to as many dimensions as you wish, the calculation remains the same. The distance is always only a number. We use them to determine how similar two data points are. Because the vector between two data points is shorter when they have very similar values. \n",
    "\n",
    "It's best for us to get an overview of the distribution of the distances so that we can better evaluate them.\n",
    "Now print the distribution of your distances with a histogram with 50 bins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "For example, import the submodule `matplotlib.pyplot` with its conventional alias and use the `my_axis.hist()` method.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1)\n",
    "ax.hist(distance_idx0, bins=100)\n",
    "ax.set(xlabel='Similarity based on L2 metric',ylabel='Number of wines');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Our histogram looked something like this:\n\n![del](00-02-03-pic2.png)\n",
    "selectable": false
   },
   "source": [
    "Our histogram looked something like this:\n",
    "\n",
    "![del](00-02-03-pic2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "We can see that the number of wines starts to increase rapidly with the distance. We could now determine a value on the x-axis that reflects our maximum distance so that a wine is still considered similar. This distribution could however be different for other wines. This could lead to a case where we're not able to recommend any wine at all because we restricted the distance too much. For a product recommendation it makes more sense to always select a fixed number. For example the 10 most similar wines. It's our goal for this lesson to write this function.\n",
    "selectable": false
   },
   "source": [
    "We can see that the number of wines starts to increase rapidly with the distance. We could now determine a value on the x-axis that reflects our maximum distance so that a wine is still considered similar. This distribution could however be different for other wines. This could lead to a case where we're not able to recommend any wine at all because we restricted the distance too much. For a product recommendation it makes more sense to always select a fixed number. For example the 10 most similar wines. It's our goal for this lesson to write this function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Use the following steps:\n* Define a function called `wine_recommendation_L2` with the parameters `df_wines`, `wine_id` and `quantity`. `df_wines` is the data frame containing the wine data. `wine_id` is the index of the wine a customer has bought. And `quantity` is the number of wines to be recommended.\n* Define the variable `cols` internally in the function. It contains all the column names of the data except for `color`.\n* Create a loop or *list comprehension* which iterates directly through the row names in `df.index`.\n* It should calculate the distance between each wine and the wine with index `wine_id`. To do this, treat the rows of data in the same way as the start and end points for the 100 meter sprint. The row with index `wine_id` is always the starting point. The loop's iterator variable returns the line of the target point. So subtract them and calculate the L2 norm of the result. Assign these distances as a list to the `distances` variable.\n* Select the smallest distances with `quantity`. Their index corresponds to the wines to be recommended.\n* Use the keyword `return` to output the index of wines to be recommended as a `list` or `array`.\n* Add a docstring to your function. Use 3 double quotation marks for this. The *docstring* should contain a short description of the function and the parameters and output values. You can look at the *docstring* from the last exercise for some inspiration.\n\nYou can use this function header to orientate yourself\n\n```python\ndef wine_recommendation_L2(df_wines, wine_id, quantity):\n    \"\"\"Return positions of wines in df_wines, which are similar to the wine at position wine_id.\n    \n    Use L2 norm as a measure of similarity between two wines.\n    \n    Args:\n        df_wines (DataFrame): Contains the wines quality data.\n        wine_id (int): Position in df_wines of the wine, on which the recommendation is based.\n        quantity (int): Number of recommended wines to return.\n\n    Returns:\n        recommendations (list): Contains the positions of quantity wines that are most similar to wine_id.\n        \n    \"\"\"\n```\n\nTip: The easiest way to select the smallest distances from a list is to use the function `np.argsort()`. It sorts the list in ascending order and returns its indices as an array. The smallest values are therefore at the beginning of the array.\n",
    "selectable": true
   },
   "source": [
    "Use the following steps:\n",
    "* Define a function called `wine_recommendation_L2` with the parameters `df_wines`, `wine_id` and `quantity`. `df_wines` is the data frame containing the wine data. `wine_id` is the index of the wine a customer has bought. And `quantity` is the number of wines to be recommended.\n",
    "* Define the variable `cols` internally in the function. It contains all the column names of the data except for `color`.\n",
    "* Create a loop or *list comprehension* which iterates directly through the row names in `df.index`.\n",
    "* It should calculate the distance between each wine and the wine with index `wine_id`. To do this, treat the rows of data in the same way as the start and end points for the 100 meter sprint. The row with index `wine_id` is always the starting point. The loop's iterator variable returns the line of the target point. So subtract them and calculate the L2 norm of the result. Assign these distances as a list to the `distances` variable.\n",
    "* Select the smallest distances with `quantity`. Their index corresponds to the wines to be recommended.\n",
    "* Use the keyword `return` to output the index of wines to be recommended as a `list` or `array`.\n",
    "* Add a docstring to your function. Use 3 double quotation marks for this. The *docstring* should contain a short description of the function and the parameters and output values. You can look at the *docstring* from the last exercise for some inspiration.\n",
    "\n",
    "You can use this function header to orientate yourself\n",
    "\n",
    "```python\n",
    "def wine_recommendation_L2(df_wines, wine_id, quantity):\n",
    "    \"\"\"Return positions of wines in df_wines, which are similar to the wine at position wine_id.\n",
    "    \n",
    "    Use L2 norm as a measure of similarity between two wines.\n",
    "    \n",
    "    Args:\n",
    "        df_wines (DataFrame): Contains the wines quality data.\n",
    "        wine_id (int): Position in df_wines of the wine, on which the recommendation is based.\n",
    "        quantity (int): Number of recommended wines to return.\n",
    "\n",
    "    Returns:\n",
    "        recommendations (list): Contains the positions of quantity wines that are most similar to wine_id.\n",
    "        \n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "Tip: The easiest way to select the smallest distances from a list is to use the function `np.argsort()`. It sorts the list in ascending order and returns its indices as an array. The smallest values are therefore at the beginning of the array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "You can select all columns apart from `color` with `df_wines.columns[:-1]`.\n Use `df.index` in the loop header to iterate directly through the row names.\n Your code to calculate the distance could look like this: `dist = norm(df_wines.loc[i,cols]-df_wines.loc[wine_id,cols])`, where `i` is your iterator variable and `cols` are the columns you want to use.\n To get the line positions of the smallest AbstÃƒÂ¤nde use the code `recommendations = np.argsort(distances)[:quantity]`.",
    "original-content": "",
    "selectable": true
   },
   "outputs": [],
   "source": [
    "def wine_recommendation_L2(df_wines, wine_id, quantity):\n",
    "    \"\"\"Return positions of wines in df_wines, which are similar to the wine at position wine_id.\n",
    "    \n",
    "    Use L2 norm as a measure of similarity between two wines.\n",
    "    \n",
    "    Args:\n",
    "        df_wines (DataFrame): Contains the wines quality data.\n",
    "        wine_id (int): Position in df_wines of the wine, on which the recommendation is based.\n",
    "        quantity (int): Number of recommended wines to return.\n",
    "\n",
    "    Returns:\n",
    "        recommendations (list): Contains the positions of quantity wines that are most similar to wine_id.\n",
    "        \n",
    "    \"\"\"\n",
    "    cols = df_wines.columns[:-1] \n",
    "    distances = []\n",
    "    for i in range(len(df_wines)):\n",
    "        distances.append( norm( df_wines.loc[i,cols] - df_wines.loc[wine_id,cols] ))\n",
    "    return np.argsort(distances)[:quantity]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "We should now test the function. We can expect that each wine should be most similar to itself. Since we are using all columns this time, the function should only return the position of the wine you enter if you specify `quantity = 1`. Let's try that out for a few wines. Our expectations are listed in the following table:\n\nInput | Output \n---|---\n`wine_id = 0`, `quantity = 1`, `df_wines = df` | `[0]`\n`wine_id = 3200`, `quantity = 1`, `df_wines = df` | `[3200]`\n`wine_id = 6400`, `quantity = 1`, `df_wines = df` | `[6400]`\n\nPrint the output values of the given with the different argument values, this may take a few seconds. Did you receive the output you were expecting?\n",
    "selectable": true
   },
   "source": [
    "We should now test the function. We can expect that each wine should be most similar to itself. Since we are using all columns this time, the function should only return the position of the wine you enter if you specify `quantity = 1`. Let's try that out for a few wines. Our expectations are listed in the following table:\n",
    "\n",
    "Input | Output \n",
    "---|---\n",
    "`wine_id = 0`, `quantity = 1`, `df_wines = df` | `[0]`\n",
    "`wine_id = 3200`, `quantity = 1`, `df_wines = df` | `[3200]`\n",
    "`wine_id = 6400`, `quantity = 1`, `df_wines = df` | `[6400]`\n",
    "\n",
    "Print the output values of the given with the different argument values, this may take a few seconds. Did you receive the output you were expecting?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Try using the code `print(wine_recommendation_L2(df_wines=df, wine_id=0, quantity = 1))`.",
    "original-content": "",
    "selectable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6400])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_recommendation_L2(wine_id = 0, quantity = 1, df_wines = df)\n",
    "wine_recommendation_L2(wine_id = 3200, quantity = 1, df_wines = df)\n",
    "wine_recommendation_L2(wine_id = 6400, quantity = 1, df_wines = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "After the small test we can now return to making actual recommendations. Which wines do you see as the output if you pass `wine_id = 0` and `quantity = 10`? Store the recommendations as `recommendation_0` and `df.loc[recommendation_0, :]`. What color are the wines?\n",
    "selectable": true
   },
   "source": [
    "After the small test we can now return to making actual recommendations. Which wines do you see as the output if you pass `wine_id = 0` and `quantity = 10`? Store the recommendations as `recommendation_0` and `df.loc[recommendation_0, :]`. What color are the wines?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "The 10 most similar wines that we receive have the indices `[0, 7, 103, 1487, 2269, 191, 182, 14, 813, 773]`.\n * If all your indices are one lower, then you went through `wine_id` in its entirety in the loop. Instead of that, try assigning the wine with `wine_id` a greater distance in an `if` statement. This keeps the indices the same, but `wine_id` will not be recommended.",
    "hint_counter": 0,
    "original-content": "",
    "selectable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed.acidity</th>\n",
       "      <th>volatile.acidity</th>\n",
       "      <th>citric.acid</th>\n",
       "      <th>residual.sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <th>total.sulfur.dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.70</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.70</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.40</td>\n",
       "      <td>18.90</td>\n",
       "      <td>0.059</td>\n",
       "      <td>44.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.0</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.74</td>\n",
       "      <td>19.40</td>\n",
       "      <td>0.054</td>\n",
       "      <td>44.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.00040</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>8.5</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.56</td>\n",
       "      <td>17.30</td>\n",
       "      <td>0.055</td>\n",
       "      <td>47.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>1.00047</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.67</td>\n",
       "      <td>9.3</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.048</td>\n",
       "      <td>48.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.40</td>\n",
       "      <td>22.00</td>\n",
       "      <td>0.048</td>\n",
       "      <td>48.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8.7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>8.3</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.62</td>\n",
       "      <td>19.25</td>\n",
       "      <td>0.040</td>\n",
       "      <td>41.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1.00020</td>\n",
       "      <td>2.98</td>\n",
       "      <td>0.67</td>\n",
       "      <td>9.7</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.32</td>\n",
       "      <td>16.50</td>\n",
       "      <td>0.045</td>\n",
       "      <td>44.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.30</td>\n",
       "      <td>16.70</td>\n",
       "      <td>0.039</td>\n",
       "      <td>49.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>0.99985</td>\n",
       "      <td>3.40</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.4</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed.acidity  volatile.acidity  citric.acid  residual.sugar  chlorides  \\\n",
       "0               7.0             0.270         0.36           20.70      0.045   \n",
       "7               7.0             0.270         0.36           20.70      0.045   \n",
       "103             7.5             0.305         0.40           18.90      0.059   \n",
       "1487            6.7             0.250         0.74           19.40      0.054   \n",
       "2269            8.5             0.190         0.56           17.30      0.055   \n",
       "191             6.8             0.280         0.40           22.00      0.048   \n",
       "182             6.8             0.280         0.40           22.00      0.048   \n",
       "14              8.3             0.420         0.62           19.25      0.040   \n",
       "813             6.5             0.260         0.32           16.50      0.045   \n",
       "773             6.1             0.270         0.30           16.70      0.039   \n",
       "\n",
       "      free.sulfur.dioxide  total.sulfur.dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "7                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "103                  44.0                 170.0  1.00000  2.99       0.46   \n",
       "1487                 44.0                 169.0  1.00040  3.51       0.45   \n",
       "2269                 47.0                 169.0  1.00047  3.07       0.67   \n",
       "191                  48.0                 167.0  1.00100  2.93       0.50   \n",
       "182                  48.0                 167.0  1.00100  2.93       0.50   \n",
       "14                   41.0                 172.0  1.00020  2.98       0.67   \n",
       "813                  44.0                 166.0  1.00000  3.38       0.46   \n",
       "773                  49.0                 172.0  0.99985  3.40       0.45   \n",
       "\n",
       "      alcohol  color  \n",
       "0         8.8  white  \n",
       "7         8.8  white  \n",
       "103       9.0  white  \n",
       "1487      9.8  white  \n",
       "2269      9.3  white  \n",
       "191       8.7  white  \n",
       "182       8.7  white  \n",
       "14        9.7  white  \n",
       "813       9.5  white  \n",
       "773       9.4  white  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_0 = wine_recommendation_L2(wine_id = 0, quantity = 10, df_wines = df)\n",
    "df.loc[recommendation_0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "We only saw white wines as a result. But that was also the case with cosine similarity. What does it look like for `wine_id = 6400`?\n",
    "selectable": true
   },
   "source": [
    "We only saw white wines as a result. But that was also the case with cosine similarity. What does it look like for `wine_id = 6400`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "The 6 most similar wines that we receive have the indices `[6400, 1468, 5320, 5322, 4904, 6081]`.\n * If all your indices are one lower, then you went through `wine_id` in its entirety in the loop. This means your your series is shorter by one value. Instead of that, try assigning the wine with `wine_id` a greater distance in an `if` statement. This keeps the indices the same, but `wine_id` will not be recommended.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed.acidity</th>\n",
       "      <th>volatile.acidity</th>\n",
       "      <th>citric.acid</th>\n",
       "      <th>residual.sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free.sulfur.dioxide</th>\n",
       "      <th>total.sulfur.dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.18</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.078</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99638</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.54</td>\n",
       "      <td>9.8</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.046</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99280</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.39</td>\n",
       "      <td>9.8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5322</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.9</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5320</th>\n",
       "      <td>7.7</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99550</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.9</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.06</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.069</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.99640</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6081</th>\n",
       "      <td>6.8</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.070</td>\n",
       "      <td>16.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.99572</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.60</td>\n",
       "      <td>9.3</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.042</td>\n",
       "      <td>14.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.99144</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.8</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4910</th>\n",
       "      <td>5.6</td>\n",
       "      <td>0.615</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.089</td>\n",
       "      <td>16.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.99430</td>\n",
       "      <td>3.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>9.9</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>9.2</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.042</td>\n",
       "      <td>15.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.99240</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.28</td>\n",
       "      <td>10.4</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5590</th>\n",
       "      <td>8.6</td>\n",
       "      <td>0.490</td>\n",
       "      <td>0.51</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.422</td>\n",
       "      <td>16.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0.99790</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.0</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed.acidity  volatile.acidity  citric.acid  residual.sugar  chlorides  \\\n",
       "6400            7.3             0.585         0.18             2.4      0.078   \n",
       "1468            6.5             0.240         0.24             1.6      0.046   \n",
       "5322            7.7             0.960         0.20             2.0      0.047   \n",
       "5320            7.7             0.960         0.20             2.0      0.047   \n",
       "4904            7.9             0.600         0.06             1.6      0.069   \n",
       "6081            6.8             0.660         0.07             1.6      0.070   \n",
       "4735            6.0             0.170         0.36             1.7      0.042   \n",
       "4910            5.6             0.615         0.00             1.6      0.089   \n",
       "1349            9.2             0.350         0.39             0.9      0.042   \n",
       "5590            8.6             0.490         0.51             2.0      0.422   \n",
       "\n",
       "      free.sulfur.dioxide  total.sulfur.dioxide  density    pH  sulphates  \\\n",
       "6400                 15.0                  60.0  0.99638  3.31       0.54   \n",
       "1468                 15.0                  60.0  0.99280  3.19       0.39   \n",
       "5322                 15.0                  60.0  0.99550  3.36       0.44   \n",
       "5320                 15.0                  60.0  0.99550  3.36       0.44   \n",
       "4904                 15.0                  59.0  0.99640  3.30       0.46   \n",
       "6081                 16.0                  61.0  0.99572  3.29       0.60   \n",
       "4735                 14.0                  61.0  0.99144  3.22       0.54   \n",
       "4910                 16.0                  59.0  0.99430  3.58       0.52   \n",
       "1349                 15.0                  61.0  0.99240  2.96       0.28   \n",
       "5590                 16.0                  62.0  0.99790  3.03       1.17   \n",
       "\n",
       "      alcohol  color  \n",
       "6400      9.8    red  \n",
       "1468      9.8  white  \n",
       "5322     10.9    red  \n",
       "5320     10.9    red  \n",
       "4904      9.4    red  \n",
       "6081      9.3    red  \n",
       "4735     10.8  white  \n",
       "4910      9.9    red  \n",
       "1349     10.4  white  \n",
       "5590      9.0    red  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation_0 = wine_recommendation_L2(wine_id = 6400, quantity = 10, df_wines = df)\n",
    "df.loc[recommendation_0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "This time it contains both red and white wines. So there is also an overlap with the L2 norm as a similarity. Apparently, some red and white wines are very similar.\n",
    "selectable": false
   },
   "source": [
    "This time it contains both red and white wines. So there is also an overlap with the L2 norm as a similarity. Apparently, some red and white wines are very similar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "beachte",
    "original-content": "**Important:** If you look more closely at the properties of the recommended wines, you can see that properties with low numerical values such as `chlorides` vary a lot more more, relative to their value, than properties with high numerical values, such as `total.sulfur.dioxide`. This is because all deviations of properties are treated equally for the L2 norm, regardless of how big the deviation is relative to the absolute values. The relative change of `chlorides` therefore holds less weight than that of `total.sulfur.dioxide`. Specifically: if you compare the largest value with the smallest value, you will notice that the largest value of `chlorides` is a multiple of the smallest value. In comparison, `total.sulfur.dioxide` only varies by a few percent. Depending on how the relative change in these properties affects the taste, it can distort the similarity calculation. We will show you how to solve this problem in the next module. The methods used to recommend products can then still be applied in the same way.\n",
    "selectable": true
   },
   "source": [
    "**Important:** If you look more closely at the properties of the recommended wines, you can see that properties with low numerical values such as `chlorides` vary a lot more more, relative to their value, than properties with high numerical values, such as `total.sulfur.dioxide`. This is because all deviations of properties are treated equally for the L2 norm, regardless of how big the deviation is relative to the absolute values. The relative change of `chlorides` therefore holds less weight than that of `total.sulfur.dioxide`. Specifically: if you compare the largest value with the smallest value, you will notice that the largest value of `chlorides` is a multiple of the smallest value. In comparison, `total.sulfur.dioxide` only varies by a few percent. Depending on how the relative change in these properties affects the taste, it can distort the similarity calculation. We will show you how to solve this problem in the next module. The methods used to recommend products can then still be applied in the same way.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "glueckwunsch",
    "original-content": "**Congratulations**: You have learned another method to classify products. Now you already know how to use the cosine similarity and the L2 norm to evaluate similarities. These methods are based solely on linear algebra. Now the sommeliers of 1001Wines are also satisfied. The company says thank you!\n",
    "selectable": false
   },
   "source": [
    "**Congratulations**: You have learned another method to classify products. Now you already know how to use the cosine similarity and the L2 norm to evaluate similarities. These methods are based solely on linear algebra. Now the sommeliers of 1001Wines are also satisfied. The company says thank you!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "You have now learned 2 methods for calculating the similarity of products: the angle between the vectors of two data points and the Euclidean distance between two data points. If we apply these two similarities to our wines, we get the following data points as similar wines to the wine at position 6400, for example.\n\n![Comparison of similarities with cosine and L2 norm](00-02-03-pic3.png)\n\nFor the visualization we only used the two columns `'residual.sugar'` and `'sulphates'`. On the left side we see that all points are on a straight line. This is because the angle is very narrow, so the relationships between of the columns are relatively constant.\nThe recommended points are in a circle on the right side. This is skewed into an ellipse in the y-direction because the scale of the y-axis is smaller in the display.\n\nBoth measures are some form of distance between the data points. Once this distance is given as an angle and once as the distance we are used to. There are many other measures that can be used to define distances between data points. Which measure you need always depends on which data you have and what you want to achieve.\n",
    "selectable": true
   },
   "source": [
    "You have now learned 2 methods for calculating the similarity of products: the angle between the vectors of two data points and the Euclidean distance between two data points. If we apply these two similarities to our wines, we get the following data points as similar wines to the wine at position 6400, for example.\n",
    "\n",
    "![Comparison of similarities with cosine and L2 norm](00-02-03-pic3.png)\n",
    "\n",
    "For the visualization we only used the two columns `'residual.sugar'` and `'sulphates'`. On the left side we see that all points are on a straight line. This is because the angle is very narrow, so the relationships between of the columns are relatively constant.\n",
    "The recommended points are in a circle on the right side. This is skewed into an ellipse in the y-direction because the scale of the y-axis is smaller in the display.\n",
    "\n",
    "Both measures are some form of distance between the data points. Once this distance is given as an angle and once as the distance we are used to. There are many other measures that can be used to define distances between data points. Which measure you need always depends on which data you have and what you want to achieve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## Additional metrics\n\nThe L2 norm we learned in this lesson is a representative of a whole family of metrics called Lp norms. The general formula for these metrics is\n\n$L^p(\\vec{x})= \\left(\\sum_i^N |x_i|^{p}\\right)^{\\frac{1}{p}},$\n\nwhere the absolute values of the components are taken to the power of $p$, added up and then the $p$-th root is taken. If you set $p=2$, you get the L2 norm. \n\n$L^2=\\sqrt{\\sum_i^N |x_i|^{2}}$\n\nAs an example, let's try calculating that for the vector `vec`. It is defined as follows:\n\n$\\vec{vec} = \\left(\\begin{array}{c} 2 \\\\ 1 \\end{array}\\right)$\n\nIn Python, this vector `vec` is defined as follows:\n```\nvec = [2, 1]\n```\n\nFor the L2 norm we get the following for the vector `vec`:\n$L^2=\\sqrt{|2|^2 + |1|^2}=\\sqrt{4 + 1}\\approx 2.3$\n\nFor $p=1$, we get another popular norm, the L1 norm. \n\n$L^1=\\sum_i^N |x_i|$\n\nHere the absolute values of the components of the vector are simply added up. It's simple to interpret. If you imagine a 2-dimensional, rectangular road network, the L1 norm of a vector on this grid describes the distance a taxi would have to travel in this road network to get from one end of the vector to the other end. It is therefore also called taxicab or Manhattan norm. \nFor the vector `vec`, we get\n\n$L^1= |2|+|1|=3$\n",
    "selectable": true,
    "tags": []
   },
   "source": [
    "## Additional metrics\n",
    "\n",
    "The L2 norm we learned in this lesson is a representative of a whole family of metrics called Lp norms. The general formula for these metrics is\n",
    "\n",
    "$L^p(\\vec{x})= \\left(\\sum_i^N |x_i|^{p}\\right)^{\\frac{1}{p}},$\n",
    "\n",
    "where the absolute values of the components are taken to the power of $p$, added up and then the $p$-th root is taken. If you set $p=2$, you get the L2 norm. \n",
    "\n",
    "$L^2=\\sqrt{\\sum_i^N |x_i|^{2}}$\n",
    "\n",
    "As an example, let's try calculating that for the vector `vec`. It is defined as follows:\n",
    "\n",
    "$\\vec{vec} = \\left(\\begin{array}{c} 2 \\\\ 1 \\end{array}\\right)$\n",
    "\n",
    "In Python, this vector `vec` is defined as follows:\n",
    "```\n",
    "vec = [2, 1]\n",
    "```\n",
    "\n",
    "For the L2 norm we get the following for the vector `vec`:\n",
    "$L^2=\\sqrt{|2|^2 + |1|^2}=\\sqrt{4 + 1}\\approx 2.3$\n",
    "\n",
    "For $p=1$, we get another popular norm, the L1 norm. \n",
    "\n",
    "$L^1=\\sum_i^N |x_i|$\n",
    "\n",
    "Here the absolute values of the components of the vector are simply added up. It's simple to interpret. If you imagine a 2-dimensional, rectangular road network, the L1 norm of a vector on this grid describes the distance a taxi would have to travel in this road network to get from one end of the vector to the other end. It is therefore also called taxicab or Manhattan norm. \n",
    "For the vector `vec`, we get\n",
    "\n",
    "$L^1= |2|+|1|=3$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "To practice, now write a short Python function *lp_norm(vec,p)*. This should have a vector as an input and the $p$ value for the corresponding metric. The function should return the value of the $Lp$ norm for the corresponding vector.\n",
    "selectable": false
   },
   "source": [
    "To practice, now write a short Python function *lp_norm(vec,p)*. This should have a vector as an input and the $p$ value for the corresponding metric. The function should return the value of the $Lp$ norm for the corresponding vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "For example, use a list comprehension to multiply the components individually. You can calculate the p-th power of x in Python with `x ** p`. With `np.sum()` you can sum up the components of a list. In this case you should make sure that you have imported `numpy` as `np`.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 norm for vec:  2.23606797749979\n",
      "L2 norm for vec:  3.0\n",
      "L1 norm for vec:  2.23606797749979\n",
      "L2 norm for vec:  3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def lp_norm( vec, p):\n",
    "    correlation = 0\n",
    "    for i in range(0, len(vec)):\n",
    "        correlation += abs(vec[i])**p\n",
    "    return correlation**(1/p)\n",
    "\n",
    "print('L1 norm for vec: ', lp_norm(vec=[2,1], p=2))\n",
    "print('L2 norm for vec: ', lp_norm(vec=[2,1], p=1))\n",
    "\n",
    "def lp_norm2(vec, p):\n",
    "    vec_p = [abs(x)**p for x in vec]\n",
    "    return (np.sum(vec_p))**(1/p)\n",
    "\n",
    "print('L1 norm for vec: ', lp_norm2(vec=[2,1], p=2))\n",
    "print('L2 norm for vec: ', lp_norm2(vec=[2,1], p=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Now we want to get an idea of how the $Lp$ metrics are related to each other. For this we'll look at how the $Lp$ norm of a vector behaves when we vary $p$. Plot the $Lp$ of the vector *vec* as a function of $p$ for integer values between 1 and 9.\n",
    "selectable": false
   },
   "source": [
    "Now we want to get an idea of how the $Lp$ metrics are related to each other. For this we'll look at how the $Lp$ norm of a vector behaves when we vary $p$. Plot the $Lp$ of the vector *vec* as a function of $p$ for integer values between 1 and 9.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "First add the vector vec: `vec = [2, 1]`. Then, for example, start by using the `range()` function to create a list of integers between 1 and 9. Store the result in the variable `x`. Now you can create a list with a list comprehension, which stores the Lp norm of the vector `vec` for every value in x. You can call this list `y`. Then you can import `matplotlib.pyplot as plt` and create the plot with `plt.plot(x,y)`.",
    "hint_counter": 2,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f23406be940>]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vec = [2, 1]\n",
    "x = range(1,10)\n",
    "y = [lp_norm(vec, i) for i in x]\n",
    "\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Your plot should look something like this:\n\n\n![Lp norms](00-02-04-pic5.png)\n\n\nFor $p=1$ we get the sum of the all the component values. $3$ appears multiple times here. For $p=2$ we get the Euclidean length of the vector. This is always smaller or equal to the $p=1$ norm. This is a consequence of the triangle inequality. The case in two dimensions is an illustrative example. If we look at any vector with coordinates $[x,y]$, we can imagine it as the vector sum of the two vectors $[x,0]$ and $[0,y]$. The three vectors then form a right-angled triangle (see picture). \n\n![Lp norms 2](00-02-04-pic6.png)\n\nThe two short sides each have a length $|x|$ and $|y|$, whereas the hypotenuse has a length of $\\sqrt{|x|^2+|y|^2}$. And it is $|x|+|y|\\ge \\sqrt{|x|^2+|y|^2}$, and $L^1([x,y])\\ge L^2([x,y])$ accordingly. In fact, the $L^p$ norms for a fixed vector all decrease monotonously with increasing $p$, which we can see well in the graph above. We can also identify that the standards for an increasing $p$ approach the value $2$. This is no coincidence, because for $p=\\infty$, the $L^p$ norm changes into the Chebyshev distance. This assigns the amount of the largest component in terms of amount to a vector.\n",
    "selectable": false
   },
   "source": [
    "Your plot should look something like this:\n",
    "\n",
    "\n",
    "![Lp norms](00-02-04-pic5.png)\n",
    "\n",
    "\n",
    "For $p=1$ we get the sum of the all the component values. $3$ appears multiple times here. For $p=2$ we get the Euclidean length of the vector. This is always smaller or equal to the $p=1$ norm. This is a consequence of the triangle inequality. The case in two dimensions is an illustrative example. If we look at any vector with coordinates $[x,y]$, we can imagine it as the vector sum of the two vectors $[x,0]$ and $[0,y]$. The three vectors then form a right-angled triangle (see picture). \n",
    "\n",
    "![Lp norms 2](00-02-04-pic6.png)\n",
    "\n",
    "The two short sides each have a length $|x|$ and $|y|$, whereas the hypotenuse has a length of $\\sqrt{|x|^2+|y|^2}$. And it is $|x|+|y|\\ge \\sqrt{|x|^2+|y|^2}$, and $L^1([x,y])\\ge L^2([x,y])$ accordingly. In fact, the $L^p$ norms for a fixed vector all decrease monotonously with increasing $p$, which we can see well in the graph above. We can also identify that the standards for an increasing $p$ approach the value $2$. This is no coincidence, because for $p=\\infty$, the $L^p$ norm changes into the Chebyshev distance. This assigns the amount of the largest component in terms of amount to a vector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "In our example `vec=[2,1]` this is just $2$.\n",
    "selectable": true
   },
   "source": [
    "In our example `vec=[2,1]` this is just $2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "merke",
    "original-content": "**Remember:**\n* Calculate the distance between two vectors with the L2 norm with `norm(my_array_1 - my_array_2)`\n* Metrics and norms are associated with distances\n* These can be used as a measure for similarly\n* Use *docstrings* and function tests for your own functions\n",
    "selectable": true
   },
   "source": [
    "**Remember:**\n",
    "* Calculate the distance between two vectors with the L2 norm with `norm(my_array_1 - my_array_2)`\n",
    "* Metrics and norms are associated with distances\n",
    "* These can be used as a measure for similarly\n",
    "* Use *docstrings* and function tests for your own functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "***\nDo you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n***\nFound a mistake? Contact Support at support@stackfuel.com.\n***\nThe data was published here first: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\nModeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009. \n***\n",
    "selectable": false
   },
   "source": [
    "***\n",
    "Do you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n",
    "***\n",
    "Found a mistake? Contact Support at support@stackfuel.com.\n",
    "***\n",
    "The data was published here first: P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009. \n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "content_id": "002a8e88-a6ac-4094-8a45-aecba0785749",
  "content_language": "en",
  "content_title": "Measuring Distances with Norms and Metrics",
  "content_type": "exercise",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
