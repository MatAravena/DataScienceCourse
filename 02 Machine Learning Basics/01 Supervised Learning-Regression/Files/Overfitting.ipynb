{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "# Too Many Features: Overfitting (Solution)\nModule 1 | Chapter 1 | Notebook 7\n\n***\nIf you give a machine learning model too much freedom to learn, then it learns the data by heart, so to speak, and and can no longer be used to make good predictions. If there are too many free parameters that are adapted to the data, this is called overfitting. Every slope in a linear regression model is a parameter in this way. You'll learn exactly what this is all about in this lesson. By the end of this exercise you will be able to:\n* Detect overfitting\n* Avoid overfitting\n***\n",
    "selectable": false
   },
   "source": [
    "# Too Many Features: Overfitting\n",
    "Module 1 | Chapter 1 | Notebook 7\n",
    "\n",
    "***\n",
    "If you give a machine learning model too much freedom to learn, then it learns the data by heart, so to speak, and and can no longer be used to make good predictions. If there are too many free parameters that are adapted to the data, this is called overfitting. Every slope in a linear regression model is a parameter in this way. You'll learn exactly what this is all about in this lesson. By the end of this exercise you will be able to:\n",
    "* Detect overfitting\n",
    "* Avoid overfitting\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## Creating a Baseline Model\n",
    "selectable": false
   },
   "source": [
    "## Creating a Baseline Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "szenario",
    "original-content": "**Scenario:** A Taiwanese investor comes to you to find out how much his properties in Taiwan are actually worth. He might want to resell them. The data on the houses is located in *Taiwan_real_estate_prediction_data.xlsx*. \n\nHe looked at your prediction based on the proximity to the nearest metro station and/or on the age of the house.  He would now like a prediction based on all the features we have. Is this kind of multiple linear regression model the best? The training data is in *Taiwan_real_estate_training_data.xlsx*.\n",
    "selectable": true
   },
   "source": [
    "**Scenario:** A Taiwanese investor comes to you to find out how much his properties in Taiwan are actually worth. He might want to resell them. The data on the houses is located in *Taiwan_real_estate_prediction_data.xlsx*. \n",
    "\n",
    "He looked at your prediction based on the proximity to the nearest metro station and/or on the age of the house.  He would now like a prediction based on all the features we have. Is this kind of multiple linear regression model the best? The training data is in *Taiwan_real_estate_training_data.xlsx*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "In order to get started quickly, let's import the data and process it like we did in the last lesson.\n",
    "selectable": false
   },
   "source": [
    "In order to get started quickly, let's import the data and process it like we did in the last lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_content_type": "code_demo",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "If you would like, you can discuss this in the forum under *Too Many Features: Overfitting*.",
    "original-content": "import pandas as pd\ndf = pd.read_excel('Taiwan_real_estate_training_data.xlsx', index_col='No')\ncol_names = ['house_age', \n              'metro_distance', \n              'number_convenience_stores', \n              'number_parking_spaces',\n              'air_pollution',\n              'light_pollution',\n              'noise_pollution',\n              'neighborhood_quality',\n              'crime_score',\n              'energy_consumption',\n              'longitude', \n              'price_per_ping']\ndf.columns = col_names\ndf.loc[:, 'price_per_m2'] = df.loc[:, 'price_per_ping'] / 3.3",
    "selectable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Taiwan_real_estate_training_data.xlsx', index_col='No')\n",
    "col_names = ['house_age', \n",
    "              'metro_distance', \n",
    "              'number_convenience_stores', \n",
    "              'number_parking_spaces',\n",
    "              'air_pollution',\n",
    "              'light_pollution',\n",
    "              'noise_pollution',\n",
    "              'neighborhood_quality',\n",
    "              'crime_score',\n",
    "              'energy_consumption',\n",
    "              'longitude', \n",
    "              'price_per_ping']\n",
    "df.columns = col_names\n",
    "df.loc[:, 'price_per_m2'] = df.loc[:, 'price_per_ping'] / 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "The data dictionary for this data is as follows:\n\nColumn number | Column name       | Type      | Description\n ------------ | ---     | :---------:           | ------------:\n0              | `'house_age'` | continuous (`float`) | age of the house in years\n1              | `'metro_distance'` | continuous (`float`) | distance in meters to the next metro station\n2              | `'number_convenience_stores'` | continuous (`int`) | Number of convenience stores nearby\n3              | `'number_parking_spaces'` | continuous (`int`) | Number of parking spaces nearby\n4              | `'air_pollution'` | continuous (`float`) | Air pollution value near the house\n5              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n6              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n7              | `'neighborhood_quality'` | continuous (`float`) | average quality of life in the neighborhood\n8              | `'crime_score'` | continuous (`float`) | crime score according to police\n9              | `'energy_consumption'` | continuous (`float`) | The property's energy consumption\n10              | `'longitude'` | continuous (`float`) | The property's longitude\n11              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per ping, one ping is 3.3 m²\n12              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per m²\n",
    "selectable": true
   },
   "source": [
    "The data dictionary for this data is as follows:\n",
    "\n",
    "Column number | Column name       | Type      | Description\n",
    " ------------ | ---     | :---------:           | ------------:\n",
    "0              | `'house_age'` | continuous (`float`) | age of the house in years\n",
    "1              | `'metro_distance'` | continuous (`float`) | distance in meters to the next metro station\n",
    "2              | `'number_convenience_stores'` | continuous (`int`) | Number of convenience stores nearby\n",
    "3              | `'number_parking_spaces'` | continuous (`int`) | Number of parking spaces nearby\n",
    "4              | `'air_pollution'` | continuous (`float`) | Air pollution value near the house\n",
    "5              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n",
    "6              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n",
    "7              | `'neighborhood_quality'` | continuous (`float`) | average quality of life in the neighborhood\n",
    "8              | `'crime_score'` | continuous (`float`) | crime score according to police\n",
    "9              | `'energy_consumption'` | continuous (`float`) | The property's energy consumption\n",
    "10              | `'longitude'` | continuous (`float`) | The property's longitude\n",
    "11              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per ping, one ping is 3.3 m²\n",
    "12              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per m²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Now let's get straight to the real estate investor's request. Use a multiple linear regression model to predict property prices based on the following features:\n```python\n['house_age',\n 'metro_distance', \n 'number_convenience_stores', \n 'number_parking_spaces',\n 'air_pollution',\n 'light_pollution',\n 'noise_pollution',\n 'neighborhood_quality',\n 'crime_score',\n 'energy_consumption',\n 'longitude']\n```\nSave the feature matrix in `features_multiple_all`. Store the model in `model_multiple_all`. Print the slopes and intercept.\n",
    "selectable": true
   },
   "source": [
    "Now let's get straight to the real estate investor's request. Use a multiple linear regression model to predict property prices based on the following features:\n",
    "```python\n",
    "['house_age',\n",
    " 'metro_distance', \n",
    " 'number_convenience_stores', \n",
    " 'number_parking_spaces',\n",
    " 'air_pollution',\n",
    " 'light_pollution',\n",
    " 'noise_pollution',\n",
    " 'neighborhood_quality',\n",
    " 'crime_score',\n",
    " 'energy_consumption',\n",
    " 'longitude']\n",
    "```\n",
    "Save the feature matrix in `features_multiple_all`. Store the model in `model_multiple_all`. Print the slopes and intercept.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Follow the first four of the five steps you learned in *Simple Linear Regression with sklearn*. Start with `from sklearn.linear_model import LinearRegression`. End with `print('Intercept: ', model_multiple_all.intercept_)`.",
    "original-content": "",
    "selectable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope:  [ -0.08080605  -0.00157327   0.58572668  -0.02730774  -0.00143356\n",
      "   0.00496967  -0.02051466   2.27005373  -0.15999745  -0.00045578\n",
      " -31.99795736]\n",
      "Intercept:  3901.708990997849\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_multiple_all = LinearRegression()\n",
    "\n",
    "features_multiple_all = df.loc[:, ['house_age',\n",
    " 'metro_distance', \n",
    " 'number_convenience_stores', \n",
    " 'number_parking_spaces',\n",
    " 'air_pollution',\n",
    " 'light_pollution',\n",
    " 'noise_pollution',\n",
    " 'neighborhood_quality',\n",
    " 'crime_score',\n",
    " 'energy_consumption',\n",
    " 'longitude']]\n",
    "target = df.loc[:,'price_per_m2']\n",
    "model_multiple_all.fit( features_multiple_all, target)\n",
    "\n",
    "\n",
    "import numpy as np; np.set_printoptions(suppress=True)  # suppress scientific notation for ease of interpretation\n",
    "print('Slope: ', model_multiple_all.coef_)  # beta (slope)\n",
    "print('Intercept: ', model_multiple_all.intercept_)  # intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "We end up with the following regression formula:\n\n\\begin{equation*}\nhouse price\\, \\ per\\, \\ m² = 3902 - (0.081 \\cdot house age) - (0.002 \\cdot metro distance) + (0.586 \\cdot number \\, food stores) - (0.03 \\cdot number \\, parking spaces) - (0.001 \\cdot air pollution value) + (0.005 \\cdot light pollution value) - (0.02 \\cdot noise pollution value) + (2.27 \\cdot neighborhood value) - (0.16 \\cdot crime value) - (0.0005 \\cdot energy consumption) - (32.00 \\cdot latitude)\n\\end{equation*}\n\nHow good is this kind of large multiple linear regression model? Calculate the mean squared error (*mean squared error*), the RMSE (*rooted mean squared error*) and the coefficient of determination (*R²*)\n",
    "selectable": false
   },
   "source": [
    "We end up with the following regression formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "house price\\, \\ per\\, \\ m² = 3902 - (0.081 \\cdot house age) - (0.002 \\cdot metro distance) + (0.586 \\cdot number \\, food stores) - (0.03 \\cdot number \\, parking spaces) - (0.001 \\cdot air pollution value) + (0.005 \\cdot light pollution value) - (0.02 \\cdot noise pollution value) + (2.27 \\cdot neighborhood value) - (0.16 \\cdot crime value) - (0.0005 \\cdot energy consumption) - (32.00 \\cdot latitude)\n",
    "\\end{equation*}\n",
    "\n",
    "How good is this kind of large multiple linear regression model? Calculate the mean squared error (*mean squared error*), the RMSE (*rooted mean squared error*) and the coefficient of determination (*R²*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Start by importing the relevant functions from the `sklearn.metrics` module. Then calculate which house prices the model predicts: `target_pred = model_multiple_all.predict(features_multiple_all)`. You can then use these values to determine the the model quality metric.",
    "original-content": "",
    "selectable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  7.766393941469823\n",
      "RMSE:  2.786825064741205\n",
      "R2:  0.565862831083511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "target_pred = model_multiple_all.predict(features_multiple_all)\n",
    "print('MSE: ', mean_squared_error(target, target_pred))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(target, target_pred)))\n",
    "print('R2: ', r2_score(target, target_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "The values look very good. If we compare them with the model quality metrics calculated so far, it becomes apparent that this model is better than all the others.\n\nModel| MSE| *R²*\n---|---|---\n`model_age`| 16.97 | 5.1%\n`model_metro`| 10.07 | 43.6%\n`model_stores`| 12.21 | 31.8% \n`model_multiple`| 9.34 | 47.8% \n`model_multiple_all`| 7.76 | 56.6%\n",
    "selectable": true
   },
   "source": [
    "The values look very good. If we compare them with the model quality metrics calculated so far, it becomes apparent that this model is better than all the others.\n",
    "\n",
    "Model| MSE| *R²*\n",
    "---|---|---\n",
    "`model_age`| 16.97 | 5.1%\n",
    "`model_metro`| 10.07 | 43.6%\n",
    "`model_stores`| 12.21 | 31.8% \n",
    "`model_multiple`| 9.34 | 47.8% \n",
    "`model_multiple_all`| 7.76 | 56.6%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "We will use this model as the *baseline model*. It will be a guide as to whether our optimization steps are taking us in the right direction.\n",
    "selectable": false
   },
   "source": [
    "We will use this model as the *baseline model*. It will be a guide as to whether our optimization steps are taking us in the right direction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "glueckwunsch",
    "original-content": "**Congratulations:** The large multiple linear regression model looks very good according to the model quality metrics. As data scientists, we are particularly interested in the how accurate our model's predictions are. In general, you shouldn't evaluate your model with the same data the algorithm used to learn. Now you'll see why.\n",
    "selectable": false
   },
   "source": [
    "**Congratulations:** The large multiple linear regression model looks very good according to the model quality metrics. As data scientists, we are particularly interested in the how accurate our model's predictions are. In general, you shouldn't evaluate your model with the same data the algorithm used to learn. Now you'll see why.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## Independent test data\n",
    "selectable": false
   },
   "source": [
    "## Independent test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "szenario",
    "original-content": "**Scenario:** The Taiwanese investor doesn't completely trust the large multiple linear regression model. He also put some data to one side to use for a test. You weren't able to use this data during the training phase. How well our model can predict this test data will now be the deciding factor in which model is the most reliable. The test data is stored in *Taiwan_real_estate_test_data.xlsx*.\n",
    "selectable": true
   },
   "source": [
    "**Scenario:** The Taiwanese investor doesn't completely trust the large multiple linear regression model. He also put some data to one side to use for a test. You weren't able to use this data during the training phase. How well our model can predict this test data will now be the deciding factor in which model is the most reliable. The test data is stored in *Taiwan_real_estate_test_data.xlsx*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "First import *Taiwan_real_estate_test_data.xlsx* and store the data in `df_test`. Calculate the `'price_per_m2'` column using the following formula:\n\n\\begin{equation*}\nHouse price\\, \\ per\\, \\ square\\,meter = \\frac{House price\\, \\ per\\, \\ ping}{3,3}\n\\end{equation*}\n\nand add it to `df_test`. Then print the first 5 rows (all columns) of `df_test`.\n\nTip: Use the `'No'` column as the row name column again. Rename the columns just like you did with `df` by using `col_names`.\n",
    "selectable": true
   },
   "source": [
    "First import *Taiwan_real_estate_test_data.xlsx* and store the data in `df_test`. Calculate the `'price_per_m2'` column using the following formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "House price\\, \\ per\\, \\ square\\,meter = \\frac{House price\\, \\ per\\, \\ ping}{3,3}\n",
    "\\end{equation*}\n",
    "\n",
    "and add it to `df_test`. Then print the first 5 rows (all columns) of `df_test`.\n",
    "\n",
    "Tip: Use the `'No'` column as the row name column again. Rename the columns just like you did with `df` by using `col_names`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Use the first code cell from this lesson as a guide.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_age</th>\n",
       "      <th>metro_distance</th>\n",
       "      <th>number_convenience_stores</th>\n",
       "      <th>number_parking_spaces</th>\n",
       "      <th>air_pollution</th>\n",
       "      <th>light_pollution</th>\n",
       "      <th>noise_pollution</th>\n",
       "      <th>neighborhood_quality</th>\n",
       "      <th>crime_score</th>\n",
       "      <th>energy_consumption</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price_per_ping</th>\n",
       "      <th>price_per_m2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>3.7</td>\n",
       "      <td>577.9615</td>\n",
       "      <td>6</td>\n",
       "      <td>108</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>1.099596</td>\n",
       "      <td>146.430378</td>\n",
       "      <td>0.485457</td>\n",
       "      <td>0.556433</td>\n",
       "      <td>103.639798</td>\n",
       "      <td>121.54722</td>\n",
       "      <td>41.6</td>\n",
       "      <td>12.606061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>15.6</td>\n",
       "      <td>1756.4110</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>1607.727683</td>\n",
       "      <td>1.456661</td>\n",
       "      <td>229.970916</td>\n",
       "      <td>0.390628</td>\n",
       "      <td>0.850871</td>\n",
       "      <td>56.356143</td>\n",
       "      <td>121.51812</td>\n",
       "      <td>27.3</td>\n",
       "      <td>8.272727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>13.3</td>\n",
       "      <td>250.6310</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>34.689814</td>\n",
       "      <td>6.098307</td>\n",
       "      <td>273.824975</td>\n",
       "      <td>0.631295</td>\n",
       "      <td>0.762503</td>\n",
       "      <td>93.381480</td>\n",
       "      <td>121.54297</td>\n",
       "      <td>42.0</td>\n",
       "      <td>12.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>15.6</td>\n",
       "      <td>752.7669</td>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>492.150645</td>\n",
       "      <td>0.071399</td>\n",
       "      <td>124.359973</td>\n",
       "      <td>0.526502</td>\n",
       "      <td>0.852945</td>\n",
       "      <td>92.024473</td>\n",
       "      <td>121.53451</td>\n",
       "      <td>37.5</td>\n",
       "      <td>11.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>7.1</td>\n",
       "      <td>379.5575</td>\n",
       "      <td>10</td>\n",
       "      <td>123</td>\n",
       "      <td>253.417158</td>\n",
       "      <td>7.865223</td>\n",
       "      <td>185.210828</td>\n",
       "      <td>0.403618</td>\n",
       "      <td>0.910539</td>\n",
       "      <td>52.222489</td>\n",
       "      <td>121.53762</td>\n",
       "      <td>49.8</td>\n",
       "      <td>15.090909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     house_age  metro_distance  number_convenience_stores  \\\n",
       "No                                                          \n",
       "315        3.7        577.9615                          6   \n",
       "316       15.6       1756.4110                          2   \n",
       "317       13.3        250.6310                          7   \n",
       "318       15.6        752.7669                          2   \n",
       "319        7.1        379.5575                         10   \n",
       "\n",
       "     number_parking_spaces  air_pollution  light_pollution  noise_pollution  \\\n",
       "No                                                                            \n",
       "315                    108     480.000000         1.099596       146.430378   \n",
       "316                     54    1607.727683         1.456661       229.970916   \n",
       "317                     83      34.689814         6.098307       273.824975   \n",
       "318                     63     492.150645         0.071399       124.359973   \n",
       "319                    123     253.417158         7.865223       185.210828   \n",
       "\n",
       "     neighborhood_quality  crime_score  energy_consumption  longitude  \\\n",
       "No                                                                      \n",
       "315              0.485457     0.556433          103.639798  121.54722   \n",
       "316              0.390628     0.850871           56.356143  121.51812   \n",
       "317              0.631295     0.762503           93.381480  121.54297   \n",
       "318              0.526502     0.852945           92.024473  121.53451   \n",
       "319              0.403618     0.910539           52.222489  121.53762   \n",
       "\n",
       "     price_per_ping  price_per_m2  \n",
       "No                                 \n",
       "315            41.6     12.606061  \n",
       "316            27.3      8.272727  \n",
       "317            42.0     12.727273  \n",
       "318            37.5     11.363636  \n",
       "319            49.8     15.090909  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_excel('Taiwan_real_estate_test_data.xlsx', index_col='No')\n",
    "df_test.columns = col_names\n",
    "df_test.loc[:, 'price_per_m2'] = df_test.loc[:, 'price_per_ping'] / 3.3\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "`df_test` now contains data which is very similar to the data in `df` in principle. Does `model_multiple_all` manage to predict the values in the `'price_per_m2'` column of `df_test` well? Create a feature matrix `features_test` and a target vector `target_test` to test it.\n",
    "selectable": true
   },
   "source": [
    "`df_test` now contains data which is very similar to the data in `df` in principle. Does `model_multiple_all` manage to predict the values in the `'price_per_m2'` column of `df_test` well? Create a feature matrix `features_test` and a target vector `target_test` to test it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Make sure that `features_test` and `target_test` contain data from `df_test`, e.g. `target_test = df_test.loc[:, 'price_per_m2']`. In addition, `features_test` should contain as many features as `features_multiple_all`.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_test = df_test.loc[:, ['house_age',\n",
    " 'metro_distance', \n",
    " 'number_convenience_stores', \n",
    " 'number_parking_spaces',\n",
    " 'air_pollution',\n",
    " 'light_pollution',\n",
    " 'noise_pollution',\n",
    " 'neighborhood_quality',\n",
    " 'crime_score',\n",
    " 'energy_consumption',\n",
    " 'longitude']]\n",
    "target_test = df_test.loc[:,'price_per_m2']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Now use `model_multiple_all` together with its `my_model.predict()` method and `features_test` to predict house prices. Assign this to `target_test_pred`. You should then compare these with the actual house prices from the test data set, which are in `target_test`. Use the *mean squared error*, the *RMSE* and *R²*.\n",
    "selectable": true
   },
   "source": [
    "Now use `model_multiple_all` together with its `my_model.predict()` method and `features_test` to predict house prices. Assign this to `target_test_pred`. You should then compare these with the actual house prices from the test data set, which are in `target_test`. Use the *mean squared error*, the *RMSE* and *R²*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "First calculate `target_test_pred` like this: `target_test_pred = model_multiple_all.predict(features_test)`",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.76765041220873\n",
      "5.636279837996756\n",
      "-1.4015802907439143\n"
     ]
    }
   ],
   "source": [
    "target_pred_test = model_multiple_all.predict(features_test)\n",
    "\n",
    "print(mean_squared_error(target_test, target_pred_test))\n",
    "print(np.sqrt(mean_squared_error(target_test, target_pred_test)))\n",
    "print(r2_score(target_test, target_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "These values are extraordinarily bad. The predicted house prices in the test data set  are $\\sqrt{31.77}$, i.e. 5.64 dollars per square meter, off target on average. The coefficient of determination is below zero. This means that the average price of of the houses without any kind of distinction provides a better prediction than this complicated model.\n\nCould this be due to the test data itself? Maybe it's the data that's incorrect?  It's best to try out how well `model_multiple` predicts the data with the features `'house_age'` and `'metro_distance'`. Instantiate the model, fit it to the **training data set** in `fd` and then calculate the *mean squared error* and *R²* quality metrics using the **test data set** in `df_test`.\n",
    "selectable": true
   },
   "source": [
    "These values are extraordinarily bad. The predicted house prices in the test data set  are $\\sqrt{31.77}$, i.e. 5.64 dollars per square meter, off target on average. The coefficient of determination is below zero. This means that the average price of of the houses without any kind of distinction provides a better prediction than this complicated model.\n",
    "\n",
    "Could this be due to the test data itself? Maybe it's the data that's incorrect?  It's best to try out how well `model_multiple` predicts the data with the features `'house_age'` and `'metro_distance'`. Instantiate the model, fit it to the **training data set** in `fd` and then calculate the *mean squared error* and *R²* quality metrics using the **test data set** in `df_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "The feature matrix should now be defined like this: `features_multiple = df.loc[:, ['house_age', 'metro_distance']]`. You can reuse the variables `target` and `target_test`.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  9.719702133987989\n",
      "RMSE:  3.117643682974048\n",
      "R2:  0.2652070652377795\n"
     ]
    }
   ],
   "source": [
    "model_multiple = LinearRegression()\n",
    "\n",
    "features_multiple = df.loc[:, ['house_age', 'metro_distance']]\n",
    "features_test_multiple = df_test.loc[:, ['house_age', 'metro_distance']]\n",
    "\n",
    "model_multiple.fit(features_multiple, target)\n",
    "\n",
    "target_test_pred_multiple = model_multiple.predict(features_test_multiple)\n",
    "\n",
    "print('MSE: ', mean_squared_error(target_test, target_test_pred_multiple))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(target_test, target_test_pred_multiple)))\n",
    "print('R2: ', r2_score(target_test, target_test_pred_multiple))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "`model_multiple` is much better at predicting the test data. For example, the mean square error is now only 9.72. So the forecasts are only off by an average of $3.12 per square meter. \n\nNow we can evaluate the performance of all previous models based on the test data in a similar way.\n",
    "selectable": true
   },
   "source": [
    "`model_multiple` is much better at predicting the test data. For example, the mean square error is now only 9.72. So the forecasts are only off by an average of $3.12 per square meter. \n",
    "\n",
    "Now we can evaluate the performance of all previous models based on the test data in a similar way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_content_type": "code_demo",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "If you would like, you can discuss this in the forum under *Too Many Features: Overfitting*.",
    "original-content": "features_cols = {'model_age' : ['house_age'],  # model_age\n                 'model_metro' : ['metro_distance'],  # model_metro\n                 'model_stores' : ['number_convenience_stores'],  # model_stores\n                 'model_multiple' : ['house_age', 'metro_distance'],  # model_multiple\n                 'model_multiple_all' : df.columns[:-2]}  # model_multiple_all\n\nfor name, features_col in features_cols.items():\n    print(name)\n    print('---------------------')\n    print('Features: ', features_col)\n    \n    model_tmp = LinearRegression()\n    \n    features_tmp = df.loc[:, features_col]\n\n    model_tmp.fit(features_tmp, target)\n    \n    features_test_tmp = df_test.loc[:, features_col]\n    \n    target_test_pred_tmp = model_tmp.predict(features_test_tmp)    \n    print('MSE: ', mean_squared_error(target_test, target_test_pred_tmp))\n    print('R2: ', r2_score(target_test, target_test_pred_tmp), '\\n')\n    ",
    "selectable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_age\n",
      "---------------------\n",
      "Features:  ['house_age']\n",
      "MSE:  11.890328785593141\n",
      "R2:  0.10111138559459787 \n",
      "\n",
      "model_metro\n",
      "---------------------\n",
      "Features:  ['metro_distance']\n",
      "MSE:  10.268754788766552\n",
      "R2:  0.2236996192294317 \n",
      "\n",
      "model_stores\n",
      "---------------------\n",
      "Features:  ['number_convenience_stores']\n",
      "MSE:  11.286542007618975\n",
      "R2:  0.1467566381385902 \n",
      "\n",
      "model_multiple\n",
      "---------------------\n",
      "Features:  ['house_age', 'metro_distance']\n",
      "MSE:  9.719702133987989\n",
      "R2:  0.2652070652377795 \n",
      "\n",
      "model_multiple_all\n",
      "---------------------\n",
      "Features:  Index(['house_age', 'metro_distance', 'number_convenience_stores',\n",
      "       'number_parking_spaces', 'air_pollution', 'light_pollution',\n",
      "       'noise_pollution', 'neighborhood_quality', 'crime_score',\n",
      "       'energy_consumption', 'longitude'],\n",
      "      dtype='object')\n",
      "MSE:  31.76765041220873\n",
      "R2:  -1.4015802907439143 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_cols = {'model_age' : ['house_age'],  # model_age\n",
    "                 'model_metro' : ['metro_distance'],  # model_metro\n",
    "                 'model_stores' : ['number_convenience_stores'],  # model_stores\n",
    "                 'model_multiple' : ['house_age', 'metro_distance'],  # model_multiple\n",
    "                 'model_multiple_all' : df.columns[:-2]}  # model_multiple_all\n",
    "\n",
    "for name, features_col in features_cols.items():\n",
    "    print(name)\n",
    "    print('---------------------')\n",
    "    print('Features: ', features_col)\n",
    "    \n",
    "    model_tmp = LinearRegression()\n",
    "    \n",
    "    features_tmp = df.loc[:, features_col]\n",
    "\n",
    "    model_tmp.fit(features_tmp, target)\n",
    "    \n",
    "    features_test_tmp = df_test.loc[:, features_col]\n",
    "    \n",
    "    target_test_pred_tmp = model_tmp.predict(features_test_tmp)    \n",
    "    print('MSE: ', mean_squared_error(target_test, target_test_pred_tmp))\n",
    "    print('R2: ', r2_score(target_test, target_test_pred_tmp), '\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Looking at the performance of the other models we have worked with so far, we get the following table:\n\nModel| Training: MSE| Training: *R²* | Test: MSE | Test: *R²*\n---|---|---|---|---\n`model_age`| 16.97 | 5.1% | 11.89 | 10.1%\n`model_metro`| 10.07 | 43.6%`| 10.07 | 22.4%\n`model_stores`| 12.21 | 31.8%`| 11.29 | 14.7%\n`model_multiple`| 9.34 | 47.8% | 9.72 | 26.5%\n`model_multiple_all`| 7.76 | 56.6% | 31.77 | -140.2%\n",
    "selectable": true
   },
   "source": [
    "Looking at the performance of the other models we have worked with so far, we get the following table:\n",
    "\n",
    "Model| Training: MSE| Training: *R²* | Test: MSE | Test: *R²*\n",
    "---|---|---|---|---\n",
    "`model_age`| 16.97 | 5.1% | 11.89 | 10.1%\n",
    "`model_metro`| 10.07 | 43.6%`| 10.07 | 22.4%\n",
    "`model_stores`| 12.21 | 31.8%`| 11.29 | 14.7%\n",
    "`model_multiple`| 9.34 | 47.8% | 9.72 | 26.5%\n",
    "`model_multiple_all`| 7.76 | 56.6% | 31.77 | -140.2%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "With one exception (`model_age`), the trained models seem to predict the **training data** better than the **test data**. Compared to the test data, the *mean squared error* is generally smaller for the training data, while the coefficient of determination is larger for the training data. So almost all models perform better with the data they had available to train with.\n\nA closer look, however, also shows that for relatively simple models (all of them except `model_multiple_all`) a model gets a better score on test data, if it was also able to make better predictions with the training data than the other models. For both the training data and the test data, `model_multiple` performs better than `model_metro`, which in turn makes better predictions than `model_stores`.\n\nIf you only look at the relatively simple models with less than 3 features, you might think that more features lead to better predictions. For models with few features, this statement is true for predicting training data as well as predicting test data. \n\nYou only start to see a discrepancy between training data and test data when you start using a lot of features. A model with many features can only predict the training data it trained with well. If you give it independent new test data, it is totally overwhelmed. **[Overfitting](https://en.wikipedia.org/wiki/Overfitting) describes the state of a machine learning model, which predicts training data much better than test data.**\n",
    "selectable": true
   },
   "source": [
    "With one exception (`model_age`), the trained models seem to predict the **training data** better than the **test data**. Compared to the test data, the *mean squared error* is generally smaller for the training data, while the coefficient of determination is larger for the training data. So almost all models perform better with the data they had available to train with.\n",
    "\n",
    "A closer look, however, also shows that for relatively simple models (all of them except `model_multiple_all`) a model gets a better score on test data, if it was also able to make better predictions with the training data than the other models. For both the training data and the test data, `model_multiple` performs better than `model_metro`, which in turn makes better predictions than `model_stores`.\n",
    "\n",
    "If you only look at the relatively simple models with less than 3 features, you might think that more features lead to better predictions. For models with few features, this statement is true for predicting training data as well as predicting test data. \n",
    "\n",
    "You only start to see a discrepancy between training data and test data when you start using a lot of features. A model with many features can only predict the training data it trained with well. If you give it independent new test data, it is totally overwhelmed. **[Overfitting](https://en.wikipedia.org/wiki/Overfitting) describes the state of a machine learning model, which predicts training data much better than test data.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "glueckwunsch",
    "original-content": "**Congratulations:** You have learned about the basic problem of overfitting. This will accompany us throughout the entire course, because all supervised learning algorithms can fall victim to overfitting. But before we turn to a possible strategy to avoid overfitting in linear regression models in the next lesson, let's take a look at the optimal number of features in our case. At what point do many features become too many features?\n",
    "selectable": false
   },
   "source": [
    "**Congratulations:** You have learned about the basic problem of overfitting. This will accompany us throughout the entire course, because all supervised learning algorithms can fall victim to overfitting. But before we turn to a possible strategy to avoid overfitting in linear regression models in the next lesson, let's take a look at the optimal number of features in our case. At what point do many features become too many features?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## The bias-variance trade-off\n",
    "selectable": false
   },
   "source": [
    "## The bias-variance trade-off\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "To explain *overfitting*, it can help to think of machine learning models as a trade-off between *bias* and *variance*. *bias* describes the average prediction error across different training datasets. A model with a very high *bias* hardly changes when the training data changes. \n\n*Variance* is exactly the opposite, *Variance* describes how sensitively the model reacts to changes in the training data set. A model with a very high *variance* changes a lot when the training data changes.\n\nTo illustrate bias and variance, imagine that our model's predictions represent the attempt to hit the center of a dartboard. Where the middle of the board represents the actual value to be predicted.\n\n<img src=\"01_01_07_pic1_biasVarianceTradeoff_en.png\" width=350>\n\nIn general, simpler models have a large *bias* and a small *variance*, whereas very complicated models have a small *bias* and a very large *variance*. In general, data scientist want to train models in such a way that they can learn the training data well (small *bias*) and then make predictions well for new data well (small *variance*).\n\nTo minimize both *bias* and *variance*, you need models that are neither simple (simple models have high *bias*) nor complex (complex models have high *variance*). So somewhere in the middle there is a model that is \"medium complex\". This model learns the training data well but it does not learn it completely by heart. This model can then optimally apply this knowledge to test data.\n\nLet's see if we can find this this optimal model that strikes that balance. The following code cell calculates the coefficient of determination of the training and test data for twelve regression models. With each iteration of the `for` loop, the regression model becomes more complex. In the beginning it contains only the first feature (`'house_age'`), then the first two (`['house_age', 'metro_distance']`) and so on. The resulting quality metrics are stored in the `DataFrame` `R2`.\n",
    "selectable": true
   },
   "source": [
    "To explain *overfitting*, it can help to think of machine learning models as a trade-off between *bias* and *variance*. *bias* describes the average prediction error across different training datasets. A model with a very high *bias* hardly changes when the training data changes. \n",
    "\n",
    "*Variance* is exactly the opposite, *Variance* describes how sensitively the model reacts to changes in the training data set. A model with a very high *variance* changes a lot when the training data changes.\n",
    "\n",
    "To illustrate bias and variance, imagine that our model's predictions represent the attempt to hit the center of a dartboard. Where the middle of the board represents the actual value to be predicted.\n",
    "\n",
    "<img src=\"01_01_07_pic1_biasVarianceTradeoff_en.png\" width=350>\n",
    "\n",
    "In general, simpler models have a large *bias* and a small *variance*, whereas very complicated models have a small *bias* and a very large *variance*. In general, data scientist want to train models in such a way that they can learn the training data well (small *bias*) and then make predictions well for new data well (small *variance*).\n",
    "\n",
    "To minimize both *bias* and *variance*, you need models that are neither simple (simple models have high *bias*) nor complex (complex models have high *variance*). So somewhere in the middle there is a model that is \"medium complex\". This model learns the training data well but it does not learn it completely by heart. This model can then optimally apply this knowledge to test data.\n",
    "\n",
    "Let's see if we can find this this optimal model that strikes that balance. The following code cell calculates the coefficient of determination of the training and test data for twelve regression models. With each iteration of the `for` loop, the regression model becomes more complex. In the beginning it contains only the first feature (`'house_age'`), then the first two (`['house_age', 'metro_distance']`) and so on. The resulting quality metrics are stored in the `DataFrame` `R2`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_content_type": "code_demo",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "If you would like, you can discuss this in the forum under *Too Many Features: Overfitting*.",
    "original-content": "R2 = pd.DataFrame({'training':[],\n                  'test': []})\n\nfor i in range(1, len(df.columns)-2):  # for each feature (not target)\n    \n    print('Features: ', df.columns[:i].format())\n    \n    # instantiate model\n    model_tmp = LinearRegression()\n    \n    # feature matrix and target vector\n    features = df.loc[:, df.columns[:i]]  # feature matrix for training data\n    target = df.loc[:, 'price_per_m2']  # target vector for training data\n    \n    # model fitting\n    model_tmp.fit(features, target)\n    \n    # model predictions (training data)\n    target_pred = model_tmp.predict(features)  # predict target values of training data\n    residuals = target - target_pred  # difference between predicted and actual target values \n    \n    R2.loc[i, 'training'] = r2_score(target, target_pred)  # calculate R2-score for training data and add it to DataFrame\n    print('R2-score (training): ', round(R2.loc[i, 'training'], 3))\n\n    # model predictions (test data)\n    features_test = df_test.loc[:, df_test.columns[:i]]  # feature matrix for test data\n    target_test = df_test.loc[:, 'price_per_m2']  # target_values of test data\n    target_test_pred = model_tmp.predict(features_test)  # predict target values of test data\n\n    R2.loc[i, 'test'] = r2_score(target_test, target_test_pred)  # calculate R2-score for test data and add it to DataFrame\n    print('R2-score (test): ', round(R2.loc[i, 'test'], 3), '\\n')",
    "selectable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  ['house_age']\n",
      "R2-score (training):  0.051\n",
      "R2-score (test):  0.101 \n",
      "\n",
      "Features:  ['house_age', 'metro_distance']\n",
      "R2-score (training):  0.478\n",
      "R2-score (test):  0.265 \n",
      "\n",
      "Features:  ['house_age', 'metro_distance', 'number_convenience_stores']\n",
      "R2-score (training):  0.524\n",
      "R2-score (test):  0.352 \n",
      "\n",
      "Features:  ['house_age', 'metro_distance', 'number_convenience_stores', 'number_parking_spaces']\n",
      "R2-score (training):  0.546\n",
      "R2-score (test):  0.086 \n",
      "\n",
      "Features:  ['house_age', 'metro_distance', 'number_convenience_stores', 'number_parking_spaces', 'air_pollution']\n",
      "R2-score (training):  0.547\n",
      "R2-score (test):  0.099 \n",
      "\n",
      "Features:  ['house_age', 'metro_distance', 'number_convenience_stores', 'number_parking_spaces', 'air_pollution', 'light_pollution']\n",
      "R2-score (training):  0.554\n",
      "R2-score (test):  0.038 \n",
      "\n",
      "Features:  ['house_age', 'metro_distance', 'number_convenience_stores', 'number_parking_spaces', 'air_pollution', 'light_pollution', 'noise_pollution']\n",
      "R2-score (training):  0.557\n",
      "R2-score (test):  -1.256 \n",
      "\n",
      "Features:  ['house_age', 'metro_distance', 'number_convenience_stores', 'number_parking_spaces', 'air_pollution', 'light_pollution', 'noise_pollution', 'neighborhood_quality']\n",
      "R2-score (training):  0.562\n",
      "R2-score (test):  -1.276 \n",
      "\n",
      "Features:  ['house_age', 'metro_distance', 'number_convenience_stores', 'number_parking_spaces', 'air_pollution', 'light_pollution', 'noise_pollution', 'neighborhood_quality', 'crime_score']\n",
      "R2-score (training):  0.562\n",
      "R2-score (test):  -1.304 \n",
      "\n",
      "Features:  ['house_age', 'metro_distance', 'number_convenience_stores', 'number_parking_spaces', 'air_pollution', 'light_pollution', 'noise_pollution', 'neighborhood_quality', 'crime_score', 'energy_consumption']\n",
      "R2-score (training):  0.562\n",
      "R2-score (test):  -1.326 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "R2 = pd.DataFrame({'training':[],\n",
    "                  'test': []})\n",
    "\n",
    "for i in range(1, len(df.columns)-2):  # for each feature (not target)\n",
    "    \n",
    "    print('Features: ', df.columns[:i].format())\n",
    "    \n",
    "    # instantiate model\n",
    "    model_tmp = LinearRegression()\n",
    "    \n",
    "    # feature matrix and target vector\n",
    "    features = df.loc[:, df.columns[:i]]  # feature matrix for training data\n",
    "    target = df.loc[:, 'price_per_m2']  # target vector for training data\n",
    "    \n",
    "    # model fitting\n",
    "    model_tmp.fit(features, target)\n",
    "    \n",
    "    # model predictions (training data)\n",
    "    target_pred = model_tmp.predict(features)  # predict target values of training data\n",
    "    residuals = target - target_pred  # difference between predicted and actual target values \n",
    "    \n",
    "    R2.loc[i, 'training'] = r2_score(target, target_pred)  # calculate R2-score for training data and add it to DataFrame\n",
    "    print('R2-score (training): ', round(R2.loc[i, 'training'], 3))\n",
    "\n",
    "    # model predictions (test data)\n",
    "    features_test = df_test.loc[:, df_test.columns[:i]]  # feature matrix for test data\n",
    "    target_test = df_test.loc[:, 'price_per_m2']  # target_values of test data\n",
    "    target_test_pred = model_tmp.predict(features_test)  # predict target values of test data\n",
    "\n",
    "    R2.loc[i, 'test'] = r2_score(target_test, target_test_pred)  # calculate R2-score for test data and add it to DataFrame\n",
    "    print('R2-score (test): ', round(R2.loc[i, 'test'], 3), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Now we can visualize the coefficients of determination. The x axis describes the number of features in the linear regression model, while the y axis shows the *R²* value.\n",
    "selectable": false
   },
   "source": [
    "Now we can visualize the coefficients of determination. The x axis describes the number of features in the linear regression model, while the y axis shows the *R²* value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_content_type": "code_demo",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "If you would like, you can discuss this in the forum under *Too Many Features: Overfitting*.",
    "original-content": "R2.plot(ylim=[-1.5, 1],title=\"Vergleich Trainings- und Testscores\").set(xlabel=\"# Features\", \n                                                                     ylabel=\"$R^2$-Score\")",
    "selectable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "R2.plot(ylim=[-1.5, 1],title=\"Vergleich Trainings- und Testscores\").set(xlabel=\"# Features\", ylabel=\"$R^2$-Score\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "We see that the coefficient of determination for the prediction of training data increases with each additional feature. So if you only evaluated the models with the training data, it would look as if the model gets better with every added feature.\n\nHowever, this is not the case with the test data. First the *R²* values increase up to a model with three features. After that, however, the prediction accuracy decreases with each additional feature. So although a 10 feature model has much more information at its disposal, it does not predict the test data as well as a model with only three features.\n\nThe model with three features appears here to be the optimal compromise between *bias* and *variance*.\n\nIf you want, you can use the following code cell to use the *mean squared error* for the same exercise. As the model becomes increasingly complex, it should steadily decrease (training data), or first decrease and then increase (test data). This part of the lesson is optional. You don't have to work through it to complete this course successfully.\n",
    "selectable": false
   },
   "source": [
    "We see that the coefficient of determination for the prediction of training data increases with each additional feature. So if you only evaluated the models with the training data, it would look as if the model gets better with every added feature.\n",
    "\n",
    "However, this is not the case with the test data. First the *R²* values increase up to a model with three features. After that, however, the prediction accuracy decreases with each additional feature. So although a 10 feature model has much more information at its disposal, it does not predict the test data as well as a model with only three features.\n",
    "\n",
    "The model with three features appears here to be the optimal compromise between *bias* and *variance*.\n",
    "\n",
    "If you want, you can use the following code cell to use the *mean squared error* for the same exercise. As the model becomes increasingly complex, it should steadily decrease (training data), or first decrease and then increase (test data). This part of the lesson is optional. You don't have to work through it to complete this course successfully.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Use the previous code cell to help you solve this optional task.",
    "original-content": "",
    "selectable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE (training):  0.051\n",
      "MSE (test):  11.89 \n",
      "\n",
      "MSE (training):  0.478\n",
      "MSE (test):  9.72 \n",
      "\n",
      "MSE (training):  0.524\n",
      "MSE (test):  8.568 \n",
      "\n",
      "MSE (training):  0.546\n",
      "MSE (test):  12.084 \n",
      "\n",
      "MSE (training):  0.547\n",
      "MSE (test):  11.914 \n",
      "\n",
      "MSE (training):  0.554\n",
      "MSE (test):  12.722 \n",
      "\n",
      "MSE (training):  0.557\n",
      "MSE (test):  29.84 \n",
      "\n",
      "MSE (training):  0.562\n",
      "MSE (test):  30.11 \n",
      "\n",
      "MSE (training):  0.562\n",
      "MSE (test):  30.479 \n",
      "\n",
      "MSE (training):  0.562\n",
      "MSE (test):  30.765 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MSE = pd.DataFrame({'training':[],\n",
    "                  'test': []})\n",
    "\n",
    "for i in range(1, len(df.columns)-2):  # for each feature (not target)\n",
    "    \n",
    "    #print('Features: ', df.columns[:i].format())\n",
    "    \n",
    "    # instantiate model\n",
    "    model_tmp = LinearRegression()\n",
    "    \n",
    "    # feature matrix and target vector\n",
    "    features = df.loc[:, df.columns[:i]]  # feature matrix for training data\n",
    "    target = df.loc[:, 'price_per_m2']  # target vector for training data\n",
    "    \n",
    "    # model fitting\n",
    "    model_tmp.fit(features, target)\n",
    "    \n",
    "    # model predictions (training data)\n",
    "    target_pred = model_tmp.predict(features)  # predict target values of training data\n",
    "    residuals = target - target_pred  # difference between predicted and actual target values \n",
    "    \n",
    "    MSE.loc[i, 'training'] = mean_squared_error(target, target_pred)  # calculate MSE for training data and add it to DataFrame\n",
    "    print('MSE (training): ', round(R2.loc[i, 'training'], 3))\n",
    "\n",
    "    # model predictions (test data)\n",
    "    features_test = df_test.loc[:, df_test.columns[:i]]  # feature matrix for test data\n",
    "    target_test = df_test.loc[:, 'price_per_m2']  # target_values of test data\n",
    "    target_test_pred = model_tmp.predict(features_test)  # predict target values of test data\n",
    "\n",
    "    MSE.loc[i, 'test'] = mean_squared_error(target_test, target_test_pred)  # calculate MSE for test data and add it to DataFrame\n",
    "    print('MSE (test): ', round(MSE.loc[i, 'test'], 3), '\\n')\n",
    "\n",
    "MSE.plot(ylim=[0,35],title=\"Vergleich Trainings- und Testscores\").set(xlabel=\"# Features\", ylabel=\"MSE\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "glueckwunsch",
    "original-content": "**Congratulations:** You got your first impression of overfitting. If machine learning models from supervised learning show too much *variance*, they practically learn the training data by heart. This happens when there are too many parameters for the model to learn. A linear regression model with eleven features learns twelve parameters (one axis intercept and eleven slopes).\n\nThere are only two remedies to avoid overfitting:\n1. More training data\n2. A simpler model\n\nIn the next lesson you will look at a strategy for finding an optimally simple regression model.\n",
    "selectable": false
   },
   "source": [
    "**Congratulations:** You got your first impression of overfitting. If machine learning models from supervised learning show too much *variance*, they practically learn the training data by heart. This happens when there are too many parameters for the model to learn. A linear regression model with eleven features learns twelve parameters (one axis intercept and eleven slopes).\n",
    "\n",
    "There are only two remedies to avoid overfitting:\n",
    "1. More training data\n",
    "2. A simpler model\n",
    "\n",
    "In the next lesson you will look at a strategy for finding an optimally simple regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "merke",
    "original-content": "**Remember:**\n* Too many features can lead to overfitting.\n* If the model is overfitted, it can only handle new data with difficulty.\n",
    "selectable": false
   },
   "source": [
    "**Remember:**\n",
    "* Too many features can lead to overfitting.\n",
    "* If the model is overfitted, it can only handle new data with difficulty.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "***\nDo you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n***\nFound a mistake? Contact Support at support@stackfuel.com.\n***\n",
    "selectable": false
   },
   "source": [
    "***\n",
    "Do you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n",
    "***\n",
    "Found a mistake? Contact Support at support@stackfuel.com.\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "content_id": "e342ee88-f324-41a0-ad4b-db917dd97604",
  "content_language": "en",
  "content_title": "Too Many Features: Overfitting",
  "content_type": "exercise",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
