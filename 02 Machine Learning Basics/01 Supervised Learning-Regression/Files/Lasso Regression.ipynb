{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "# Lasso Regularization (Solution)\nModule 1 | Chapter 1 | Notebook 9\n\n***\nAfter getting to know *Ridge* in the previous lesson, we will look at lasso regularization in this lesson. It is particularly practical for *feature selection*. This notebook will cover the following concept:\n* Lasso Regression\n***\n",
    "selectable": false
   },
   "source": [
    "# Lasso Regularization\n",
    "Module 1 | Chapter 1 | Notebook 9\n",
    "\n",
    "***\n",
    "After getting to know *Ridge* in the previous lesson, we will look at lasso regularization in this lesson. It is particularly practical for *feature selection*. This notebook will cover the following concept:\n",
    "* Lasso Regression\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## Lasso Regression\n",
    "selectable": false
   },
   "source": [
    "## Lasso Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "szenario",
    "original-content": "**Scenario:** A Taiwanese investor comes to you to find out how much his properties in Taiwan are actually worth. He might want to resell them. The data for the houses he needs predictions for is located in *Taiwan_real_estate_prediction_data.xlsx*. \n\nAfter the overfitting problems in the lesson before last, he is now looking for an optimal solution with as many features as feasibly possible, but not more than that. The training data is in *Taiwan_real_estate_training_data.xlsx*.\n\nThe model quality should be evaluated with the data in *Taiwan_real_estate_test_data.xlsx*. If it is good, the investor wants to know how much his properties are worth.\n",
    "selectable": true
   },
   "source": [
    "**Scenario:** A Taiwanese investor comes to you to find out how much his properties in Taiwan are actually worth. He might want to resell them. The data for the houses he needs predictions for is located in *Taiwan_real_estate_prediction_data.xlsx*. \n",
    "\n",
    "After the overfitting problems in the lesson before last, he is now looking for an optimal solution with as many features as feasibly possible, but not more than that. The training data is in *Taiwan_real_estate_training_data.xlsx*.\n",
    "\n",
    "The model quality should be evaluated with the data in *Taiwan_real_estate_test_data.xlsx*. If it is good, the investor wants to know how much his properties are worth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "In order to make rapid progress, let's import the data and divide it into `df_train` (training data), `df_test` (test data to validate the models) and `df_aim` (prediction data not including property prices).\n",
    "selectable": true
   },
   "source": [
    "In order to make rapid progress, let's import the data and divide it into `df_train` (training data), `df_test` (test data to validate the models) and `df_aim` (prediction data not including property prices).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "cell_content_type": "code_demo",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "If you would like, you can discuss this in the forum under *Lasso Regularization*.",
    "original-content": "import pandas as pd\nimport numpy as np\nfrom sklearn.metrics import *\ndf_train = pd.read_excel('Taiwan_real_estate_training_data.xlsx', index_col='No')\ndf_test = pd.read_excel('Taiwan_real_estate_test_data.xlsx', index_col='No')\ndf_aim = pd.read_excel('Taiwan_real_estate_prediction_data.xlsx', index_col='No')\n\ncol_names = ['house_age', \n              'metro_distance', \n              'number_convenience_stores', \n              'number_parking_spaces',\n              'air_pollution',\n              'light_pollution',\n              'noise_pollution',\n              'neighborhood_quality',\n              'crime_score',\n              'energy_consumption',\n              'longtitude', \n              'price_per_ping']\ndf_train.columns = col_names\ndf_test.columns = col_names\ndf_aim.columns = col_names\n\ndf_train.loc[:, 'price_per_m2'] = df_train.loc[:, 'price_per_ping'] / 3.3\ndf_test.loc[:, 'price_per_m2'] = df_test.loc[:, 'price_per_ping'] / 3.3\ndf_aim.loc[:, 'price_per_m2'] = df_aim.loc[:, 'price_per_ping'] / 3.3\n\ndf_train = df_train.drop('price_per_ping', axis=1)\ndf_test = df_test.drop('price_per_ping', axis=1)\ndf_aim = df_aim.drop('price_per_ping', axis=1)\n\nfeatures_train = df_train.drop('price_per_m2', axis=1)\nfeatures_test = df_test.drop('price_per_m2', axis=1)\ntarget_train = df_train.loc[:,'price_per_m2']\ntarget_test = df_test.loc[:,'price_per_m2']",
    "selectable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    NaN\n",
      "9    NaN\n",
      "10   NaN\n",
      "Name: price_per_ping, dtype: float64\n",
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "df_train = pd.read_excel('Taiwan_real_estate_training_data.xlsx', index_col='No')\n",
    "df_test = pd.read_excel('Taiwan_real_estate_test_data.xlsx', index_col='No')\n",
    "df_aim = pd.read_excel('Taiwan_real_estate_prediction_data.xlsx', index_col='No')\n",
    "\n",
    "col_names = ['house_age', \n",
    "              'metro_distance', \n",
    "              'number_convenience_stores', \n",
    "              'number_parking_spaces',\n",
    "              'air_pollution',\n",
    "              'light_pollution',\n",
    "              'noise_pollution',\n",
    "              'neighborhood_quality',\n",
    "              'crime_score',\n",
    "              'energy_consumption',\n",
    "              'longtitude', \n",
    "              'price_per_ping']\n",
    "df_train.columns = col_names\n",
    "df_test.columns = col_names\n",
    "df_aim.columns = col_names\n",
    "\n",
    "print(df_aim.loc[:, 'price_per_ping'])\n",
    "print(df_aim.loc[:, 'price_per_ping'].unique())\n",
    "\n",
    "df_train.loc[:, 'price_per_m2'] = df_train.loc[:, 'price_per_ping'] / 3.3\n",
    "df_test.loc[:, 'price_per_m2'] = df_test.loc[:, 'price_per_ping'] / 3.3\n",
    "df_aim.loc[:, 'price_per_m2'] = df_aim.loc[:, 'price_per_ping'] / 3.3\n",
    "\n",
    "df_train = df_train.drop('price_per_ping', axis=1)\n",
    "df_test = df_test.drop('price_per_ping', axis=1)\n",
    "df_aim = df_aim.drop('price_per_ping', axis=1)\n",
    "\n",
    "features_train = df_train.drop('price_per_m2', axis=1)\n",
    "features_test = df_test.drop('price_per_m2', axis=1)\n",
    "\n",
    "target_train = df_train.loc[:,'price_per_m2']\n",
    "target_test = df_test.loc[:,'price_per_m2']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Once again, the data dictionary for this data is as follows:\n\nColumn number | Column name       | Type      | Description\n ------------ | ---     | :---------:           | ------------:\n0              | `'house_age'` | continuous (`float`) | age of the house in years\n1              | `'metro_distance'` | continuous (`float`) | distance in meters to the next metro station\n2              | `'number_convenience_stores'` | continuous (`int`) | Number of convenience stores nearby\n3              | `'number_parking_spaces'` | continuous (`int`) | Number of parking spaces nearby\n4              | `'air_pollution'` | continuous (`float`) | Air pollution value near the house\n5              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n6              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n7              | `'neighborhood_quality'` | continuous (`float`) | average quality of life in the neighborhood\n8              | `'crime_score'` | continuous (`float`) | crime score according to police\n9              | `'energy_consumption'` | continuous (`float`) | The property's energy consumption\n10              | `'longitude'` | continuous (`float`) | The property's longitude\n11              | 'price_per_ping' | continuous (`float') | House price in Taiwan dollars per ping, one ping is 3.3 m²\n12              | `'price_per_ping'` | continuous (`'float'`) | House price in Taiwan dollars per m²\n",
    "selectable": true
   },
   "source": [
    "Once again, the data dictionary for this data is as follows:\n",
    "\n",
    "Column number | Column name       | Type      | Description\n",
    " ------------ | ---     | :---------:           | ------------:\n",
    "0              | `'house_age'` | continuous (`float`) | age of the house in years\n",
    "1              | `'metro_distance'` | continuous (`float`) | distance in meters to the next metro station\n",
    "2              | `'number_convenience_stores'` | continuous (`int`) | Number of convenience stores nearby\n",
    "3              | `'number_parking_spaces'` | continuous (`int`) | Number of parking spaces nearby\n",
    "4              | `'air_pollution'` | continuous (`float`) | Air pollution value near the house\n",
    "5              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n",
    "6              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n",
    "7              | `'neighborhood_quality'` | continuous (`float`) | average quality of life in the neighborhood\n",
    "8              | `'crime_score'` | continuous (`float`) | crime score according to police\n",
    "9              | `'energy_consumption'` | continuous (`float`) | The property's energy consumption\n",
    "10              | `'longitude'` | continuous (`float`) | The property's longitude\n",
    "11              | 'price_per_ping' | continuous (`float') | House price in Taiwan dollars per ping, one ping is 3.3 m²\n",
    "12              | `'price_per_ping'` | continuous (`'float'`) | House price in Taiwan dollars per m²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "In the last lesson we saw that too many features in the linear regression model led to overfitting. The trained parameters can then no longer be used to predict new, independent data. The only way to prevent overfitting is regularization and to simplify the model. In principle, the fewer features a model considers, the simpler it is. But how do you choose the best features in a data-driven way? Lasso regularization is a very practical option.\n",
    "selectable": false
   },
   "source": [
    "In the last lesson we saw that too many features in the linear regression model led to overfitting. The trained parameters can then no longer be used to predict new, independent data. The only way to prevent overfitting is regularization and to simplify the model. In principle, the fewer features a model considers, the simpler it is. But how do you choose the best features in a data-driven way? Lasso regularization is a very practical option.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "A lasso regression is actually barely different from a ridge regression. The only difference is that in a lasso regression, the absolute slope values are minimized instead of the square of the slope values, as is the case with ridge regression. Lasso regression therefore adjusts the parameters to the data with two objectives:\n* Keep the difference between predicted and actual target values as small as possible\n* Keep the sum of the absolute slopes (e.g. $|slope_1| + |slope_2|$) as small as possible.\n\nAs with ridge regression, the $\\alpha$ hyperparameter controls how the two objectives are balanced. With `alpha=0` the second objective (regularization) is disregarded. Then the lasso regression would be a normal linear regression. With an infinitely high `alpha`, the first objective disregarded. In this case all slopes are zero.\n\nIf you are interested, [the official `sklearn` documentation](https://scikit-learn.org/stable/modules/linear_model.html#setting-regularization-parameter) provides all the information you need.\nWe have summarized the most important information for you here:\n\n```python\nLasso(\n    alpha= float,       #strength of penalty for regularization\n    fit_intercept=True, #fit intercept in underlying linear regression\n    random_state=None,  #random seed used for data shuffling\n)\n```\n\nLasso regression tends to set a lot of slopes to zero. This means that the features with a slope of zero will not even be used for the prediction. So you can generally disregard them and select the most important features.\n\nNow use a lasso regression with `alpha=1`. `Lasso` is located in `sklearn.linear_model`. Store the model in `model_lasso`. Fit the model to the data with all eleven features. Note that the features should be standardized, as with the ridge regression. Print the slopes at the end. Are any of the slopes actually zero?\n",
    "selectable": true
   },
   "source": [
    "A lasso regression is actually barely different from a ridge regression. The only difference is that in a lasso regression, the absolute slope values are minimized instead of the square of the slope values, as is the case with ridge regression. Lasso regression therefore adjusts the parameters to the data with two objectives:\n",
    "* Keep the difference between predicted and actual target values as small as possible\n",
    "* Keep the sum of the absolute slopes (e.g. $|slope_1| + |slope_2|$) as small as possible.\n",
    "\n",
    "As with ridge regression, the $\\alpha$ hyperparameter controls how the two objectives are balanced. With `alpha=0` the second objective (regularization) is disregarded. Then the lasso regression would be a normal linear regression. With an infinitely high `alpha`, the first objective disregarded. In this case all slopes are zero.\n",
    "\n",
    "If you are interested, [the official `sklearn` documentation](https://scikit-learn.org/stable/modules/linear_model.html#setting-regularization-parameter) provides all the information you need.\n",
    "We have summarized the most important information for you here:\n",
    "\n",
    "```python\n",
    "Lasso(\n",
    "    alpha= float,       #strength of penalty for regularization\n",
    "    fit_intercept=True, #fit intercept in underlying linear regression\n",
    "    random_state=None,  #random seed used for data shuffling\n",
    ")\n",
    "```\n",
    "\n",
    "Lasso regression tends to set a lot of slopes to zero. This means that the features with a slope of zero will not even be used for the prediction. So you can generally disregard them and select the most important features.\n",
    "\n",
    "Now use a lasso regression with `alpha=1`. `Lasso` is located in `sklearn.linear_model`. Store the model in `model_lasso`. Fit the model to the data with all eleven features. Note that the features should be standardized, as with the ridge regression. Print the slopes at the end. Are any of the slopes actually zero?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "First import `Lasso` and then instantiate the model with `model_lasso = Lasso(alpha=1)`. Fit it to the data afterwards.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.         -1.47427896  0.46369063  0.         -0.         -0.\n",
      " -0.04670917  0.          0.          0.          0.        ]\n",
      "Index(['house_age', 'metro_distance', 'number_convenience_stores',\n",
      "       'number_parking_spaces', 'air_pollution', 'light_pollution',\n",
      "       'noise_pollution', 'neighborhood_quality', 'crime_score',\n",
      "       'energy_consumption', 'longtitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train)\n",
    "features_train_standardized = scaler.transform(features_train) \n",
    "\n",
    "model_lasso = Lasso(alpha=1)\n",
    "model_lasso.fit( features_train, target_train)\n",
    "model_lasso.fit(features_train_standardized, target_train)\n",
    "\n",
    "print(model_lasso.coef_)\n",
    "print(features_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Almost all features were set to zero. Only `metro_distance`, `number_convenience_stores` and `noise_pollution` have survived and would be used to make predictions with this model.\n\nNext you can evaluate the `model_lasso` model using the test data. Note that the features of the test data should be standardized exactly as the training data was before. Print the *mean squared error*, *RMSE* and *R²* values  of `model_lasso` and the test data.\n",
    "selectable": true
   },
   "source": [
    "Almost all features were set to zero. Only `metro_distance`, `number_convenience_stores` and `noise_pollution` have survived and would be used to make predictions with this model.\n",
    "\n",
    "Next you can evaluate the `model_lasso` model using the test data. Note that the features of the test data should be standardized exactly as the training data was before. Print the *mean squared error*, *RMSE* and *R²* values  of `model_lasso` and the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "First you need to standardize the feature values from the test data. Then you can use them like this: `target_test_pred_lasso = model_lasso.predict(features_test_standardized)`.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE:  8.571168547622161\n",
      "RMSE:  2.927655810989769\n",
      "R2:  0.3520342491334303\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    " \n",
    "features_test_standardized = scaler.transform(features_test)\n",
    "target_test_pred_lasso = model_lasso.predict(features_test_standardized)\n",
    "\n",
    "print('MSE: ', mean_squared_error(target_test, target_test_pred_lasso))\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(target_test, target_test_pred_lasso)))\n",
    "print('R2: ', r2_score(target_test, target_test_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "If we now compare these values with those of the other models, it becomes apparent that the lasso model delivers the best performance.\n\nModel| Test: *MSE* | Test: *R²*\n---|---|---\n`model_age`| 11.89 | 10.1%\n`model_metro`| 10.27 | 22.4%\n`model_stores`| 11.29 | 14.7%\n`model_multiple`| 9.72 | 26.5%\n`model_multiple_all`| 31.77 | -140.2%\n`model_ridge`| 10.83 | 18.1%\n`model_lasso`| 8.57 | 35.2%\n",
    "selectable": true
   },
   "source": [
    "If we now compare these values with those of the other models, it becomes apparent that the lasso model delivers the best performance.\n",
    "\n",
    "Model| Test: *MSE* | Test: *R²*\n",
    "---|---|---\n",
    "`model_age`| 11.89 | 10.1%\n",
    "`model_metro`| 10.27 | 22.4%\n",
    "`model_stores`| 11.29 | 14.7%\n",
    "`model_multiple`| 9.72 | 26.5%\n",
    "`model_multiple_all`| 31.77 | -140.2%\n",
    "`model_ridge`| 10.83 | 18.1%\n",
    "`model_lasso`| 8.57 | 35.2%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "glueckwunsch",
    "original-content": "**Congratulations:** You have now learned about two regression models with regularization. In practice, ridge regression is used more against overfitting and correlated features and lasso regression is used to identify the most important features. Lasso regressions are also often used when there is a very large number of features. In our case the lasso model is also the best model according to quality metrics. So let's use it to predict the real estate investor's house prices as best we can.\n",
    "selectable": false
   },
   "source": [
    "**Congratulations:** You have now learned about two regression models with regularization. In practice, ridge regression is used more against overfitting and correlated features and lasso regression is used to identify the most important features. Lasso regressions are also often used when there is a very large number of features. In our case the lasso model is also the best model according to quality metrics. So let's use it to predict the real estate investor's house prices as best we can.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## Predicting house prices with lasso regression\n",
    "selectable": false
   },
   "source": [
    "## Predicting house prices with lasso regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "szenario",
    "original-content": "**Scenario:** The Taiwanese investor would now like to know how much his properties are worth. Predict their value with the best model you have found (`model_lasso`). You will find the data in `df_aim`.\n",
    "selectable": true
   },
   "source": [
    "**Scenario:** The Taiwanese investor would now like to know how much his properties are worth. Predict their value with the best model you have found (`model_lasso`). You will find the data in `df_aim`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "First define `features_aim` with `features_aim = df_aim.loc[:, col_names[:-1]]`. After that you should standardize the features and use the standardized features together with `model_lasso` for the predictions.",
    "hint_counter": 1,
    "original-content": "",
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.876347921105019\n"
     ]
    }
   ],
   "source": [
    "df_aim =  df_aim.dropna(axis=0, how='all')\n",
    "\n",
    "features_aim = df_aim.drop('price_per_m2', axis=1)\n",
    "target_aim = df_aim.loc[:,'price_per_m2']\n",
    "\n",
    "features_aim_standardized = scaler.transform(features_aim)\n",
    "target_aim_pred_lasso = model_lasso.predict(features_aim_standardized)\n",
    "print(target_aim_pred_lasso.mean())\n",
    "\n",
    "#print('MSE: ', mean_squared_error(target_aim, target_aim_pred_lasso))\n",
    "#print('RMSE: ', np.sqrt(mean_squared_error(target_aim, target_aim_pred_lasso)))\n",
    "#print('R2: ', r2_score(target_aim, target_aim_pred_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "glueckwunsch",
    "original-content": "**Congratulations:** You got an impression of overfitting and how to avoid it. In the end, the best model was a lasso regression that predicted an average house price of $12.88 / m². The real estate investor is very happy with this. He thanks you for all your hard work and hopes you enjoy the rest of the course!\n",
    "selectable": false
   },
   "source": [
    "**Congratulations:** You got an impression of overfitting and how to avoid it. In the end, the best model was a lasso regression that predicted an average house price of $12.88 / m². The real estate investor is very happy with this. He thanks you for all your hard work and hopes you enjoy the rest of the course!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "merke",
    "original-content": "**Remember:**\n* `Lasso` minimizes the sum of the absolute slope values.\n* `Lasso` is suitable for preventing overfitting and for *feature selection*.\n",
    "selectable": true
   },
   "source": [
    "**Remember:**\n",
    "* `Lasso` minimizes the sum of the absolute slope values.\n",
    "* `Lasso` is suitable for preventing overfitting and for *feature selection*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "***\nDo you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n***\nFound a mistake? Contact Support at support@stackfuel.com.\n***\n",
    "selectable": false
   },
   "source": [
    "***\n",
    "Do you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n",
    "***\n",
    "Found a mistake? Contact Support at support@stackfuel.com.\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "content_id": "2419f174-c6f1-4a48-a732-2a770e81374e",
  "content_language": "en",
  "content_title": "Lasso Regularization",
  "content_type": "exercise",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
