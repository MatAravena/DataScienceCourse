{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "# Ridge Regularization (Solution)\nModule 1 | Chapter 1 | Notebook 8\n\n***\nAfter learning about overfitting in the previous lesson, we will look at a remedy for that in this lesson. Regularization. Regularization simplifies multiple linear regression models. You will learn about the first approach, *ridge* regularization, in this lesson.\n***\n",
        "selectable": false
      },
      "source": [
        "# Ridge Regularization (Solution)\n",
        "Module 1 | Chapter 1 | Notebook 8\n",
        "\n",
        "***\n",
        "After learning about overfitting in the previous lesson, we will look at a remedy for that in this lesson. Regularization. Regularization simplifies multiple linear regression models. You will learn about the first approach, *ridge* regularization, in this lesson.\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "## Ridge Regression\n",
        "selectable": false
      },
      "source": [
        "## Ridge Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "messageType": "szenario",
        "original-content": "**Scenario:** A Taiwanese investor comes to you to find out how much his properties in Taiwan are actually worth. He might want to resell them. The data for the houses he needs predictions for is located in *Taiwan_real_estate_prediction_data.xlsx*. \n\nAfter the overfitting problems in the previous lesson, he is now looking for an optimal solution with as many features as possible, but not more than that. The training data is in *Taiwan_real_estate_training_data.xlsx*.\n\nHe wants you to evaluate the model quality with the data in *Taiwan_real_estate_test_data.xlsx*. If it's good, the investor wants to know how much his properties are worth.\n",
        "selectable": true
      },
      "source": [
        "**Scenario:** A Taiwanese investor comes to you to find out how much his properties in Taiwan are actually worth. He might want to resell them. The data for the houses he needs predictions for is located in *Taiwan_real_estate_prediction_data.xlsx*. \n",
        "\n",
        "After the overfitting problems in the previous lesson, he is now looking for an optimal solution with as many features as possible, but not more than that. The training data is in *Taiwan_real_estate_training_data.xlsx*.\n",
        "\n",
        "He wants you to evaluate the model quality with the data in *Taiwan_real_estate_test_data.xlsx*. If it's good, the investor wants to know how much his properties are worth.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "In order to make rapid progress, let's import the data and divide it into `df_train` (training data), `df_test` (test data to validate the models) and `df_aim` (prediction data not including property prices).\n",
        "selectable": true
      },
      "source": [
        "In order to make rapid progress, let's import the data and divide it into `df_train` (training data), `df_test` (test data to validate the models) and `df_aim` (prediction data not including property prices).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cell_content_type": "code_demo",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "If you would like, you can discuss this in the forum under *Ridge Regularization*.",
        "hint_counter": 0,
        "original-content": "import pandas as pd\nimport numpy as np\ndf_train = pd.read_excel('Taiwan_real_estate_training_data.xlsx', index_col='No')\ndf_test = pd.read_excel('Taiwan_real_estate_test_data.xlsx', index_col='No')\ndf_aim = pd.read_excel('Taiwan_real_estate_prediction_data.xlsx', index_col='No')\n\ncol_names = ['house_age', \n              'metro_distance', \n              'number_convenience_stores', \n              'number_parking_spaces',\n              'air_pollution',\n              'light_pollution',\n              'noise_pollution',\n              'neighborhood_quality',\n              'crime_score',\n              'energy_consumption',\n              'longitude', \n              'price_per_ping']\ndf_train.columns = col_names\ndf_test.columns = col_names\ndf_aim.columns = col_names\n\ndf_train.loc[:, 'price_per_m2'] = df_train.loc[:, 'price_per_ping'] / 3.3\ndf_test.loc[:, 'price_per_m2'] = df_test.loc[:, 'price_per_ping'] / 3.3\ndf_aim.loc[:, 'price_per_m2'] = df_aim.loc[:, 'price_per_ping'] / 3.3\n\ndf_train = df_train.drop('price_per_ping', axis=1)\ndf_test = df_test.drop('price_per_ping', axis=1)\ndf_aim = df_aim.drop('price_per_ping', axis=1)",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "df_train = pd.read_excel('Taiwan_real_estate_training_data.xlsx', index_col='No')\n",
        "df_test = pd.read_excel('Taiwan_real_estate_test_data.xlsx', index_col='No')\n",
        "df_aim = pd.read_excel('Taiwan_real_estate_prediction_data.xlsx', index_col='No')\n",
        "\n",
        "col_names = ['house_age', \n",
        "              'metro_distance', \n",
        "              'number_convenience_stores', \n",
        "              'number_parking_spaces',\n",
        "              'air_pollution',\n",
        "              'light_pollution',\n",
        "              'noise_pollution',\n",
        "              'neighborhood_quality',\n",
        "              'crime_score',\n",
        "              'energy_consumption',\n",
        "              'longitude', \n",
        "              'price_per_ping']\n",
        "df_train.columns = col_names\n",
        "df_test.columns = col_names\n",
        "df_aim.columns = col_names\n",
        "\n",
        "df_train.loc[:, 'price_per_m2'] = df_train.loc[:, 'price_per_ping'] / 3.3\n",
        "df_test.loc[:, 'price_per_m2'] = df_test.loc[:, 'price_per_ping'] / 3.3\n",
        "df_aim.loc[:, 'price_per_m2'] = df_aim.loc[:, 'price_per_ping'] / 3.3\n",
        "\n",
        "df_train = df_train.drop('price_per_ping', axis=1)\n",
        "df_test = df_test.drop('price_per_ping', axis=1)\n",
        "df_aim = df_aim.drop('price_per_ping', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Once again, the data dictionary for this data is as follows:\n\nColumn number | Column name       | Type      | Description\n ------------ | ---     | :---------:           | ------------:\n0              | `'house_age'` | continuous (`float`) | age of the house in years\n1              | `'metro_distance'` | continuous (`float`) | distance in meters to the next metro station\n2              | `'number_convenience_stores'` | continuous (`int`) | Number of convenience stores nearby\n3              | `'number_parking_spaces'` | continuous (`int`) | Number of parking spaces nearby\n4              | `'air_pollution'` | continuous (`float`) | Air pollution value near the house\n5              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n6              | `'noise_pollution'` | continuous (`float`) | Noise pollution value near the house\n7              | `'neighborhood_quality'` | continuous (`float`) | average quality of life in the neighborhood\n8              | `'crime_score'` | continuous (`float`) | crime score according to police\n9              | `'energy_consumption'` | continuous (`float`) | The property's energy consumption\n10              | `'longitude'` | continuous (`float`) | The property's longitude\n11              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per ping, one ping is 3.3 m\u00b2\n12              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per m\u00b2\n",
        "selectable": true
      },
      "source": [
        "Once again, the data dictionary for this data is as follows:\n",
        "\n",
        "Column number | Column name       | Type      | Description\n",
        " ------------ | ---     | :---------:           | ------------:\n",
        "0              | `'house_age'` | continuous (`float`) | age of the house in years\n",
        "1              | `'metro_distance'` | continuous (`float`) | distance in meters to the next metro station\n",
        "2              | `'number_convenience_stores'` | continuous (`int`) | Number of convenience stores nearby\n",
        "3              | `'number_parking_spaces'` | continuous (`int`) | Number of parking spaces nearby\n",
        "4              | `'air_pollution'` | continuous (`float`) | Air pollution value near the house\n",
        "5              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n",
        "6              | `'noise_pollution'` | continuous (`float`) | Noise pollution value near the house\n",
        "7              | `'neighborhood_quality'` | continuous (`float`) | average quality of life in the neighborhood\n",
        "8              | `'crime_score'` | continuous (`float`) | crime score according to police\n",
        "9              | `'energy_consumption'` | continuous (`float`) | The property's energy consumption\n",
        "10              | `'longitude'` | continuous (`float`) | The property's longitude\n",
        "11              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per ping, one ping is 3.3 m\u00b2\n",
        "12              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per m\u00b2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "In the last lesson we saw that too many features in the linear regression model led to overfitting. The trained parameters can then no longer be used to predict new, independent data. The only way to prevent overfitting is to enlarge the training data set and/or simplify the model.\n\nWhat's known as regularization simplifies the multiple regression model with a data-driven approach. Since the lesson *Simple Linear Regression with sklearn* you know that a linear regression adjusts parameters to the data so that the distance between the regression line and data points is as small as possible. Regularization adds an additional goal. Not only should the distance between the regression line and the data points be as small as possible, but also the slope values.\n\nThe formula for multiple linear regression with two features looks like this:\n\n\\begin{equation*}\nTarget = intercept + (slope_1 \\cdot Feature_1) + (slope_2 \\cdot Feature_2) + error\n\\end{equation*}\n\nRidge regression, also known as Tikhonov regularization uses regularization to avoid overfitting. When the model is fitted to the data, there are two objectives that should be pursued:\n* Keep the difference between predicted and actual target values as small as possible.\n* Keep the sum of the squared slopes (e.g. $(slope_1)^2 + (slope_2)^2$) as small as possible.\n\nThe second objective is called regularization, or *shrinkage penalty*. This is as if the model will be punished if the slopes are too big.\n\nIt makes sense for you to gain practical experience with ridge regression. Import `Ridge` from the `sklearn.linear_model` module.\n",
        "selectable": true
      },
      "source": [
        "In the last lesson we saw that too many features in the linear regression model led to overfitting. The trained parameters can then no longer be used to predict new, independent data. The only way to prevent overfitting is to enlarge the training data set and/or simplify the model.\n",
        "\n",
        "What's known as regularization simplifies the multiple regression model with a data-driven approach. Since the lesson *Simple Linear Regression with sklearn* you know that a linear regression adjusts parameters to the data so that the distance between the regression line and data points is as small as possible. Regularization adds an additional goal. Not only should the distance between the regression line and the data points be as small as possible, but also the slope values.\n",
        "\n",
        "The formula for multiple linear regression with two features looks like this:\n",
        "\n",
        "\\begin{equation*}\n",
        "Target = intercept + (slope_1 \\cdot Feature_1) + (slope_2 \\cdot Feature_2) + error\n",
        "\\end{equation*}\n",
        "\n",
        "Ridge regression, also known as Tikhonov regularization uses regularization to avoid overfitting. When the model is fitted to the data, there are two objectives that should be pursued:\n",
        "* Keep the difference between predicted and actual target values as small as possible.\n",
        "* Keep the sum of the squared slopes (e.g. $(slope_1)^2 + (slope_2)^2$) as small as possible.\n",
        "\n",
        "The second objective is called regularization, or *shrinkage penalty*. This is as if the model will be punished if the slopes are too big.\n",
        "\n",
        "It makes sense for you to gain practical experience with ridge regression. Import `Ridge` from the `sklearn.linear_model` module.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "Write `from sklearn.linear_model import Ridge` and run the cell.",
        "original-content": "# Solution:\nfrom sklearn.linear_model import Ridge",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "# Solution:\n",
        "from sklearn.linear_model import Ridge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "To instantiate the model, we need knowledge about the hyperparameters of the model. The main one is called $\\alpha$. This hyper parameter controls how much the ridge regression should follow one target and how much it should follow the other. With `alpha=0` the second objective (regularization) is disregarded. Then the ridge regression would be a normal linear regression.\n\nWith an infinitely high `alpha` the first objective disregarded. In this case all slopes are zero.\n\n`alpha` therefore controls the balance between *bias* (very large `alpha`) and *variance* (very small `alpha`). There are data driven ways to get an optimal value for `alpha`. Unfortunately we don't have enough time to cover this here. If you are interested, [the official `sklearn` documentation](https://scikit-learn.org/stable/modules/linear_model.html#setting-regularization-parameter) provides all the information you need.\nWe have summarized the most important information for you here:\n```python\nRidge(\n    alpha= float,       #strength of penalty for regularization\n    fit_intercept=True, #fit intercept in underlying linear regression\n    solver='auto',      #solving algorithm, will affect training runtime\n    random_state=None,  #random seed used for data shuffling\n)\n```\n\nIn our case we use an `alpha` value of 1500.\n",
        "selectable": true
      },
      "source": [
        "To instantiate the model, we need knowledge about the hyperparameters of the model. The main one is called $\\alpha$. This hyper parameter controls how much the ridge regression should follow one target and how much it should follow the other. With `alpha=0` the second objective (regularization) is disregarded. Then the ridge regression would be a normal linear regression.\n",
        "\n",
        "With an infinitely high `alpha` the first objective disregarded. In this case all slopes are zero.\n",
        "\n",
        "`alpha` therefore controls the balance between *bias* (very large `alpha`) and *variance* (very small `alpha`). There are data driven ways to get an optimal value for `alpha`. Unfortunately we don't have enough time to cover this here. If you are interested, [the official `sklearn` documentation](https://scikit-learn.org/stable/modules/linear_model.html#setting-regularization-parameter) provides all the information you need.\n",
        "We have summarized the most important information for you here:\n",
        "```python\n",
        "Ridge(\n",
        "    alpha= float,       #strength of penalty for regularization\n",
        "    fit_intercept=True, #fit intercept in underlying linear regression\n",
        "    solver='auto',      #solving algorithm, will affect training runtime\n",
        "    random_state=None,  #random seed used for data shuffling\n",
        ")\n",
        "```\n",
        "\n",
        "In our case we use an `alpha` value of 1500.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "messageType": "vertiefung",
        "original-content": "**Deep dive:** The following content is optional, feel free to skip it.<br>\n\n**How does ridge regularization work?**\n\nAs we saw in Module 1, Chapter 1, Notebook 6, the *cost function* of the linear regression simply calculates the MSE. Regularizations add what's called a *penalty term* or *regularization term* to this *cost function*. In the case of ridge regularization, this term is nothing more than the L2 norm (see Module 0, Chapter 2 Notebook 4) of the coefficient vector ($\\vec{\\beta}$) with the exception of the *y_intercept* ($\\beta_0$). To make sure you have the ability to adjust the strength of the regularization, the hyperparameter $\\alpha$ is used, which the *penalty-term* is multiplied by.\n\nThis results in the *cost function* ( $J(\\vec{\\beta})$ ) of the ridge regression:\n\n$J(\\vec{\\beta}) = MSE(X,\\vec{\\beta}) + \\alpha \\cdot ||\\vec{\\beta}||_2$\n\nWhen training the model, the system tries again to minimize this *cost function* and to find optimal values for the coefficients in $\\vec{b}$. This solution can be done in several ways, which you can select under the parameter `solver`.\n",
        "selectable": true
      },
      "source": [
        "**Deep dive:** The following content is optional, feel free to skip it.<br>\n",
        "\n",
        "**How does ridge regularization work?**\n",
        "\n",
        "As we saw in Module 1, Chapter 1, Notebook 6, the *cost function* of the linear regression simply calculates the MSE. Regularizations add what's called a *penalty term* or *regularization term* to this *cost function*. In the case of ridge regularization, this term is nothing more than the L2 norm (see Module 0, Chapter 2 Notebook 4) of the coefficient vector ($\\vec{\\beta}$) with the exception of the *y_intercept* ($\\beta_0$). To make sure you have the ability to adjust the strength of the regularization, the hyperparameter $\\alpha$ is used, which the *penalty-term* is multiplied by.\n",
        "\n",
        "This results in the *cost function* ( $J(\\vec{\\beta})$ ) of the ridge regression:\n",
        "\n",
        "$J(\\vec{\\beta}) = MSE(X,\\vec{\\beta}) + \\alpha \\cdot ||\\vec{\\beta}||_2$\n",
        "\n",
        "When training the model, the system tries again to minimize this *cost function* and to find optimal values for the coefficients in $\\vec{b}$. This solution can be done in several ways, which you can select under the parameter `solver`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "2) Instantiate a linear regression model and store it in the variable `model_ridge`. Set the function parameter `alpha` to `1500`.\n",
        "selectable": true
      },
      "source": [
        "2) Instantiate a linear regression model and store it in the variable `model_ridge`. Set the function parameter `alpha` to `1500`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "Write `model_ridge = Ridge(alpha=1500)` and run the cell.",
        "original-content": "# Solution:\nmodel_ridge = Ridge(alpha=1500)",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "# Solution:\n",
        "model_ridge = Ridge(alpha=1500)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Now we can turn to the feature matrix and the target vector. Save a feature matrix with all eleven features in the new `DataFrame` named `features_train`. Also store the target values from `price_per_m2` in the `Series` named `target_train`.\n",
        "selectable": true
      },
      "source": [
        "Now we can turn to the feature matrix and the target vector. Save a feature matrix with all eleven features in the new `DataFrame` named `features_train`. Also store the target values from `price_per_m2` in the `Series` named `target_train`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "For example, you could define the feature matrix like this `features_train = df_train.loc[:, col_names[:-1]]`.",
        "original-content": "# Solution:\nfeatures_train = df_train.loc[:, col_names[:-1]]\ntarget_train = df_train.loc[:, 'price_per_m2']",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "# Solution:\n",
        "features_train = df_train.loc[:, col_names[:-1]]\n",
        "target_train = df_train.loc[:, 'price_per_m2']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Since the ridge regression tries to minimize the squared slopes, the slopes should be on the same scale. Remember that the slopes use their feature's scale. Print the eight value summary for `features_train` to get an impression of the current scales of the different features.\n",
        "selectable": true
      },
      "source": [
        "Since the ridge regression tries to minimize the squared slopes, the slopes should be on the same scale. Remember that the slopes use their feature's scale. Print the eight value summary for `features_train` to get an impression of the current scales of the different features.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "Write `features_train.describe()` and run the cell.",
        "original-content": "# Solution:\nfeatures_train.describe()",
        "selectable": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>house_age</th>\n",
              "      <th>metro_distance</th>\n",
              "      <th>number_convenience_stores</th>\n",
              "      <th>number_parking_spaces</th>\n",
              "      <th>air_pollution</th>\n",
              "      <th>light_pollution</th>\n",
              "      <th>noise_pollution</th>\n",
              "      <th>neighborhood_quality</th>\n",
              "      <th>crime_score</th>\n",
              "      <th>energy_consumption</th>\n",
              "      <th>longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "      <td>314.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>17.964968</td>\n",
              "      <td>1080.554101</td>\n",
              "      <td>4.073248</td>\n",
              "      <td>72.544586</td>\n",
              "      <td>552.604234</td>\n",
              "      <td>350.052585</td>\n",
              "      <td>24.454473</td>\n",
              "      <td>0.499967</td>\n",
              "      <td>0.827038</td>\n",
              "      <td>85.749346</td>\n",
              "      <td>121.533587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.302234</td>\n",
              "      <td>1265.305662</td>\n",
              "      <td>2.917018</td>\n",
              "      <td>33.956459</td>\n",
              "      <td>724.980887</td>\n",
              "      <td>214.841852</td>\n",
              "      <td>28.952314</td>\n",
              "      <td>0.129891</td>\n",
              "      <td>0.137589</td>\n",
              "      <td>15.608840</td>\n",
              "      <td>0.015328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>23.382840</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.129046</td>\n",
              "      <td>109.402514</td>\n",
              "      <td>0.642399</td>\n",
              "      <td>0.154785</td>\n",
              "      <td>0.370455</td>\n",
              "      <td>52.271031</td>\n",
              "      <td>121.475160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>10.025000</td>\n",
              "      <td>292.997800</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>47.250000</td>\n",
              "      <td>105.270986</td>\n",
              "      <td>219.736031</td>\n",
              "      <td>6.975039</td>\n",
              "      <td>0.404905</td>\n",
              "      <td>0.750257</td>\n",
              "      <td>73.492326</td>\n",
              "      <td>121.529540</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>16.250000</td>\n",
              "      <td>492.231300</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>74.000000</td>\n",
              "      <td>273.298306</td>\n",
              "      <td>291.221794</td>\n",
              "      <td>12.933224</td>\n",
              "      <td>0.488622</td>\n",
              "      <td>0.863517</td>\n",
              "      <td>85.537347</td>\n",
              "      <td>121.538990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>28.350000</td>\n",
              "      <td>1412.735250</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>91.000000</td>\n",
              "      <td>650.921839</td>\n",
              "      <td>398.473926</td>\n",
              "      <td>29.924671</td>\n",
              "      <td>0.590752</td>\n",
              "      <td>0.936969</td>\n",
              "      <td>98.303667</td>\n",
              "      <td>121.543480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>43.800000</td>\n",
              "      <td>6396.283000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>173.000000</td>\n",
              "      <td>4257.231953</td>\n",
              "      <td>1473.563235</td>\n",
              "      <td>162.678976</td>\n",
              "      <td>0.830381</td>\n",
              "      <td>0.999743</td>\n",
              "      <td>119.588789</td>\n",
              "      <td>121.566270</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        house_age  metro_distance  number_convenience_stores  \\\n",
              "count  314.000000      314.000000                 314.000000   \n",
              "mean    17.964968     1080.554101                   4.073248   \n",
              "std     11.302234     1265.305662                   2.917018   \n",
              "min      0.000000       23.382840                   0.000000   \n",
              "25%     10.025000      292.997800                   1.000000   \n",
              "50%     16.250000      492.231300                   4.000000   \n",
              "75%     28.350000     1412.735250                   6.000000   \n",
              "max     43.800000     6396.283000                  10.000000   \n",
              "\n",
              "       number_parking_spaces  air_pollution  light_pollution  noise_pollution  \\\n",
              "count             314.000000     314.000000       314.000000       314.000000   \n",
              "mean               72.544586     552.604234       350.052585        24.454473   \n",
              "std                33.956459     724.980887       214.841852        28.952314   \n",
              "min                 0.000000       0.129046       109.402514         0.642399   \n",
              "25%                47.250000     105.270986       219.736031         6.975039   \n",
              "50%                74.000000     273.298306       291.221794        12.933224   \n",
              "75%                91.000000     650.921839       398.473926        29.924671   \n",
              "max               173.000000    4257.231953      1473.563235       162.678976   \n",
              "\n",
              "       neighborhood_quality  crime_score  energy_consumption   longitude  \n",
              "count            314.000000   314.000000          314.000000  314.000000  \n",
              "mean               0.499967     0.827038           85.749346  121.533587  \n",
              "std                0.129891     0.137589           15.608840    0.015328  \n",
              "min                0.154785     0.370455           52.271031  121.475160  \n",
              "25%                0.404905     0.750257           73.492326  121.529540  \n",
              "50%                0.488622     0.863517           85.537347  121.538990  \n",
              "75%                0.590752     0.936969           98.303667  121.543480  \n",
              "max                0.830381     0.999743          119.588789  121.566270  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Solution:\n",
        "features_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Let's take the scales of `'air_pollution'` and `'noise_pollution'` as an example. While the `'air_pollution'` values vary between 0.1 and 4,300, the `'noise_pollution'` values are only between 0.6 and 163. This does not mean that `'air_pollution'` is any more important than `'noise_pollution'`. Values in one column are not simply directly comparable with values in the other column. \n\nNevertheless, ridge regression tries to minimize the slopes that use the scale of its feature. The ridge regression would therefore punish the slope of `'air_pollution'` much less than the increase of `'noise_pollution'`, because `'air_pollution'` has larger values on average and would therefore probably also have a smaller slope value.\n\nHow can you tell the ridge regression to treat all features the same? You can use a trick. You standardize the values of each feature. This means that from each value in features ($x$) the mean of its own column ($\\bar{x}$) is subtracted and each value is divided by the standard deviation ($\\sigma$) of its column. As a formula that looks like this:\n\n<table style=\"float:left;\">\n    <tr><th align=\"left\">Word formula</th>\n        <th align=\"left\">math. Formula</th>\n    </tr>\n<tr>\n<td>\n\\begin{equation*}\n\\operatorname{feature_{standardized}} = \\frac{feature - mean_{feature}}{standard deviation_{feature}}\n\\end{equation*}\n    </td>\n<td>\n\\begin{equation*}\n\\operatorname{feature_{standard}} = \\frac{x - \\bar{x}}{\\sigma}\n\\end{equation*}  \n        </td>\n    </tr>\n</table>\n\n<br style=\"clear:both\">\n\n`StandardScaler` from `sklearn.preprocessing` implements this kind of standardization. Import `StandardScaler` directly.\n",
        "selectable": true
      },
      "source": [
        "Let's take the scales of `'air_pollution'` and `'noise_pollution'` as an example. While the `'air_pollution'` values vary between 0.1 and 4,300, the `'noise_pollution'` values are only between 0.6 and 163. This does not mean that `'air_pollution'` is any more important than `'noise_pollution'`. Values in one column are not simply directly comparable with values in the other column. \n",
        "\n",
        "Nevertheless, ridge regression tries to minimize the slopes that use the scale of its feature. The ridge regression would therefore punish the slope of `'air_pollution'` much less than the increase of `'noise_pollution'`, because `'air_pollution'` has larger values on average and would therefore probably also have a smaller slope value.\n",
        "\n",
        "How can you tell the ridge regression to treat all features the same? You can use a trick. You standardize the values of each feature. This means that from each value in features ($x$) the mean of its own column ($\\bar{x}$) is subtracted and each value is divided by the standard deviation ($\\sigma$) of its column. As a formula that looks like this:\n",
        "\n",
        "<table style=\"float:left;\">\n",
        "    <tr><th align=\"left\">Word formula</th>\n",
        "        <th align=\"left\">math. Formula</th>\n",
        "    </tr>\n",
        "<tr>\n",
        "<td>\n",
        "\\begin{equation*}\n",
        "\\operatorname{feature_{standardized}} = \\frac{feature - mean_{feature}}{standard deviation_{feature}}\n",
        "\\end{equation*}\n",
        "    </td>\n",
        "<td>\n",
        "\\begin{equation*}\n",
        "\\operatorname{feature_{standard}} = \\frac{x - \\bar{x}}{\\sigma}\n",
        "\\end{equation*}  \n",
        "        </td>\n",
        "    </tr>\n",
        "</table>\n",
        "\n",
        "<br style=\"clear:both\">\n",
        "\n",
        "`StandardScaler` from `sklearn.preprocessing` implements this kind of standardization. Import `StandardScaler` directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "Wrote `from sklearn.preprocessing import StandardScaler` and run the cell.",
        "original-content": "# Solution:\nfrom sklearn.preprocessing import StandardScaler",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "# Solution:\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Now we can use `StandardScaler()` to build a scaler. Assign it to `scaler`.\n",
        "selectable": true
      },
      "source": [
        "Now we can use `StandardScaler()` to build a scaler. Assign it to `scaler`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cell_content_type": "code_demo",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "If you would like, you can discuss this in the forum under *Ridge Regularization*.",
        "original-content": "scaler = StandardScaler()",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "`scaler` calculates means and dispersions using the `my_scaler.fit()` method which it needs to standardize the data. The `my_scaler.transform()` method then standardizes the data with these values. We'll use the `my_scaler.fit_transform()` method here, which carries out both steps. You can ignore the warnings.\n",
        "selectable": true
      },
      "source": [
        "`scaler` calculates means and dispersions using the `my_scaler.fit()` method which it needs to standardize the data. The `my_scaler.transform()` method then standardizes the data with these values. We'll use the `my_scaler.fit_transform()` method here, which carries out both steps. You can ignore the warnings.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cell_content_type": "code_demo",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "If you would like, you can discuss this in the forum under *Ridge Regularization*.",
        "original-content": "features_train_standardized = scaler.fit_transform(features_train)",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "features_train_standardized = scaler.fit_transform(features_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "The warnings are harmless, as they do not affect how your code is executed, but they can become annoying. You can stop the warnings from appearing using the following ode. Try it out now.\n",
        "selectable": false
      },
      "source": [
        "The warnings are harmless, as they do not affect how your code is executed, but they can become annoying. You can stop the warnings from appearing using the following ode. Try it out now.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cell_content_type": "code_demo",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "If you would like, you can discuss this in the forum under *Ridge Regularization*.",
        "original-content": "#ignore DataConversionWarning\nfrom sklearn.exceptions import DataConversionWarning\nimport warnings\nwarnings.filterwarnings(action='ignore', category=DataConversionWarning)\n\n#test results\nfeatures_train_standardized = scaler.fit_transform(features_train)",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "#ignore DataConversionWarning\n",
        "from sklearn.exceptions import DataConversionWarning\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
        "\n",
        "#test results\n",
        "features_train_standardized = scaler.fit_transform(features_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Now the mean values of all columns in `features_train_standardized` should be zero, while the standard deviations (a measure for the dispersion of the data in the row `'std'`) in each column should be 1. We'll tell `pandas` to switch off the scientific notation and convert `features_train_standardized` into a `DataFrame`, and we can then display its eight-value summmary.\n",
        "selectable": true
      },
      "source": [
        "Now the mean values of all columns in `features_train_standardized` should be zero, while the standard deviations (a measure for the dispersion of the data in the row `'std'`) in each column should be 1. We'll tell `pandas` to switch off the scientific notation and convert `features_train_standardized` into a `DataFrame`, and we can then display its eight-value summmary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cell_content_type": "code_demo",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "If you would like, you can discuss this in the forum under *Ridge Regularization*.",
        "original-content": "pd.options.display.float_format = '{:.2f}'.format  # avoid scientific notation using exponent, display up to two digital places instead\npd.DataFrame(features_train_standardized).describe()  # eight value summary",
        "selectable": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.59</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>-1.40</td>\n",
              "      <td>-2.14</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>-1.12</td>\n",
              "      <td>-0.82</td>\n",
              "      <td>-2.66</td>\n",
              "      <td>-3.32</td>\n",
              "      <td>-2.15</td>\n",
              "      <td>-3.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>-0.79</td>\n",
              "      <td>-0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.47</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.27</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.92</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.29</td>\n",
              "      <td>4.21</td>\n",
              "      <td>2.04</td>\n",
              "      <td>2.96</td>\n",
              "      <td>5.12</td>\n",
              "      <td>5.24</td>\n",
              "      <td>4.78</td>\n",
              "      <td>2.55</td>\n",
              "      <td>1.26</td>\n",
              "      <td>2.17</td>\n",
              "      <td>2.14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1      2      3      4      5      6      7      8      9   \\\n",
              "count 314.00 314.00 314.00 314.00 314.00 314.00 314.00 314.00 314.00 314.00   \n",
              "mean    0.00  -0.00  -0.00   0.00   0.00   0.00   0.00   0.00  -0.00   0.00   \n",
              "std     1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   1.00   \n",
              "min    -1.59  -0.84  -1.40  -2.14  -0.76  -1.12  -0.82  -2.66  -3.32  -2.15   \n",
              "25%    -0.70  -0.62  -1.06  -0.75  -0.62  -0.61  -0.60  -0.73  -0.56  -0.79   \n",
              "50%    -0.15  -0.47  -0.03   0.04  -0.39  -0.27  -0.40  -0.09   0.27  -0.01   \n",
              "75%     0.92   0.26   0.66   0.54   0.14   0.23   0.19   0.70   0.80   0.81   \n",
              "max     2.29   4.21   2.04   2.96   5.12   5.24   4.78   2.55   1.26   2.17   \n",
              "\n",
              "          10  \n",
              "count 314.00  \n",
              "mean    0.00  \n",
              "std     1.00  \n",
              "min    -3.82  \n",
              "25%    -0.26  \n",
              "50%     0.35  \n",
              "75%     0.65  \n",
              "max     2.14  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.options.display.float_format = '{:.2f}'.format  # avoid scientific notation using exponent, display up to two digital places instead\n",
        "pd.DataFrame(features_train_standardized).describe()  # eight value summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "messageType": "beachte",
        "original-content": "**Attention**: Because of the conversion of the numpy array into a DataFrame, the information about the column names disappeared. When instantiating the `DataFrame` you can add the parameter `columns=features_train.columns` to restore the names. This might help you to interpret the numbers more easily.\n",
        "selectable": true
      },
      "source": [
        "**Attention**: Because of the conversion of the numpy array into a DataFrame, the information about the column names disappeared. When instantiating the `DataFrame` you can add the parameter `columns=features_train.columns` to restore the names. This might help you to interpret the numbers more easily.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "The function for converting a `numpy.array` into a `DataFrame` is `pd.DataFrame()`",
        "original-content": "#Solution\npd.DataFrame(features_train_standardized, columns=features_train.columns).describe()",
        "selectable": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>house_age</th>\n",
              "      <th>metro_distance</th>\n",
              "      <th>number_convenience_stores</th>\n",
              "      <th>number_parking_spaces</th>\n",
              "      <th>air_pollution</th>\n",
              "      <th>light_pollution</th>\n",
              "      <th>noise_pollution</th>\n",
              "      <th>neighborhood_quality</th>\n",
              "      <th>crime_score</th>\n",
              "      <th>energy_consumption</th>\n",
              "      <th>longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "      <td>314.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>-0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.59</td>\n",
              "      <td>-0.84</td>\n",
              "      <td>-1.40</td>\n",
              "      <td>-2.14</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>-1.12</td>\n",
              "      <td>-0.82</td>\n",
              "      <td>-2.66</td>\n",
              "      <td>-3.32</td>\n",
              "      <td>-2.15</td>\n",
              "      <td>-3.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.70</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-1.06</td>\n",
              "      <td>-0.75</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.61</td>\n",
              "      <td>-0.60</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>-0.56</td>\n",
              "      <td>-0.79</td>\n",
              "      <td>-0.26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.15</td>\n",
              "      <td>-0.47</td>\n",
              "      <td>-0.03</td>\n",
              "      <td>0.04</td>\n",
              "      <td>-0.39</td>\n",
              "      <td>-0.27</td>\n",
              "      <td>-0.40</td>\n",
              "      <td>-0.09</td>\n",
              "      <td>0.27</td>\n",
              "      <td>-0.01</td>\n",
              "      <td>0.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.92</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.29</td>\n",
              "      <td>4.21</td>\n",
              "      <td>2.04</td>\n",
              "      <td>2.96</td>\n",
              "      <td>5.12</td>\n",
              "      <td>5.24</td>\n",
              "      <td>4.78</td>\n",
              "      <td>2.55</td>\n",
              "      <td>1.26</td>\n",
              "      <td>2.17</td>\n",
              "      <td>2.14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       house_age  metro_distance  number_convenience_stores  \\\n",
              "count     314.00          314.00                     314.00   \n",
              "mean        0.00           -0.00                      -0.00   \n",
              "std         1.00            1.00                       1.00   \n",
              "min        -1.59           -0.84                      -1.40   \n",
              "25%        -0.70           -0.62                      -1.06   \n",
              "50%        -0.15           -0.47                      -0.03   \n",
              "75%         0.92            0.26                       0.66   \n",
              "max         2.29            4.21                       2.04   \n",
              "\n",
              "       number_parking_spaces  air_pollution  light_pollution  noise_pollution  \\\n",
              "count                 314.00         314.00           314.00           314.00   \n",
              "mean                    0.00           0.00             0.00             0.00   \n",
              "std                     1.00           1.00             1.00             1.00   \n",
              "min                    -2.14          -0.76            -1.12            -0.82   \n",
              "25%                    -0.75          -0.62            -0.61            -0.60   \n",
              "50%                     0.04          -0.39            -0.27            -0.40   \n",
              "75%                     0.54           0.14             0.23             0.19   \n",
              "max                     2.96           5.12             5.24             4.78   \n",
              "\n",
              "       neighborhood_quality  crime_score  energy_consumption  longitude  \n",
              "count                314.00       314.00              314.00     314.00  \n",
              "mean                   0.00        -0.00                0.00       0.00  \n",
              "std                    1.00         1.00                1.00       1.00  \n",
              "min                   -2.66        -3.32               -2.15      -3.82  \n",
              "25%                   -0.73        -0.56               -0.79      -0.26  \n",
              "50%                   -0.09         0.27               -0.01       0.35  \n",
              "75%                    0.70         0.80                0.81       0.65  \n",
              "max                    2.55         1.26                2.17       2.14  "
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Solution\n",
        "pd.DataFrame(features_train_standardized, columns=features_train.columns).describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "As you predicted earlier, This means that the feature values are now comparable. They now use the same scale. This means that the ridge regression will no longer penalize the slope of one feature more than another.\n",
        "selectable": false
      },
      "source": [
        "As you predicted earlier, This means that the feature values are now comparable. They now use the same scale. This means that the ridge regression will no longer penalize the slope of one feature more than another.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Now use the `my_model.fit()` method with `model_ridge` together with the standardized feature matrix `features_train_standardized` and `target_train` to fit the ridge regression model to the data.\n",
        "selectable": true
      },
      "source": [
        "Now use the `my_model.fit()` method with `model_ridge` together with the standardized feature matrix `features_train_standardized` and `target_train` to fit the ridge regression model to the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "Write `model_ridge.fit(features_train_standardized, target_train)` and run the cell.",
        "original-content": "# Solution:\nmodel_ridge.fit(features_train_standardized, target_train)",
        "selectable": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ridge(alpha=1500)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Solution:\n",
        "model_ridge.fit(features_train_standardized, target_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Now visualize the slope values of the ridge regression in a bar chart to find out which are the most important features in the ridge model. Because all slope values are on the same standardized scale, you can compare them directly.\n",
        "selectable": false
      },
      "source": [
        "Now visualize the slope values of the ridge regression in a bar chart to find out which are the most important features in the ridge model. Because all slope values are on the same standardized scale, you can compare them directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "The values for the coefficients can be found in `model_ridge.coef_`. If you convert it to a `pd.Series`, you can use the `plot.bar()` method.",
        "original-content": "# Solution:\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1,figsize=(6,6))\npd.Series(model_ridge.coef_, index=features_train.columns).sort_values().plot.bar(ax=ax)\nax.set_title('Feature Weights in Ridgemodel')\nax.set_ylabel('Weight (standardized)')\nax.set_xlabel('Feature')\nfig.tight_layout()",
        "selectable": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Solution:\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots(1,figsize=(6,6))\n",
        "pd.Series(model_ridge.coef_, index=features_train.columns).sort_values().plot.bar(ax=ax)\n",
        "ax.set_title('Feature Weights in Ridgemodel')\n",
        "ax.set_ylabel('Weight (standardized)')\n",
        "ax.set_xlabel('Feature')\n",
        "fig.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Your visualization should now look something like this:\n\n<img src=\"01_01_08_pic01_featureWeightsPlot_en.png\"  align=\"left\">\n",
        "selectable": false
      },
      "source": [
        "Your visualization should now look something like this:\n",
        "\n",
        "<img src=\"01_01_08_pic01_featureWeightsPlot_en.png\"  align=\"left\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "messageType": "glueckwunsch",
        "original-content": "**Congratulations:** You fitted your first ridge regression model to the data. How good is it actually? Next we will evaluate the model quality using the independent test data.\n",
        "selectable": false
      },
      "source": [
        "**Congratulations:** You fitted your first ridge regression model to the data. How good is it actually? Next we will evaluate the model quality using the independent test data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "## Determing the ridge regression model quality\n",
        "selectable": false
      },
      "source": [
        "## Determing the ridge regression model quality\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Assessing the model quality requires the prediction of target values. For that we need the feature matrix and the target vector with the data from `df_test`. Save them in `features_test` and `target_test`.\n",
        "selectable": true
      },
      "source": [
        "Assessing the model quality requires the prediction of target values. For that we need the feature matrix and the target vector with the data from `df_test`. Save them in `features_test` and `target_test`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "Use the fourth code cell of this lesson as a guide.",
        "original-content": "# Solution:\nfeatures_test = df_test.loc[:, col_names[:-1]]\ntarget_test = df_test.loc[:, 'price_per_m2']",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "# Solution:\n",
        "features_test = df_test.loc[:, col_names[:-1]]\n",
        "target_test = df_test.loc[:, 'price_per_m2']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "The feature matrix `features_test` doesn't use a uniform scale yet. In order to use the same scale as above, `scaler` should transform the test data exactly as it did the training data. We therefore have to carry out the `my_scaler.transform()` step with the test data set.\n",
        "selectable": true
      },
      "source": [
        "The feature matrix `features_test` doesn't use a uniform scale yet. In order to use the same scale as above, `scaler` should transform the test data exactly as it did the training data. We therefore have to carry out the `my_scaler.transform()` step with the test data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "cell_content_type": "code_demo",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "If you would like, you can discuss this in the forum under *Ridge Regularization*.",
        "hint_counter": 0,
        "original-content": "features_test_standardized = scaler.transform(features_test)",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "features_test_standardized = scaler.transform(features_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "messageType": "beachte",
        "original-content": "**Important:**\nThe separation of training and test data is an important principle in the data science process.\n\nRemember this: **Only ever fit to the training set!**\n\nOnce a *scaler* or other *transformer* has been fitted, you can apply it to all the data sets.\n",
        "selectable": false
      },
      "source": [
        "**Important:**\n",
        "The separation of training and test data is an important principle in the data science process.\n",
        "\n",
        "Remember this: **Only ever fit to the training set!**\n",
        "\n",
        "Once a *scaler* or other *transformer* has been fitted, you can apply it to all the data sets.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "If we now look at the eight-value summary of `features_test_standardized`, it becomes apparent that the features now don't quite exactly have a mean value of zero and a dispersion (standard deviation) of one. This is to do with the fact that the standardization used the mean and dispersion values from the training data set.\n",
        "selectable": true
      },
      "source": [
        "If we now look at the eight-value summary of `features_test_standardized`, it becomes apparent that the features now don't quite exactly have a mean value of zero and a dispersion (standard deviation) of one. This is to do with the fact that the standardization used the mean and dispersion values from the training data set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "cell_content_type": "code_demo",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "If you would like, you can discuss this in the forum under *Ridge Regularization*.",
        "original-content": "pd.DataFrame(features_test_standardized).describe()  # eight value summary",
        "selectable": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "      <td>110.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.22</td>\n",
              "      <td>-0.04</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.29</td>\n",
              "      <td>-0.10</td>\n",
              "      <td>-1.47</td>\n",
              "      <td>5.51</td>\n",
              "      <td>0.12</td>\n",
              "      <td>-0.06</td>\n",
              "      <td>-0.07</td>\n",
              "      <td>-0.08</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.01</td>\n",
              "      <td>1.02</td>\n",
              "      <td>1.23</td>\n",
              "      <td>2.03</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0.61</td>\n",
              "      <td>2.52</td>\n",
              "      <td>0.96</td>\n",
              "      <td>1.04</td>\n",
              "      <td>1.03</td>\n",
              "      <td>1.03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.59</td>\n",
              "      <td>-0.85</td>\n",
              "      <td>-1.40</td>\n",
              "      <td>-2.14</td>\n",
              "      <td>-0.76</td>\n",
              "      <td>-1.63</td>\n",
              "      <td>-0.73</td>\n",
              "      <td>-2.06</td>\n",
              "      <td>-2.87</td>\n",
              "      <td>-2.15</td>\n",
              "      <td>-3.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-1.09</td>\n",
              "      <td>-0.71</td>\n",
              "      <td>-0.71</td>\n",
              "      <td>-0.49</td>\n",
              "      <td>-0.70</td>\n",
              "      <td>-1.63</td>\n",
              "      <td>4.06</td>\n",
              "      <td>-0.54</td>\n",
              "      <td>-0.62</td>\n",
              "      <td>-0.99</td>\n",
              "      <td>-1.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.39</td>\n",
              "      <td>-0.52</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-0.51</td>\n",
              "      <td>-1.62</td>\n",
              "      <td>5.48</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.32</td>\n",
              "      <td>0.50</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.09</td>\n",
              "      <td>-1.61</td>\n",
              "      <td>7.44</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.19</td>\n",
              "      <td>4.28</td>\n",
              "      <td>5.81</td>\n",
              "      <td>18.68</td>\n",
              "      <td>3.83</td>\n",
              "      <td>3.22</td>\n",
              "      <td>9.45</td>\n",
              "      <td>2.77</td>\n",
              "      <td>1.26</td>\n",
              "      <td>2.18</td>\n",
              "      <td>1.70</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0      1      2      3      4      5      6      7      8      9   \\\n",
              "count 110.00 110.00 110.00 110.00 110.00 110.00 110.00 110.00 110.00 110.00   \n",
              "mean   -0.22  -0.04   0.28   0.29  -0.10  -1.47   5.51   0.12  -0.06  -0.07   \n",
              "std     1.01   1.02   1.23   2.03   0.89   0.61   2.52   0.96   1.04   1.03   \n",
              "min    -1.59  -0.85  -1.40  -2.14  -0.76  -1.63  -0.73  -2.06  -2.87  -2.15   \n",
              "25%    -1.09  -0.71  -0.71  -0.49  -0.70  -1.63   4.06  -0.54  -0.62  -0.99   \n",
              "50%    -0.39  -0.52   0.32   0.09  -0.51  -1.62   5.48   0.12   0.17   0.01   \n",
              "75%     0.32   0.50   1.00   0.63   0.09  -1.61   7.44   0.79   0.73   0.72   \n",
              "max     2.19   4.28   5.81  18.68   3.83   3.22   9.45   2.77   1.26   2.18   \n",
              "\n",
              "          10  \n",
              "count 110.00  \n",
              "mean   -0.08  \n",
              "std     1.03  \n",
              "min    -3.92  \n",
              "25%    -1.04  \n",
              "50%     0.32  \n",
              "75%     0.62  \n",
              "max     1.70  "
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(features_test_standardized).describe()  # eight value summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Now calculate the predicted house prices of the test data set using the `my_model.predict()` method with `model_ridge`. Note that it should now get the standardized features of the test data set. Store the predicted house prices in the variable `target_test_pred_ridge`.\n",
        "selectable": true
      },
      "source": [
        "Now calculate the predicted house prices of the test data set using the `my_model.predict()` method with `model_ridge`. Note that it should now get the standardized features of the test data set. Store the predicted house prices in the variable `target_test_pred_ridge`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "Write `target_test_pred_ridge = model_ridge.predict(features_test_standardized)` and run the cell.",
        "original-content": "# Solution:\ntarget_test_pred_ridge = model_ridge.predict(features_test_standardized)",
        "selectable": true
      },
      "outputs": [],
      "source": [
        "# Solution:\n",
        "target_test_pred_ridge = model_ridge.predict(features_test_standardized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "With `target_test` and `target_test_pred_ridge` you now have everything you need to calculate the *mean squared error* , *RMSE* and *R\u00b2* model quality metrics. Print these values.\n",
        "selectable": true
      },
      "source": [
        "With `target_test` and `target_test_pred_ridge` you now have everything you need to calculate the *mean squared error* , *RMSE* and *R\u00b2* model quality metrics. Print these values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "cell_content_type": "code_user",
        "changed": false,
        "deletable": false,
        "editable": true,
        "hint": "First import the associated functions, for example like this: `from sklearn.metrics import mean_squared_error`.",
        "original-content": "# Solution:\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\nprint('MSE: ', mean_squared_error(target_test, target_test_pred_ridge))\nprint('RMSE: ', np.sqrt(mean_squared_error(target_test, target_test_pred_ridge)))\nprint('R2: ', r2_score(target_test, target_test_pred_ridge))",
        "selectable": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE:  10.834407403869\n",
            "RMSE:  3.2915661020050924\n",
            "R2:  0.18093724447993753\n"
          ]
        }
      ],
      "source": [
        "# Solution:\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "print('MSE: ', mean_squared_error(target_test, target_test_pred_ridge))\n",
        "print('RMSE: ', np.sqrt(mean_squared_error(target_test, target_test_pred_ridge)))\n",
        "print('R2: ', r2_score(target_test, target_test_pred_ridge))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "How good are these values compared to the other regressions we calculated in this chapter?\n",
        "selectable": false
      },
      "source": [
        "How good are these values compared to the other regressions we calculated in this chapter?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "Looking at the performance of the other models we've worked with so far, we get the following table:\n\nModel| Test: *MSE* | Test: *R\u00b2*\n---|---|---\n`model_age`| 11.89 | 10.1%\n`model_metro`| 10.27 | 22.4%\n`model_stores`| 11.29 | 14.7%\n`model_multiple`| 9.72 | 26.5%\n`model_multiple_all`| 31.77 | -140.2%\n`model_ridge`| 10.83 | 18.1%\n",
        "selectable": true
      },
      "source": [
        "Looking at the performance of the other models we've worked with so far, we get the following table:\n",
        "\n",
        "Model| Test: *MSE* | Test: *R\u00b2*\n",
        "---|---|---\n",
        "`model_age`| 11.89 | 10.1%\n",
        "`model_metro`| 10.27 | 22.4%\n",
        "`model_stores`| 11.29 | 14.7%\n",
        "`model_multiple`| 9.72 | 26.5%\n",
        "`model_multiple_all`| 31.77 | -140.2%\n",
        "`model_ridge`| 10.83 | 18.1%\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "messageType": "glueckwunsch",
        "original-content": "**Congratulations:** You used a ridge regression to use all features in a model without leading to severe overfitting. The quality metrics based on test data are better for the ridge regression with eleven features than for the multiple linear regression with eleven features \n\nRidge regressions are popular when people want to avoid overfitting and when features correlate with each other. However, they are not suitable for completely removing unimportant features. To do that, you should then look at lasso regressions. We'll cover this approach for *feature selection* in the next lesson.\n",
        "selectable": false
      },
      "source": [
        "**Congratulations:** You used a ridge regression to use all features in a model without leading to severe overfitting. The quality metrics based on test data are better for the ridge regression with eleven features than for the multiple linear regression with eleven features \n",
        "\n",
        "Ridge regressions are popular when people want to avoid overfitting and when features correlate with each other. However, they are not suitable for completely removing unimportant features. To do that, you should then look at lasso regressions. We'll cover this approach for *feature selection* in the next lesson.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_selectable",
        "changed": false,
        "deletable": false,
        "editable": false,
        "messageType": "merke",
        "original-content": "**Remember:**\n* `Ridge` minimizes the sum of the squared slope values\n* `Ridge` is suitable to prevent overfitting and colinearity\n* **Only ever fit to the training set!**\n",
        "selectable": true
      },
      "source": [
        "**Remember:**\n",
        "* `Ridge` minimizes the sum of the squared slope values\n",
        "* `Ridge` is suitable to prevent overfitting and colinearity\n",
        "* **Only ever fit to the training set!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "messageType": "literatur",
        "original-content": "**Literature:**\nIf you would like to delve deeper into the subject matter of this chapter, we recommend the following source(s):\n* G\u00e9ron, Aur\u00e9lien. 2017. *Hands-On Machine Learning with Scikit-Learn & TensorFlow*. Sebastopol : O'Reilly, 2017. p. 108 pp.",
        "selectable": false
      },
      "source": [
        "**Literature:**\n",
        "If you would like to delve deeper into the subject matter of this chapter, we recommend the following source(s):\n",
        "* G\u00e9ron, Aur\u00e9lien. 2017. *Hands-On Machine Learning with Scikit-Learn & TensorFlow*. Sebastopol : O'Reilly, 2017. p. 108 pp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_content_type": "markdown_default",
        "changed": false,
        "deletable": false,
        "editable": false,
        "original-content": "***\nDo you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n***\nFound a mistake? Contact Support at support@stackfuel.com.\n***\n",
        "selectable": false
      },
      "source": [
        "***\n",
        "Do you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n",
        "***\n",
        "Found a mistake? Contact Support at support@stackfuel.com.\n",
        "***\n"
      ]
    }
  ],
  "metadata": {
    "content_id": "350a9f9a-35c5-458e-a203-c5924a4bafb1",
    "content_language": "en",
    "content_title": "Ridge Regularization",
    "content_type": "solution",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}