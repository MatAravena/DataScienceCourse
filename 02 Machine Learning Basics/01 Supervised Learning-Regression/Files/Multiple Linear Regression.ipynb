{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "# Multiple Linear Regression (Solution)\nModule 1 | Chapter 1 | Notebook 6\n\n***\nIn this notebook we'll expand the simple linear regression model to use more than one feature to make predictions. Thanks to the metrics and visualizations for model quality that you got to know, you can assess whether the model with several features is better than the models with only one feature each. By the end of this lesson you will be able to:\n* Use multiple linear regression\n* Examine the assumptions of a multiple linear regression\n***\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "# Multiple Linear Regression\n",
    "Module 1 | Chapter 1 | Notebook 6\n",
    "\n",
    "***\n",
    "In this notebook we'll expand the simple linear regression model to use more than one feature to make predictions. Thanks to the metrics and visualizations for model quality that you got to know, you can assess whether the model with several features is better than the models with only one feature each. By the end of this lesson you will be able to:\n",
    "* Use multiple linear regression\n",
    "* Examine the assumptions of a multiple linear regression\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## Multiple linear regression\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "## Multiple linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "szenario",
    "original-content": "**Scenario:** A Taiwanese investor comes to you to find out how much his properties in Taiwan are actually worth. He might want to resell them. The data on the houses is located in *Taiwan_real_estate_prediction_data.xlsx*. \n\nHe looked at your prediction based on the proximity to nearest metro station and based on the age of the house and based on food stores in the area. The investor is asking you to look at how much his houses are worth, if you use multiple features at the same time rather than just using one at a time. The training data is in *Taiwan_real_estate_training_data.xlsx*.\n",
    "protected": false,
    "selectable": true
   },
   "source": [
    "**Scenario:** A Taiwanese investor comes to you to find out how much his properties in Taiwan are actually worth. He might want to resell them. The data on the houses is located in *Taiwan_real_estate_prediction_data.xlsx*. \n",
    "\n",
    "He looked at your prediction based on the proximity to nearest metro station and based on the age of the house and based on food stores in the area. The investor is asking you to look at how much his houses are worth, if you use multiple features at the same time rather than just using one at a time. The training data is in *Taiwan_real_estate_training_data.xlsx*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "In order to get started quickly, let's import the data and process it like we did in the last lesson.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "In order to get started quickly, let's import the data and process it like we did in the last lesson.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_content_type": "code_demo",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "If you would like, you can discuss this in the forum under *Multiple Linear Regression*.",
    "original-content": "import pandas as pd\ndf = pd.read_excel('Taiwan_real_estate_training_data.xlsx', index_col='No')\ncol_names = ['house_age', \n              'metro_distance', \n              'number_convenience_stores', \n              'number_parking_spaces',\n              'air_pollution',\n              'light_pollution',\n              'noise_pollution',\n              'neighborhood_quality',\n              'crime_score',\n              'energy_consumption',\n              'longitude', \n              'price_per_ping']\ndf.columns = col_names\ndf.loc[:, 'price_per_m2'] = df.loc[:, 'price_per_ping'] / 3.3",
    "protected": false,
    "selectable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel('Taiwan_real_estate_training_data.xlsx', index_col='No')\n",
    "col_names = ['house_age', \n",
    "              'metro_distance', \n",
    "              'number_convenience_stores', \n",
    "              'number_parking_spaces',\n",
    "              'air_pollution',\n",
    "              'light_pollution',\n",
    "              'noise_pollution',\n",
    "              'neighborhood_quality',\n",
    "              'crime_score',\n",
    "              'energy_consumption',\n",
    "              'longitude', \n",
    "              'price_per_ping']\n",
    "df.columns = col_names\n",
    "df.loc[:, 'price_per_m2'] = df.loc[:, 'price_per_ping'] / 3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "The data dictionary for this data is as follows:\n\nColumn number | Column name       | Type      | Description\n ------------ | ---     | :---------:           | ------------:\n0              | `'house_age'` | continuous (`float`) | age of the house in years\n1              | `'metro_distance'` | continuous (`float`) | distance in meters to the next metro station\n2              | `'number_convenience_stores'` | continuous (`int`) | Number of convenience stores nearby\n3              | `'number_parking_spaces'` | continuous (`int`) | Number of parking spaces nearby\n4              | `'air_pollution'` | continuous (`float`) | Air pollution value near the house\n5              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n6              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n7              | `'neighborhood_quality'` | continuous (`float`) | average Quality of life in the neighborhood\n8              | `'crime_score'` | continuous (`float`) | crime score according to police\n9              | `'energy_consumption'` | continuous (`float`) | The property's energy consumption\n10              | `'longitude'` | continuous (`float`) | The property's longitude\n11              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per ping, one ping is 3.3 square meters\n12              | `'price_per_ping'` | continuous (`'float'`) | House price in Taiwan dollars per m²\n",
    "protected": false,
    "selectable": true
   },
   "source": [
    "The data dictionary for this data is as follows:\n",
    "\n",
    "Column number | Column name       | Type      | Description\n",
    " ------------ | ---     | :---------:           | ------------:\n",
    "0              | `'house_age'` | continuous (`float`) | age of the house in years\n",
    "1              | `'metro_distance'` | continuous (`float`) | distance in meters to the next metro station\n",
    "2              | `'number_convenience_stores'` | continuous (`int`) | Number of convenience stores nearby\n",
    "3              | `'number_parking_spaces'` | continuous (`int`) | Number of parking spaces nearby\n",
    "4              | `'air_pollution'` | continuous (`float`) | Air pollution value near the house\n",
    "5              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n",
    "6              | `'light_pollution'` | continuous (`float`) | Light pollution value near the house\n",
    "7              | `'neighborhood_quality'` | continuous (`float`) | average Quality of life in the neighborhood\n",
    "8              | `'crime_score'` | continuous (`float`) | crime score according to police\n",
    "9              | `'energy_consumption'` | continuous (`float`) | The property's energy consumption\n",
    "10              | `'longitude'` | continuous (`float`) | The property's longitude\n",
    "11              | `'price_per_ping'` | continuous (`float`) | House price in Taiwan dollars per ping, one ping is 3.3 square meters\n",
    "12              | `'price_per_ping'` | continuous (`'float'`) | House price in Taiwan dollars per m²\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Since the lesson *Simple linear regression with sklearn* you know that regression models follow this formula:\n\n\\begin{equation*}\nTarget = intercept + (slope \\cdot Feature) + error\n\\end{equation*}\n\nMultiple linear regression uses several features simultaneously to make predictions for the data. Each feature ($Feature_1$ and $Feature_2$) gets its own slope ($slope_1$ and $slope_2$). This also changes the formula, which looks like this for two features:\n\n\\begin{equation*}\nTarget = intercept + (slope_1 \\cdot Feature_1) + (slope_2 \\cdot Feature_2) + error\n\\end{equation*}\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "Since the lesson *Simple linear regression with sklearn* you know that regression models follow this formula:\n",
    "\n",
    "\\begin{equation*}\n",
    "Target = intercept + (slope \\cdot Feature) + error\n",
    "\\end{equation*}\n",
    "\n",
    "Multiple linear regression uses several features simultaneously to make predictions for the data. Each feature ($Feature_1$ and $Feature_2$) gets its own slope ($slope_1$ and $slope_2$). This also changes the formula, which looks like this for two features:\n",
    "\n",
    "\\begin{equation*}\n",
    "Target = intercept + (slope_1 \\cdot Feature_1) + (slope_2 \\cdot Feature_2) + error\n",
    "\\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "vertiefung",
    "original-content": "**Deep dive**: The following content is optional, feel free to skip it.<br>\nYou can generalize this formula using matrices and vectors:\n\n<table style=\"float:left;\">\n    <tr><th align=\"center\">Word formula</th>\n        <th align=\"center\">math. Formula</th>\n    </tr>\n<tr>\n<td>\n\\begin{equation*}\nprediction vector = feature matrix \\cdot slope vector + intercept + error vector\n\\end{equation*}\n    </td>\n<td>\n\\begin{equation*}\n\\hat{y} = X\\cdot\\vec{\\beta} + \\beta_{0} + \\vec{\\epsilon}\n\\end{equation*}    \n        </td>\n    </tr>\n</table>\n\n<br style=\"clear:both\">When predicting with the model, the intercept ($\\beta_{0}$) is converted by *broadcasting* into a vector with the same length as the slope vector and then the equation can be solved - we get our predictions $\\hat{y}$\n\nIn sklearn this *broadcasting* step is omitted, instead the intercept is written in the zero position of the slope vector. Since this is an additional constant, a column is added to the feature matrix at position 0. This column is filled with ones so that the scalar product of the feature matrix and slope vector is always increased by the value of the intercept when calculating the prediction. This conversion is equivalent to our calculation above.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "**Deep dive**: The following content is optional, feel free to skip it.<br>\n",
    "You can generalize this formula using matrices and vectors:\n",
    "\n",
    "<table style=\"float:left;\">\n",
    "    <tr><th align=\"center\">Word formula</th>\n",
    "        <th align=\"center\">math. Formula</th>\n",
    "    </tr>\n",
    "<tr>\n",
    "<td>\n",
    "\\begin{equation*}\n",
    "prediction vector = feature matrix \\cdot slope vector + intercept + error vector\n",
    "\\end{equation*}\n",
    "    </td>\n",
    "<td>\n",
    "\\begin{equation*}\n",
    "\\hat{y} = X\\cdot\\vec{\\beta} + \\beta_{0} + \\vec{\\epsilon}\n",
    "\\end{equation*}    \n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br style=\"clear:both\">When predicting with the model, the intercept ($\\beta_{0}$) is converted by *broadcasting* into a vector with the same length as the slope vector and then the equation can be solved - we get our predictions $\\hat{y}$\n",
    "\n",
    "In sklearn this *broadcasting* step is omitted, instead the intercept is written in the zero position of the slope vector. Since this is an additional constant, a column is added to the feature matrix at position 0. This column is filled with ones so that the scalar product of the feature matrix and slope vector is always increased by the value of the intercept when calculating the prediction. This conversion is equivalent to our calculation above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "We can also imagine the difference graphically. While in simple linear regression with one feature we fit a line to points in an area, in multiple linear regression with two features we fit a plane to points in space.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "We can also imagine the difference graphically. While in simple linear regression with one feature we fit a line to points in an area, in multiple linear regression with two features we fit a plane to points in space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "So the parameters of a regression with one feature describe a line like this:\n\n![simple linear regression](01_01_05_pic1_en.png)\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "So the parameters of a regression with one feature describe a line like this:\n",
    "\n",
    "![simple linear regression](01_01_05_pic1_en.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "So the parameters of a regression with two feature describe a plane like this:\n\n![multiple linear regression](01_01_05_pic2_en.png)\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "So the parameters of a regression with two feature describe a plane like this:\n",
    "\n",
    "![multiple linear regression](01_01_05_pic2_en.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "If you add even more features, this is what we call a hyperplane, which you can no longer imagine spatially. This hyperplane has as many dimensions as there are features.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "If you add even more features, this is what we call a hyperplane, which you can no longer imagine spatially. This hyperplane has as many dimensions as there are features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "beachte",
    "original-content": "**Note:**\nThe term **linear regression** does not, as people often assume, come from the fact that we draw a line through the data points. As you have seen, a line is only used in the special case of linear regression with just one feature. In all other cases we use a (hyper)plane rather than a line. The name linear regression is derived from the linear combination of the matrices and vectors of the regression model.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "**Note:**\n",
    "The term **linear regression** does not, as people often assume, come from the fact that we draw a line through the data points. As you have seen, a line is only used in the special case of linear regression with just one feature. In all other cases we use a (hyper)plane rather than a line. The name linear regression is derived from the linear combination of the matrices and vectors of the regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Now let's try out a multiple linear regression. We'll follow the same five steps again:\n1. Select model type: `Linear Regression`\n2. Instantiate the model with certain hyperparameters: Store standard model with axis intercept in `model_multiple`\n3. Organize data into a feature matrix and target vector: `features` and `target`\n4. Model fitting: use `my_model.fit()`\n5. Make predictions with the trained model: use `my_model.predict()`\n\nWe'll stick with  `LinearRegression` from the `sklearn.linear_model` module. Import it.\n",
    "protected": false,
    "selectable": true
   },
   "source": [
    "Now let's try out a multiple linear regression. We'll follow the same five steps again:\n",
    "1. Select model type: `Linear Regression`\n",
    "2. Instantiate the model with certain hyperparameters: Store standard model with axis intercept in `model_multiple`\n",
    "3. Organize data into a feature matrix and target vector: `features` and `target`\n",
    "4. Model fitting: use `my_model.fit()`\n",
    "5. Make predictions with the trained model: use `my_model.predict()`\n",
    "\n",
    "We'll stick with  `LinearRegression` from the `sklearn.linear_model` module. Import it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Write `from sklearn.linear_model import LinearRegression` and run the cell.",
    "hint_counter": 1,
    "original-content": "",
    "protected": false,
    "selectable": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Also the second step is no different to in a simple linear regression. In this case we'll call the model `model_multiple`.\n",
    "protected": false,
    "selectable": true
   },
   "source": [
    "Also the second step is no different to in a simple linear regression. In this case we'll call the model `model_multiple`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Write `model_multiple = LinearRegression()` and run the cell.",
    "original-content": "",
    "protected": false,
    "selectable": true
   },
   "outputs": [],
   "source": [
    "model_multiple = LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "A difference only becomes apparent in the third step. The feature matrix now includes more than one feature. We'll use the `'house_age'` and `'metro_distance'` columns.\n",
    "protected": false,
    "selectable": true
   },
   "source": [
    "A difference only becomes apparent in the third step. The feature matrix now includes more than one feature. We'll use the `'house_age'` and `'metro_distance'` columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_content_type": "code_demo",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "If you would like, you can discuss this in the forum under *Multiple Linear Regression*.",
    "original-content": "# step 3\nfeatures_multiple = df.loc[:, ['house_age', 'metro_distance']]\ntarget = df.loc[:, 'price_per_m2']",
    "protected": false,
    "selectable": true
   },
   "outputs": [],
   "source": [
    "# step 3\n",
    "features_multiple = df.loc[:, ['house_age', 'metro_distance']]\n",
    "target = df.loc[:, 'price_per_m2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "In the fourth step (*model fitting*) two slopes are now calculated: one slope for the `'house_age'` and one slope for the `'metro_distance'` feature. Use the model `model_multiple` together with the feature matrix `features_multiple` and the target vector `target` to fit a multiple linear regression model to the data. Then print the slopes in `model_multiple.coef_` and the intercept in `model_multiple.intercept_`.\n",
    "protected": false,
    "selectable": true
   },
   "source": [
    "In the fourth step (*model fitting*) two slopes are now calculated: one slope for the `'house_age'` and one slope for the `'metro_distance'` feature. Use the model `model_multiple` together with the feature matrix `features_multiple` and the target vector `target` to fit a multiple linear regression model to the data. Then print the slopes in `model_multiple.coef_` and the intercept in `model_multiple.intercept_`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "The first line of the cell should look like this: `model_multiple.fit(features_multiple, target)`.",
    "original-content": "",
    "protected": false,
    "selectable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07615426 -0.00218815]\n",
      "15.277396784757384\n"
     ]
    }
   ],
   "source": [
    "model_multiple.fit(features_multiple, target)\n",
    "print(model_multiple.coef_)\n",
    "print(model_multiple.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "The interpretation of the parameters has not changed. The model predicts that with each additional year of age for the property, its value decreases by $0.08 per square meter. With every meter of distance to the nearest metro station, the value of the property decreases by 0.02 dollars.\n\nWe can now determine the model quality using the *mean quared error* and *R²* values as before. Does the multiple linear regression model perform better than the simple linear regression models?\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "The interpretation of the parameters has not changed. The model predicts that with each additional year of age for the property, its value decreases by $0.08 per square meter. With every meter of distance to the nearest metro station, the value of the property decreases by 0.02 dollars.\n",
    "\n",
    "We can now determine the model quality using the *mean quared error* and *R²* values as before. Does the multiple linear regression model perform better than the simple linear regression models?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "First import the `mean_squared_error()` and `r2_score()`functions. The first line of the cell should look like this: `target_pred_multiple = model_multiple.predict(features_multiple)`.",
    "original-content": "",
    "protected": false,
    "selectable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.337033633449392\n",
      "0.4780649322899778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "target_pred = model_multiple.predict(features_multiple)\n",
    "\n",
    "\n",
    "print(mean_squared_error(target, target_pred))\n",
    "print(r2_score(target, target_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "It's true. If we summarize all the models calculated so far in a table, you'll notice that both the mean squared error and the coefficient of determination are better in the multiple linear regression.\n\nModel| *MSE*| *R²*\n---|---|---\n`model_age`| 16.97 | 5.1%\n`model_metro`| 10.07 | 43.7%\n`model_stores`| 12.21 | 31.8%\n`model_multiple`| 9.34 | 47.8%\n",
    "protected": false,
    "selectable": true
   },
   "source": [
    "It's true. If we summarize all the models calculated so far in a table, you'll notice that both the mean squared error and the coefficient of determination are better in the multiple linear regression.\n",
    "\n",
    "Model| *MSE*| *R²*\n",
    "---|---|---\n",
    "`model_age`| 16.97 | 5.1%\n",
    "`model_metro`| 10.07 | 43.7%\n",
    "`model_stores`| 12.21 | 31.8%\n",
    "`model_multiple`| 9.34 | 47.8%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "We can now look at the regression plane visually. 3D visualizations are not part of this module. So here's this image for now:\n\n![multiple linear regression](01_01_05_pic3_en.png)\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "We can now look at the regression plane visually. 3D visualizations are not part of this module. So here's this image for now:\n",
    "\n",
    "![multiple linear regression](01_01_05_pic3_en.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "In multiple linear regression, the residuals are the vertical distances between the actual data points and the regression plane. So we can take another look at a residual plot to see whether the assumptions of the regression model are correct. \n\nCreate a residual plot with the predicted real estate prices on the x-axis and the residuals on the y-axis. Don't forget to draw a zero line to make it easier to interpret the graph.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "In multiple linear regression, the residuals are the vertical distances between the actual data points and the regression plane. So we can take another look at a residual plot to see whether the assumptions of the regression model are correct. \n",
    "\n",
    "Create a residual plot with the predicted real estate prices on the x-axis and the residuals on the y-axis. Don't forget to draw a zero line to make it easier to interpret the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "You learned how to best draw a residual graph in *Assumptions of the Linear Regression Model*. Use the `my_ax.scatter()` function or the `seaborn.scatterplot()` function. For both options you have to assign the predicted house prices (`target_pred_multiple`) to an `x` argument and the residuals (`residuals`) to a `y` argument.",
    "hint_counter": 3,
    "original-content": "",
    "protected": false,
    "selectable": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, axs = plt.subplots( )\n",
    "\n",
    "target_pred_multiple = model_multiple.predict(features_multiple)\n",
    "residuals = target - target_pred_multiple\n",
    "\n",
    "residuals = target - target_pred\n",
    "sns.scatterplot(x=target_pred_multiple,\n",
    "                y=residuals,\n",
    "                ax=axs);\n",
    "\n",
    "axs.hlines(y=0,\n",
    "          xmin=target_pred.min(),\n",
    "          xmax=target_pred.max(),\n",
    "          color='black')\n",
    "axs.set(ylabel='Residuals',xlabel='Predicted y-values');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "The residual plot should now look something like this:\n\n![residuals graph](01_01_05_pic4_en.png)\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "The residual plot should now look something like this:\n",
    "\n",
    "![residuals graph](01_01_05_pic4_en.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Our evaluation of the residual plot is that the data points are concentrated on the right. One assumption of the linear regression model (linear dependency) is not quite fulfilled here.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "Our evaluation of the residual plot is that the data points are concentrated on the right. One assumption of the linear regression model (linear dependency) is not quite fulfilled here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "glueckwunsch",
    "original-content": "**Congratulations:** You have created your first multiple linear regression. Now you can use several features at the same time to predict continuous values. However, you should consider a new assumption. We'll look at that next.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "**Congratulations:** You have created your first multiple linear regression. Now you can use several features at the same time to predict continuous values. However, you should consider a new assumption. We'll look at that next.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "## Assumptions of the multiple linear regression\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "## Assumptions of the multiple linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "We have already interpreted the calculated increases of the features. The model predicts that with every additional year of age, the property prices lose 0.83 dollars per square meter. With every meter of distance to the nearest metro station, the value of the property decreases by 0.02 dollars. \n\nIt's noticeable that this interpretation assumes an independence of age and metro distance. The age of the property says nothing about its metro distance, and vice versa. So, you don't say things like \"Older properties are generally located further away from metro stations and are therefore worth less\", but \"older properties are simply older and therefore worth less\".\n\nOverall, multiple linear regression is therefore made up of the four assumptions of the simple linear regression model and additionally the assumption of feature independence:\n1. The data points are independent from each other\n2. There is a linear dependency between feature and target\n3. The residuals are normally distributed\n4. The residuals have a constant variance\n5. The Features are independent from each other\n\nIf the fifth assumption is violated, we call this collinearity, i.e. a linear dependence between features. This creates two problems:\n* The slopes can no longer be directly interpreted\n* The model's predictions are based on all the features together. Removing a feature because it may no longer be measured changes the slopes of the other features and therefore also the predictions.\n\nHow do you find out whether the fifth assumption is fulfilled? In the case of two features, we can calculate their correlation coefficients. If this is close to zero, you can assume that there is no correlation between the features. If the value is 1 or -1, there is a perfect correlation and the assumption is clearly violated. Generally speaking, you should be concerned if you have a value exceeding 0.9 or -0.9.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "We have already interpreted the calculated increases of the features. The model predicts that with every additional year of age, the property prices lose 0.83 dollars per square meter. With every meter of distance to the nearest metro station, the value of the property decreases by 0.02 dollars. \n",
    "\n",
    "It's noticeable that this interpretation assumes an independence of age and metro distance. The age of the property says nothing about its metro distance, and vice versa. So, you don't say things like \"Older properties are generally located further away from metro stations and are therefore worth less\", but \"older properties are simply older and therefore worth less\".\n",
    "\n",
    "Overall, multiple linear regression is therefore made up of the four assumptions of the simple linear regression model and additionally the assumption of feature independence:\n",
    "1. The data points are independent from each other\n",
    "2. There is a linear dependency between feature and target\n",
    "3. The residuals are normally distributed\n",
    "4. The residuals have a constant variance\n",
    "5. The Features are independent from each other\n",
    "\n",
    "If the fifth assumption is violated, we call this collinearity, i.e. a linear dependence between features. This creates two problems:\n",
    "* The slopes can no longer be directly interpreted\n",
    "* The model's predictions are based on all the features together. Removing a feature because it may no longer be measured changes the slopes of the other features and therefore also the predictions.\n",
    "\n",
    "How do you find out whether the fifth assumption is fulfilled? In the case of two features, we can calculate their correlation coefficients. If this is close to zero, you can assume that there is no correlation between the features. If the value is 1 or -1, there is a perfect correlation and the assumption is clearly violated. Generally speaking, you should be concerned if you have a value exceeding 0.9 or -0.9.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "vertiefung",
    "original-content": "**Deep dive**: The following content is optional, feel free to skip it.<br>\n\n<div class=\"details\">\n\nWhy is perfect collinearity a problem?\nTo answer this question we need to go a little further and look at how our multiple linear regression model learns.\nThe goal of the training stage is always to find the parameters that minimize a selected evaluation metric. The evaluation metric is calculated with a ***cost function***. So you can also interpret the training of a model as a search for the minimum in the *cost function*.\n\nThe sklearn implementation that you have learned so far uses the OLS method to train. OLS stands for *ordinary least squares*. In short: the best hyperplane is determined by the mean of the sum of the squared errors, i.e. the MSE.\nDepending on the values we choose for $\\beta_0$ and $\\vec{\\beta}$ the MSE will change.\n\nThe *cost function* that is minimized in OLS is the same as the calculation of the MSE:\n\n$MSE=\\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat{y_i})^2$\n\nmit: $\\hat{y_i} = \\vec{x_i} \\cdot \\vec{\\beta} + \\beta_0$\n\nAs mentioned earlier, assuming we add a zero column of ones to the feature matrix (X), we can insert $\\beta_0$ in the zero position of $\\vec{\\beta}$ and then ignore $\\beta_0$. \nFor linear regression there is a mathematical equation which can be used to calculate $\\vec{\\beta}$ - the normal equation. The equation is:\n\n$\\vec{\\beta} = (X^T\\cdot X)^{⁻1}\\cdot X^T\\cdot \\vec{y}$\n\nWhen training the linear regression model, this equation is solved mathematically. However, a prerequisite for solving this equation is that the matrix $(X^T\\cdot X)$ is invertible. If perfect colinearity occurs, this is not the case and the model cannot be trained.\nIt is therefore worth considering the correlation coefficients before selecting the features.\n\n</div>",
    "protected": false,
    "selectable": false,
    "tags": []
   },
   "source": [
    "**Deep dive**: The following content is optional, feel free to skip it.<br>\n",
    "\n",
    "<div class=\"details\">\n",
    "\n",
    "Why is perfect collinearity a problem?\n",
    "To answer this question we need to go a little further and look at how our multiple linear regression model learns.\n",
    "The goal of the training stage is always to find the parameters that minimize a selected evaluation metric. The evaluation metric is calculated with a ***cost function***. So you can also interpret the training of a model as a search for the minimum in the *cost function*.\n",
    "\n",
    "The sklearn implementation that you have learned so far uses the OLS method to train. OLS stands for *ordinary least squares*. In short: the best hyperplane is determined by the mean of the sum of the squared errors, i.e. the MSE.\n",
    "Depending on the values we choose for $\\beta_0$ and $\\vec{\\beta}$ the MSE will change.\n",
    "\n",
    "The *cost function* that is minimized in OLS is the same as the calculation of the MSE:\n",
    "\n",
    "$MSE=\\frac{1}{n}\\sum_{i=1}^n(y_i-\\hat{y_i})^2$\n",
    "\n",
    "mit: $\\hat{y_i} = \\vec{x_i} \\cdot \\vec{\\beta} + \\beta_0$\n",
    "\n",
    "As mentioned earlier, assuming we add a zero column of ones to the feature matrix (X), we can insert $\\beta_0$ in the zero position of $\\vec{\\beta}$ and then ignore $\\beta_0$. \n",
    "For linear regression there is a mathematical equation which can be used to calculate $\\vec{\\beta}$ - the normal equation. The equation is:\n",
    "\n",
    "$\\vec{\\beta} = (X^T\\cdot X)^{⁻1}\\cdot X^T\\cdot \\vec{y}$\n",
    "\n",
    "When training the linear regression model, this equation is solved mathematically. However, a prerequisite for solving this equation is that the matrix $(X^T\\cdot X)$ is invertible. If perfect colinearity occurs, this is not the case and the model cannot be trained.\n",
    "It is therefore worth considering the correlation coefficients before selecting the features.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_selectable",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "Let's calculate the correlation coefficient using `my_df.corr()`.\n",
    "protected": false,
    "selectable": true
   },
   "source": [
    "Let's calculate the correlation coefficient using `my_df.corr()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_content_type": "code_user",
    "changed": false,
    "deletable": false,
    "editable": true,
    "hint": "Write `df.loc[:, ['house_age', 'metro_distance']].corr()` and run the cell.",
    "original-content": "",
    "protected": false,
    "selectable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>house_age</th>\n",
       "      <th>metro_distance</th>\n",
       "      <th>number_convenience_stores</th>\n",
       "      <th>number_parking_spaces</th>\n",
       "      <th>air_pollution</th>\n",
       "      <th>light_pollution</th>\n",
       "      <th>noise_pollution</th>\n",
       "      <th>neighborhood_quality</th>\n",
       "      <th>crime_score</th>\n",
       "      <th>energy_consumption</th>\n",
       "      <th>longitude</th>\n",
       "      <th>price_per_ping</th>\n",
       "      <th>price_per_m2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>house_age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.036331</td>\n",
       "      <td>0.014449</td>\n",
       "      <td>-0.022529</td>\n",
       "      <td>0.040284</td>\n",
       "      <td>0.025715</td>\n",
       "      <td>0.028178</td>\n",
       "      <td>-0.081576</td>\n",
       "      <td>-0.052100</td>\n",
       "      <td>-0.084817</td>\n",
       "      <td>-0.065618</td>\n",
       "      <td>-0.226919</td>\n",
       "      <td>-0.226919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metro_distance</th>\n",
       "      <td>0.036331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.606720</td>\n",
       "      <td>-0.432883</td>\n",
       "      <td>0.780327</td>\n",
       "      <td>0.737938</td>\n",
       "      <td>0.855484</td>\n",
       "      <td>-0.030894</td>\n",
       "      <td>0.043856</td>\n",
       "      <td>-0.093475</td>\n",
       "      <td>-0.815071</td>\n",
       "      <td>-0.660938</td>\n",
       "      <td>-0.660938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_convenience_stores</th>\n",
       "      <td>0.014449</td>\n",
       "      <td>-0.606720</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.674302</td>\n",
       "      <td>-0.515958</td>\n",
       "      <td>-0.496835</td>\n",
       "      <td>-0.553736</td>\n",
       "      <td>-0.016989</td>\n",
       "      <td>-0.056977</td>\n",
       "      <td>0.022464</td>\n",
       "      <td>0.450321</td>\n",
       "      <td>0.563644</td>\n",
       "      <td>0.563644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_parking_spaces</th>\n",
       "      <td>-0.022529</td>\n",
       "      <td>-0.432883</td>\n",
       "      <td>0.674302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.322823</td>\n",
       "      <td>-0.312605</td>\n",
       "      <td>-0.393450</td>\n",
       "      <td>-0.041470</td>\n",
       "      <td>-0.041056</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.224307</td>\n",
       "      <td>0.288261</td>\n",
       "      <td>0.288261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>air_pollution</th>\n",
       "      <td>0.040284</td>\n",
       "      <td>0.780327</td>\n",
       "      <td>-0.515958</td>\n",
       "      <td>-0.322823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>0.813770</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>0.066948</td>\n",
       "      <td>-0.077235</td>\n",
       "      <td>-0.640769</td>\n",
       "      <td>-0.559532</td>\n",
       "      <td>-0.559532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>light_pollution</th>\n",
       "      <td>0.025715</td>\n",
       "      <td>0.737938</td>\n",
       "      <td>-0.496835</td>\n",
       "      <td>-0.312605</td>\n",
       "      <td>0.947841</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.785710</td>\n",
       "      <td>-0.007780</td>\n",
       "      <td>0.077222</td>\n",
       "      <td>-0.068125</td>\n",
       "      <td>-0.620875</td>\n",
       "      <td>-0.503870</td>\n",
       "      <td>-0.503870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>noise_pollution</th>\n",
       "      <td>0.028178</td>\n",
       "      <td>0.855484</td>\n",
       "      <td>-0.553736</td>\n",
       "      <td>-0.393450</td>\n",
       "      <td>0.813770</td>\n",
       "      <td>0.785710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.148646</td>\n",
       "      <td>-0.702294</td>\n",
       "      <td>-0.606372</td>\n",
       "      <td>-0.606372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neighborhood_quality</th>\n",
       "      <td>-0.081576</td>\n",
       "      <td>-0.030894</td>\n",
       "      <td>-0.016989</td>\n",
       "      <td>-0.041470</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>-0.007780</td>\n",
       "      <td>-0.011858</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.073701</td>\n",
       "      <td>-0.023033</td>\n",
       "      <td>0.059182</td>\n",
       "      <td>0.097014</td>\n",
       "      <td>0.097014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crime_score</th>\n",
       "      <td>-0.052100</td>\n",
       "      <td>0.043856</td>\n",
       "      <td>-0.056977</td>\n",
       "      <td>-0.041056</td>\n",
       "      <td>0.066948</td>\n",
       "      <td>0.077222</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.073701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.073215</td>\n",
       "      <td>-0.022769</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>-0.017667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>energy_consumption</th>\n",
       "      <td>-0.084817</td>\n",
       "      <td>-0.093475</td>\n",
       "      <td>0.022464</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>-0.077235</td>\n",
       "      <td>-0.068125</td>\n",
       "      <td>-0.148646</td>\n",
       "      <td>-0.023033</td>\n",
       "      <td>-0.073215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.097615</td>\n",
       "      <td>0.078049</td>\n",
       "      <td>0.078049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>longitude</th>\n",
       "      <td>-0.065618</td>\n",
       "      <td>-0.815071</td>\n",
       "      <td>0.450321</td>\n",
       "      <td>0.224307</td>\n",
       "      <td>-0.640769</td>\n",
       "      <td>-0.620875</td>\n",
       "      <td>-0.702294</td>\n",
       "      <td>0.059182</td>\n",
       "      <td>-0.022769</td>\n",
       "      <td>0.097615</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.517159</td>\n",
       "      <td>0.517159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_per_ping</th>\n",
       "      <td>-0.226919</td>\n",
       "      <td>-0.660938</td>\n",
       "      <td>0.563644</td>\n",
       "      <td>0.288261</td>\n",
       "      <td>-0.559532</td>\n",
       "      <td>-0.503870</td>\n",
       "      <td>-0.606372</td>\n",
       "      <td>0.097014</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>0.078049</td>\n",
       "      <td>0.517159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price_per_m2</th>\n",
       "      <td>-0.226919</td>\n",
       "      <td>-0.660938</td>\n",
       "      <td>0.563644</td>\n",
       "      <td>0.288261</td>\n",
       "      <td>-0.559532</td>\n",
       "      <td>-0.503870</td>\n",
       "      <td>-0.606372</td>\n",
       "      <td>0.097014</td>\n",
       "      <td>-0.017667</td>\n",
       "      <td>0.078049</td>\n",
       "      <td>0.517159</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           house_age  metro_distance  \\\n",
       "house_age                   1.000000        0.036331   \n",
       "metro_distance              0.036331        1.000000   \n",
       "number_convenience_stores   0.014449       -0.606720   \n",
       "number_parking_spaces      -0.022529       -0.432883   \n",
       "air_pollution               0.040284        0.780327   \n",
       "light_pollution             0.025715        0.737938   \n",
       "noise_pollution             0.028178        0.855484   \n",
       "neighborhood_quality       -0.081576       -0.030894   \n",
       "crime_score                -0.052100        0.043856   \n",
       "energy_consumption         -0.084817       -0.093475   \n",
       "longitude                  -0.065618       -0.815071   \n",
       "price_per_ping             -0.226919       -0.660938   \n",
       "price_per_m2               -0.226919       -0.660938   \n",
       "\n",
       "                           number_convenience_stores  number_parking_spaces  \\\n",
       "house_age                                   0.014449              -0.022529   \n",
       "metro_distance                             -0.606720              -0.432883   \n",
       "number_convenience_stores                   1.000000               0.674302   \n",
       "number_parking_spaces                       0.674302               1.000000   \n",
       "air_pollution                              -0.515958              -0.322823   \n",
       "light_pollution                            -0.496835              -0.312605   \n",
       "noise_pollution                            -0.553736              -0.393450   \n",
       "neighborhood_quality                       -0.016989              -0.041470   \n",
       "crime_score                                -0.056977              -0.041056   \n",
       "energy_consumption                          0.022464               0.007477   \n",
       "longitude                                   0.450321               0.224307   \n",
       "price_per_ping                              0.563644               0.288261   \n",
       "price_per_m2                                0.563644               0.288261   \n",
       "\n",
       "                           air_pollution  light_pollution  noise_pollution  \\\n",
       "house_age                       0.040284         0.025715         0.028178   \n",
       "metro_distance                  0.780327         0.737938         0.855484   \n",
       "number_convenience_stores      -0.515958        -0.496835        -0.553736   \n",
       "number_parking_spaces          -0.322823        -0.312605        -0.393450   \n",
       "air_pollution                   1.000000         0.947841         0.813770   \n",
       "light_pollution                 0.947841         1.000000         0.785710   \n",
       "noise_pollution                 0.813770         0.785710         1.000000   \n",
       "neighborhood_quality           -0.002350        -0.007780        -0.011858   \n",
       "crime_score                     0.066948         0.077222         0.000197   \n",
       "energy_consumption             -0.077235        -0.068125        -0.148646   \n",
       "longitude                      -0.640769        -0.620875        -0.702294   \n",
       "price_per_ping                 -0.559532        -0.503870        -0.606372   \n",
       "price_per_m2                   -0.559532        -0.503870        -0.606372   \n",
       "\n",
       "                           neighborhood_quality  crime_score  \\\n",
       "house_age                             -0.081576    -0.052100   \n",
       "metro_distance                        -0.030894     0.043856   \n",
       "number_convenience_stores             -0.016989    -0.056977   \n",
       "number_parking_spaces                 -0.041470    -0.041056   \n",
       "air_pollution                         -0.002350     0.066948   \n",
       "light_pollution                       -0.007780     0.077222   \n",
       "noise_pollution                       -0.011858     0.000197   \n",
       "neighborhood_quality                   1.000000     0.073701   \n",
       "crime_score                            0.073701     1.000000   \n",
       "energy_consumption                    -0.023033    -0.073215   \n",
       "longitude                              0.059182    -0.022769   \n",
       "price_per_ping                         0.097014    -0.017667   \n",
       "price_per_m2                           0.097014    -0.017667   \n",
       "\n",
       "                           energy_consumption  longitude  price_per_ping  \\\n",
       "house_age                           -0.084817  -0.065618       -0.226919   \n",
       "metro_distance                      -0.093475  -0.815071       -0.660938   \n",
       "number_convenience_stores            0.022464   0.450321        0.563644   \n",
       "number_parking_spaces                0.007477   0.224307        0.288261   \n",
       "air_pollution                       -0.077235  -0.640769       -0.559532   \n",
       "light_pollution                     -0.068125  -0.620875       -0.503870   \n",
       "noise_pollution                     -0.148646  -0.702294       -0.606372   \n",
       "neighborhood_quality                -0.023033   0.059182        0.097014   \n",
       "crime_score                         -0.073215  -0.022769       -0.017667   \n",
       "energy_consumption                   1.000000   0.097615        0.078049   \n",
       "longitude                            0.097615   1.000000        0.517159   \n",
       "price_per_ping                       0.078049   0.517159        1.000000   \n",
       "price_per_m2                         0.078049   0.517159        1.000000   \n",
       "\n",
       "                           price_per_m2  \n",
       "house_age                     -0.226919  \n",
       "metro_distance                -0.660938  \n",
       "number_convenience_stores      0.563644  \n",
       "number_parking_spaces          0.288261  \n",
       "air_pollution                 -0.559532  \n",
       "light_pollution               -0.503870  \n",
       "noise_pollution               -0.606372  \n",
       "neighborhood_quality           0.097014  \n",
       "crime_score                   -0.017667  \n",
       "energy_consumption             0.078049  \n",
       "longitude                      0.517159  \n",
       "price_per_ping                 1.000000  \n",
       "price_per_m2                   1.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "The value is very close to zero. The fifth assumption of the multiple linear regression model has therefore been fulfilled. The slopes can be directly interpreted.\n\nWhat do you do if the fifth assumption of the multiple linear regression model is not fulfilled? Then you have three options:\n* *Feature selection*: if there are two correlated features, remove one. You can discuss which is the best one to remove with experts in the field where the data comes from.\n* *Feature engineering*: You can force the features to be independent with a principal component analysis.\n* Alternative model: You can use ridge or lasso regression to reduce correlated features to the most important feature and therefore make predictions.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "The value is very close to zero. The fifth assumption of the multiple linear regression model has therefore been fulfilled. The slopes can be directly interpreted.\n",
    "\n",
    "What do you do if the fifth assumption of the multiple linear regression model is not fulfilled? Then you have three options:\n",
    "* *Feature selection*: if there are two correlated features, remove one. You can discuss which is the best one to remove with experts in the field where the data comes from.\n",
    "* *Feature engineering*: You can force the features to be independent with a principal component analysis.\n",
    "* Alternative model: You can use ridge or lasso regression to reduce correlated features to the most important feature and therefore make predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "glueckwunsch",
    "original-content": "**Congratulations:** You have learned the five most important assumptions of the multiple linear regression model:\n\n1. The data points are independent from each other\n2. There is a linear dependency between feature and target\n3. The residuals are normally distributed\n4. The residuals have a constant variance\n5. The Features are independent from each other\n\nYou have now learned how to check the fifth assumption with a correlation value. If you use more than two features, you can proceed similarly, or you can check whether the slope values of the linear multiple regression roughly match those of a ridge or lasso regression, which you'll encounter later in this chapter.\n\nWe've now used two of six possible features. Why not include all eleven features in the model? Because this leads to a whole new problem: *overfitting*. You'll find out what that means in the next lesson.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "**Congratulations:** You have learned the five most important assumptions of the multiple linear regression model:\n",
    "\n",
    "1. The data points are independent from each other\n",
    "2. There is a linear dependency between feature and target\n",
    "3. The residuals are normally distributed\n",
    "4. The residuals have a constant variance\n",
    "5. The Features are independent from each other\n",
    "\n",
    "You have now learned how to check the fifth assumption with a correlation value. If you use more than two features, you can proceed similarly, or you can check whether the slope values of the linear multiple regression roughly match those of a ridge or lasso regression, which you'll encounter later in this chapter.\n",
    "\n",
    "We've now used two of six possible features. Why not include all eleven features in the model? Because this leads to a whole new problem: *overfitting*. You'll find out what that means in the next lesson.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "merke",
    "original-content": "**Remember:**\n* A multiple linear regression uses more than one feature.\n* Adding additional features often improves the predictions.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "**Remember:**\n",
    "* A multiple linear regression uses more than one feature.\n",
    "* Adding additional features often improves the predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "messageType": "literatur",
    "original-content": "**Literature:**\nIf you would like to delve deeper into the subject matter of this chapter, we recommend the following source(s):\n* Géron, Aurélien. 2017. *Hands-On Machine Learning with Scikit-Learn & TensorFlow*. Sebastopol : O'Reilly, 2017. p. 108 pp.\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "**Literature:**\n",
    "If you would like to delve deeper into the subject matter of this chapter, we recommend the following source(s):\n",
    "* Géron, Aurélien. 2017. *Hands-On Machine Learning with Scikit-Learn & TensorFlow*. Sebastopol : O'Reilly, 2017. p. 108 pp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_content_type": "markdown_default",
    "changed": false,
    "deletable": false,
    "editable": false,
    "original-content": "***\nDo you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n***\nFound a mistake? Contact Support at support@stackfuel.com.\n***\n",
    "protected": false,
    "selectable": false
   },
   "source": [
    "***\n",
    "Do you have any questions about this exercise? Look in the forum to see if they have already been discussed.\n",
    "***\n",
    "Found a mistake? Contact Support at support@stackfuel.com.\n",
    "***\n"
   ]
  }
 ],
 "metadata": {
  "content_id": "0e72bba0-b5ef-4add-96b1-ea1028172ea1",
  "content_language": "en",
  "content_title": "Multiple Linear Regression",
  "content_type": "exercise",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
